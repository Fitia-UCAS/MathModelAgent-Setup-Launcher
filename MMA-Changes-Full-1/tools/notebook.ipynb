{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b19e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "æ­£å¨å è½½æ°æ®...\n",
       "æ§è¡åå§æ°æ®æ£æ¥...\n",
       "è®¡ç®åºæ¬ç»è®¡é...\n",
       "çæç©ºé´åå¸ç­å¾...\n",
       "æ£æ¥è¾¹çå¼æ¯å¦è¶è¿äºé¶...\n",
       "è®¡ç®ç©ºé´ç¸å",
       "³æ§...\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[2], line 85\n     83 # === ç©ºé´ç¸å\n     84 ³æ§åæ ===\n---> 85 print(\"è®¡ç®ç©ºé´ç¸å\n     86 ³æ§...\")\n     87 # ä½¿ç¨Moran's Iè®¡ç®ç©ºé´èªç¸å\n\nModuleNotFoundError: No module named 'libpysal'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# åå»ºEDAç®å½ç»æ\n",
    "os.makedirs('eda/datasets', exist_ok=True)\n",
    "os.makedirs('eda/figures', exist_ok=True)\n",
    "os.makedirs('eda/reports', exist_ok=True)\n",
    "\n",
    "# %% eda - å¼å§æ¢ç´¢æ§æ°æ®åæ\n",
    "# è®¾ç½®ç§å­¦åºçé£æ ¼\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "\n",
    "# è®¾ç½®ä¸­æå­ä½æ¯æ\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"Arial Unicode MS\", \"DejaVu Sans\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# === å è½½æ°æ® ===\n",
    "print(\"æ­£å¨å è½½æ°æ®...\")\n",
    "df = pd.read_csv(\"pollution_data.csv\")\n",
    "\n",
    "# === åå§æ°æ®æ£æ¥ ===\n",
    "print(\"æ§è¡åå§æ°æ®æ£æ¥...\")\n",
    "data_info = f\"æ°æ®éç»´åº¦: {df.shape}\\n\"\n",
    "data_info += f\"åå: {list(df.columns)}\\n\"\n",
    "data_info += \"\\nå5è¡æ°æ®é¢è§:\\n\" + df.head().to_string()\n",
    "\n",
    "data_info += \"\\n\\nç¼ºå¤±å¼ç»è®¡:\\n\"\n",
    "data_info += df.isnull().sum().to_string()\n",
    "\n",
    "# === åºæ¬ç»è®¡åæ ===\n",
    "print(\"è®¡ç®åºæ¬ç»è®¡é...\")\n",
    "basic_stats = df.describe(percentiles=[.01, .05, .25, .5, .75, .95, .99])\n",
    "stats_report = f\"\\nåºæ¬ç»è®¡é:\\n{basic_stats}\"\n",
    "\n",
    "# === ç©ºé´åå¸å¯è§å ===\n",
    "print(\"çæç©ºé´åå¸ç­å¾...\")\n",
    "# åè®¾æ°æ®åä¸º [x_grid, y_grid, concentration]\n",
    "if all(col in df.columns for col in ['x_grid', 'y_grid', 'concentration']):\n",
    "    # åå»ºç½æ ¼æ°æ®\n",
    "    grid_data = df.pivot(index='y_grid', columns='x_grid', values='concentration')\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        grid_data,\n",
    "        cmap=\"viridis\",\n",
    "        cbar_kws={'label': 'æ±¡æç©æµåº¦'},\n",
    "        square=True\n",
    "    )\n",
    "    plt.title(\"æ±¡æç©ç©ºé´åå¸ç­å¾\")\n",
    "    plt.xlabel(\"Xç½æ ¼åæ \")\n",
    "    plt.ylabel(\"Yç½æ ¼åæ \")\n",
    "    plt.savefig(\"eda/figures/fig_spatial_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# === è¾¹çæ¡ä»¶æ£æ¥ ===\n",
    "print(\"æ£æ¥è¾¹çå¼æ¯å¦è¶è¿äºé¶...\")\n",
    "boundary_info = \"\\nè¾¹çæ¡ä»¶åæ:\\n\"\n",
    "if 'x_grid' in df.columns:\n",
    "    max_x = df['x_grid'].max()\n",
    "    min_x = df['x_grid'].min()\n",
    "    boundary_x = df[(df['x_grid'] == min_x) | (df['x_grid'] == max_x)]\n",
    "    boundary_info += f\"Xæ¹åè¾¹çç¹æ°é: {len(boundary_x)}\"\n",
    "    boundary_info += f\"\\nXè¾¹çå¹³åæµåº¦: {boundary_x['concentration'].mean():.4f}\"\n",
    "    boundary_info += f\"\\nXè¾¹çæå°æµåº¦: {boundary_x['concentration'].min():.4f}\"\n",
    "\n",
    "    # å¨å",
    "³é®ä½ç½®çæå¯è§å\n",
    "    if not boundary_x.empty:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sns.kdeplot(boundary_x['concentration'], fill=True)\n",
    "        plt.axvline(x=0, color='r', linestyle='--', label='çè®ºè¾¹çå¼(0)')\n",
    "        plt.title(\"è¾¹çæ±¡æç©æµåº¦åå¸\")\n",
    "        plt.xlabel(\"æ±¡æç©æµåº¦\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"eda/figures/fig_boundary_distribution.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "# === ç©ºé´ç¸å",
    "³æ§åæ ===\n",
    "print(\"è®¡ç®ç©ºé´ç¸å",
    "³æ§...\")\n",
    "# ä½¿ç¨Moran's Iè®¡ç®ç©ºé´èªç¸å",
    "³\n",
    "from libpysal.weights import lat2W\n",
    "from esda.moran import Moran\n",
    "\n",
    "correlation_info = \"\\nç©ºé´ç¸å",
    "³æ§åæ:\\n\"\n",
    "if all(col in df.columns for col in ['x_grid', 'y_grid', 'concentration']):\n",
    "    # åå»ºç©ºé´æéç©éµ\n",
    "    w = lat2W(100, 100, rook=False)  # queené»æ¥\n",
    "\n",
    "    # ç¡®ä¿æ°æ®æåæ é¡ºåºæå\n",
    "    sorted_df = df.sort_values(['y_grid', 'x_grid'])\n",
    "    concentrations = sorted_df['concentration'].values\n",
    "\n",
    "    # è®¡ç®Moran's I\n",
    "    try:\n",
    "        moran = Moran(concentrations, w)\n",
    "        correlation_info += f\"Moran's Iå¼: {moran.I:.4f}\\n\"\n",
    "        correlation_info += f\"på¼: {moran.p_norm:.4f}\\n\"\n",
    "    except Exception as e:\n",
    "        correlation_info += f\"ç©ºé´ç¸å",
    "³æ§è®¡ç®éè¯¯: {str(e)}\\n\"\n",
    "\n",
    "# === å¼å¸¸å¼æ£æ¥ä¸å¤ç ===\n",
    "print(\"æ£æµåå¤çå¼å¸¸å¼...\")\n",
    "outlier_info = \"\\nå¼å¸¸å¼åæ:\\n\"\n",
    "if 'concentration' in df.columns:\n",
    "    # ä½¿ç¨Z-scoreæ£æµå¼å¸¸å¼\n",
    "    z_scores = np.abs(stats.zscore(df['concentration']))\n",
    "    outliers = df[z_scores > 3]\n",
    "    outlier_info += f\"æ£æµå°çå¼å¸¸å¼æ°é: {len(outliers)}\\n\"\n",
    "    outlier_info += outliers.describe().to_string()\n",
    "\n",
    "    # ä½¿ç¨IQRæå¼æ¿æ¢å¼å¸¸å¼\n",
    "    if not outliers.empty:\n",
    "        q1 = df['concentration'].quantile(0.25)\n",
    "        q3 = df['concentration'].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        upper_bound = q3 + 1.5*iqr\n",
    "\n",
    "        df['concentration'] = np.where(\n",
    "            z_scores > 3,\n",
    "            upper_bound,\n",
    "            df['concentration']\n",
    "        )\n",
    "        outlier_info += \"\\nå·²ä½¿ç¨IQRæ¹æ³æ¿æ¢å¼å¸¸å¼\"\n",
    "\n",
    "    # çæå¯è§å\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.boxplot(x=df['concentration'])\n",
    "    plt.title(\"æ±¡æç©æµåº¦åå¸ï¼å¼å¸¸å¼å¤çåï¼\")\n",
    "    plt.savefig(\"eda/figures/fig_outliers_treated.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# === ç¼ºå¤±å¼æè¡¥ ===\n",
    "print(\"å¤çç¼ºå¤±å¼...\")\n",
    "missing_info = \"\\nç¼ºå¤±å¼å¤ç:\\n\"\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    missing_info += f\"åå§ç¼ºå¤±å¼æ°é: {df.isnull().sum().sum()}\\n\"\n",
    "\n",
    "    # ä½¿ç¨ç©ºé´æå¼ï¼æè¿é»ï¼\n",
    "    from sklearn.impute import KNNImputer\n",
    "\n",
    "    # ç¡®ä¿æ°æ®æåæ æåº\n",
    "    sorted_df = df.sort_values(['y_grid', 'x_grid'])\n",
    "    imputer = KNNImputer(n_neighbors=4)\n",
    "    imputed = imputer.fit_transform(sorted_df[['concentration']])\n",
    "    df.loc[sorted_df.index, 'concentration'] = imputed\n",
    "\n",
    "    missing_info += f\"å¤çåçç¼ºå¤±å¼æ°é: {df['concentration'].isnull().sum()}\"\n",
    "\n",
    "# === ä¿å­æ¸",
    "æ´åçæ°æ® ===\n",
    "df.to_csv(\"eda/datasets/data_cleaned.csv\", index=False)\n",
    "print(\"æ¸",
    "æ´åæ°æ®å·²ä¿å­\")\n",
    "\n",
    "# === çææç»æ¥å ===\n",
    "report_content = \"æ±¡æç©æµåº¦æ°æ®EDAæ¥å\\n\"\n",
    "report_content += \"=\"*50 + \"\\n\"\n",
    "report_content += data_info\n",
    "report_content += \"\\n\" + stats_report\n",
    "report_content += \"\\n\" + boundary_info\n",
    "report_content += \"\\n\" + correlation_info\n",
    "report_content += \"\\n\" + outlier_info\n",
    "report_content += \"\\n\" + missing_info\n",
    "\n",
    "with open(\"eda/reports/report_eda.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(\"EDAåæå®æï¼æ¥åå·²çæ\")\n",
    "df.head()  # æ¾ç¤ºåäºè¡ç¡®è®¤æ¸",
    "æ´ç»æ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e5090",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "  Cell In[3], line 131\n    \n    ^\nSyntaxError: unterminated string literal (detected at line 131)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# åå»ºEDAç®å½ç»æ\n",
    "os.makedirs('eda/datasets', exist_ok=True)\n",
    "os.makedirs('eda/figures', exist_ok=True)\n",
    "os.makedirs('eda/reports', exist_ok=True)\n",
    "\n",
    "# %% eda - å¼å§æ¢ç´¢æ§æ°æ®åæ\n",
    "# è®¾ç½®ç§å­¦åºçé£æ ¼\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "\n",
    "# è®¾ç½®ä¸­æå­ä½æ¯æ\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"Arial Unicode MS\", \"DejaVu Sans\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# === å è½½æ°æ® ===\n",
    "print(\"æ­£å¨å è½½æ°æ®...\")\n",
    "df = pd.read_csv(\"pollution_data.csv\")\n",
    "\n",
    "# === åå§æ°æ®æ£æ¥ ===\n",
    "print(\"æ§è¡åå§æ°æ®æ£æ¥...\")\n",
    "data_info = f\"æ°æ®éç»´åº¦: {df.shape}\\n\"\n",
    "data_info += f\"åå: {list(df.columns)}\\n\"\n",
    "data_info += \"\\nå5è¡æ°æ®é¢è§:\\n\" + df.head().to_string()\n",
    "\n",
    "data_info += \"\\n\\nç¼ºå¤±å¼ç»è®¡:\\n\"\n",
    "data_info += df.isnull().sum().to_string()\n",
    "\n",
    "# === åºæ¬ç»è®¡åæ ===\n",
    "print(\"è®¡ç®åºæ¬ç»è®¡é...\")\n",
    "basic_stats = df.describe(include='all', percentiles=[.01, .05, .25, .5, .75, .95, .99])\n",
    "stats_report = f\"\\nåºæ¬ç»è®¡é:\\n{basic_stats}\"\n",
    "\n",
    "# === ç©ºé´åå¸å¯è§å ===\n",
    "print(\"çæç©ºé´åå¸ç­å¾...\")\n",
    "# åè®¾æ°æ®åä¸º [x_grid, y_grid, concentration]\n",
    "if all(col in df.columns for col in ['x_grid', 'y_grid', 'concentration']):\n",
    "    # åå»ºç½æ ¼æ°æ®\n",
    "    grid_data = df.pivot(index='y_grid', columns='x_grid', values='concentration')\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        grid_data,\n",
    "        cmap=\"viridis\",\n",
    "        cbar_kws={'label': 'æ±¡æç©æµåº¦'},\n",
    "        square=True\n",
    "    )\n",
    "    plt.title(\"æ±¡æç©ç©ºé´åå¸ç­å¾\")\n",
    "    plt.xlabel(\"Xç½æ ¼åæ \")\n",
    "    plt.ylabel(\"Yç½æ ¼åæ \")\n",
    "    plt.savefig(\"eda/figures/fig_spatial_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# === è¾¹çæ¡ä»¶æ£æ¥ ===\n",
    "print(\"æ£æ¥è¾¹çå¼æ¯å¦è¶è¿äºé¶...\")\n",
    "boundary_info = \"\\nè¾¹çæ¡ä»¶åæ:\\n\"\n",
    "if all(col in df.columns for col in ['x_grid', 'y_grid']):\n",
    "    max_x, min_x = df['x_grid'].max(), df['x_grid'].min()\n",
    "    max_y, min_y = df['y_grid'].max(), df['y_grid'].min()\n",
    "\n",
    "    boundaries = df[\n",
    "        (df['x_grid'] == max_x) | (df['x_grid'] == min_x) | \n",
    "        (df['y_grid'] == max_y) | (df['y_grid'] == min_y)\n",
    "    ]\n",
    "\n",
    "    boundary_info += f\"è¾¹çç¹æ»æ°: {len(boundaries)}\\n\"\n",
    "    boundary_info += f\"è¾¹çå¹³åæµåº¦: {boundaries['concentration'].mean():.4f}\\n\"\n",
    "    boundary_info += f\"è¾¹çæµåº¦æ åå·®: {boundaries['concentration'].std():.4f}\\n\"\n",
    "\n",
    "    # è¾¹çåå¸å¯è§å\n",
    "    if not boundaries.empty:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sns.kdeplot(boundaries['concentration'], fill=True)\n",
    "        plt.axvline(x=0, color='r', linestyle='--', label='çè®ºè¾¹çå¼(0)')\n",
    "        plt.title(\"è¾¹çæ±¡æç©æµåº¦åå¸\")\n",
    "        plt.xlabel(\"æ±¡æç©æµåº¦\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"eda/figures/fig_boundary_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# === ç©ºé´ç¸å",
    "³æ§åæ(ä¿®æ­£ç) ===\n",
    "print(\"è®¡ç®ç©ºé´ç¸å",
    "³æ§...\")\n",
    "correlation_info = \"\\nç©ºé´ç¸å",
    "³æ§åæ(é»è¿ç¹):\\n\"\n",
    "if all(col in df.columns for col in ['x_grid', 'y_grid', 'concentration']):\n",
    "    # åå»ºç½æ ¼æ°æ®ç©éµ\n",
    "    grid_matrix = df.pivot(index='y_grid', columns='x_grid', values='concentration').values\n",
    "\n",
    "    # è®¡ç®æ°´å¹³æ¹åç¸å",
    "³æ§\n",
    "    horizontal_corr = np.corrcoef(grid_matrix[:, :-1].flatten(), grid_matrix[:, 1:].flatten())[0, 1]\n",
    "\n",
    "    # è®¡ç®åç´æ¹åç¸å",
    "³æ§\n",
    "    vertical_corr = np.corrcoef(grid_matrix[:-1, :].flatten(), grid_matrix[1:, :].flatten())[0, 1]\n",
    "\n",
    "    correlation_info += f\"æ°´å¹³æ¹å(å·¦å³é»å±",
    ")ç¸å",
    "³ç³»æ°: {horizontal_corr:.4f}\\n\"\n",
    "    correlation_info += f\"åç´æ¹å(ä¸ä¸é»å±",
    ")ç¸å",
    "³ç³»æ°: {vertical_corr:.4f}\\n\"\n",
    "\n",
    "# === å¼å¸¸å¼æ£æ¥ä¸å¤ç ===\n",
    "print(\"æ£æµåå¤çå¼å¸¸å¼...\")\n",
    "outlier_info = \"\\nå¼å¸¸å¼åæ:\\n\"\n",
    "if 'concentration' in df.columns:\n",
    "    # ä½¿ç¨5Ïéå¼ä»£æ¿3Ïæé«é²æ£æ§\n",
    "    z_scores = np.abs(stats.zscore(df['concentration']))\n",
    "    outliers = df[z_scores > 5]\n",
    "    outlier_info += f\"å¼å¸¸ç¹æ°é(5Ï): {len(outliers)}\\n\"\n",
    "\n",
    "    # åºäºåä½æ°çå¼å¸¸å¼æ¿æ¢\n",
    "    q1 = df['concentration'].quantile(0.05)\n",
    "    q3 = df['concentration'].quantile(0.95)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + iqr * 3\n",
    "    lower_bound = q1 - iqr * 3\n",
    "\n",
    "    # æ¿æ¢å¼å¸¸å¼\n",
    "    mask = (z_scores > 5) & ((df['concentration'] > upper_bound) | (df['concentration'] < lower_bound))\n",
    "    df.loc[mask, 'concentration'] = df[~mask]['concentration'].clip(lower_bound, upper_bound).median()\n",
    "\n",
    "    # å¼å¸¸å¼å¤çååå¸å¯è§å\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.boxplot(x=df['concentration'])\n",
    "    plt.title(\"æ±¡æç©æµåº¦åå¸ï¼å¼å¸¸å¼å¤çåï¼\")\n",
    "    plt.savefig(\"eda/figures/fig_outliers_treated.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# === ç¼ºå¤±å¼æè¡¥ ===\n",
    "print(\"å¤çç¼ºå¤±å¼...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9bcfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "==== é®é¢1: æ±¡æç©æ©æ£å¨æä»¿ç ====\n",
       "æ­£å¨å è½½åå§æµåº¦åº...\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[4], line 18\n     16 # å è½½EDAæ¸\n     17 æ´åçæ°æ®\n---> 18 print(\"æ­£å¨å è½½åå§æµåº¦åº...\")\n     19 initial_df = pd.read_csv(\"eda/datasets/data_cleaned.csv\")\n     20 \n\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-> 1026 return _read(filepath_or_buffer, kwds)\n\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--> 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-> 1620 self._engine = self._make_engine(f, self.engine)\n\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-> 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--> 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: 'eda/datasets/data_cleaned.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import diags, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "# åå»ºé®é¢è¾åºç®å½\n",
    "os.makedirs('ques1/datasets', exist_ok=True)\n",
    "os.makedirs('ques1/figures', exist_ok=True)\n",
    "os.makedirs('ques1/reports', exist_ok=True)\n",
    "\n",
    "# %% ques1\n",
    "print(\"==== é®é¢1: æ±¡æç©æ©æ£å¨æä»¿ç ====\")\n",
    "\n",
    "# å è½½EDAæ¸",
    "æ´åçæ°æ®\n",
    "print(\"æ­£å¨å è½½åå§æµåº¦åº...\")\n",
    "initial_df = pd.read_csv(\"eda/datasets/data_cleaned.csv\")\n",
    "\n",
    "# === åæ°è®¾ç½® ===\n",
    "L = 100  # ç½æ ¼å°ºå¯¸ (100x100)\n",
    "dx = dy = 1.0  # ç©ºé´æ­¥é¿ (ç±³)\n",
    "u = 0.005  # xæ¹åæµé (m/s)\n",
    "v = 0.001   # yæ¹åæµé (m/s)\n",
    "dt = 1.0    # æ¶é´æ­¥é¿ (ç§)\n",
    "total_time = 3600  # æ»ä»¿çæ¶é´ (ç§), 1å°æ¶\n",
    "output_interval = 300  # è¾åºé´é (ç§)\n",
    "\n",
    "# === ä¼°ç®æ©æ£ç³»æ°D ===\n",
    "print(\"ä¼°ç®æ©æ£ç³»æ°D...\")\n",
    "# æ¹æ³ï¼è®¡ç®ç©ºé´æ¢¯åº¦å¹¶æå\n",
    "grid_data = initial_df.pivot(index='y_grid', columns='x_grid', values='concentration')\n",
    "c_matrix = grid_data.values\n",
    "\n",
    "grad_x, grad_y = np.gradient(c_matrix, dx, dy)\n",
    "laplacian = np.gradient(grad_x, dx, axis=1) + np.gradient(grad_y, dy, axis=0)\n",
    "\n",
    "# å¿½ç¥è¾¹çæåºï¼ä½¿ç¨å",
    "é¨ç¹ä¼°ç®\n",
    "inner_slice = slice(20, 80)  # ä¸­é´åºå\n",
    "D = np.abs(np.nanmean(grad_x[inner_slice, inner_slice]) * dx / 0.1)\n",
    "print(f\"ä¼°ç®æ©æ£ç³»æ° D = {D:.6f} mÂ²/s\")\n",
    "\n",
    "# === åå»ºåå§æ¡ä»¶ ===\n",
    "C = c_matrix.copy()\n",
    "\n",
    "# === æéå·®åç³»æ° ===\n",
    "rx = D * dt / (2 * dx**2)\n",
    "ry = D * dt / (2 * dy**2)\n",
    "cx = u * dt / (4 * dx)\n",
    "cy = v * dt / (4 * dy)\n",
    "\n",
    "# === åå»ºå¾®åç®å­ ===\n",
    "def create_sparse_matrix(N):\n",
    "    \"\"\"åå»ºéå¼é¨åçç¨çç©éµ\"\"\"\n",
    "    diagonals = []\n",
    "\n",
    "    # ä¸»å¯¹è§çº¿: 1 + 2*rx + 2*ry\n",
    "    main_diag = np.ones(N) * (1 + 2*rx + 2*ry)\n",
    "    diagonals.append(main_diag)\n",
    "\n",
    "    # ä¸/ä¸å¯¹è§çº¿: -rx\n",
    "    off_diag = np.ones(N-1) * (-rx)\n",
    "    diagonals.append(off_diag)\n",
    "    diagonals.append(off_diag)\n",
    "\n",
    "    # è¿å¯¹è§çº¿: -ry\n",
    "    far_diag = np.ones(N) * (-ry)\n",
    "    diagonals.append(far_diag)\n",
    "    diagonals.append(far_diag)\n",
    "\n",
    "    offsets = [0, 1, -1, int(np.sqrt(N)), -int(np.sqrt(N))]\n",
    "    return diags(diagonals, offsets, shape=(N, N), format='csr')\n",
    "\n",
    "N = (L-2)**2  # å",
    "é¨ç¹æ°é\n",
    "A_implicit = create_sparse_matrix(N)\n",
    "\n",
    "# === æ¶é´æ¼è¿å¾ªç¯ ===\n",
    "print(f\"å¼å§å¨æä»¿ç: {total_time}ç§ (æ­¥é¿{dt}ç§)\")\n",
    "time_points = range(0, total_time + 1, output_interval)\n",
    "simulation_results = {}\n",
    "\n",
    "for t in range(total_time + 1):\n",
    "    # è¾¹çæ¡ä»¶ (Dirichleté¶è¾¹ç)\n",
    "    C[0, :] = C[-1, :] = C[:, 0] = C[:, -1] = 0.0\n",
    "\n",
    "    # æ¾å¼è®¡ç®å¯¹æµåæ©æ£é¡¹\n",
    "    grad_x_ex, grad_y_ex = np.gradient(C, dx, dy)\n",
    "    conv_x = u * grad_x_ex\n",
    "    conv_y = v * grad_y_ex\n",
    "\n",
    "    grad_x_im, grad_y_im = np.gradient(conv_x, dx, dy)\n",
    "    diff = D * (grad_x_im + grad_y_im)\n",
    "\n",
    "    # ç»åæ¾å¼é¡¹\n",
    "    explicit_term = C - dt * (conv_x + conv_y - diff)\n",
    "\n",
    "    # æåå",
    "é¨ç¹ç»éå¼ç³»ç»\n",
    "    interior = explicit_term[1:-1, 1:-1].flatten()\n",
    "\n",
    "    # æ±è§£éå¼ç³»ç»\n",
    "    interior_next = spsolve(A_implicit, interior)\n",
    "\n",
    "    # æ´æ°æµåº¦åº\n",
    "    C[1:-1, 1:-1] = interior_next.reshape((L-2, L-2))\n",
    "\n",
    "    # ä¿å­ç»æ\n",
    "    if t in time_points:\n",
    "        print(f\"ä¿å­æ¶é´ç¹ t = {t}ç§\")\n",
    "        simulation_results[t] = C.copy()\n",
    "\n",
    "        # ä¿å­å½åç¶æ\n",
    "        time_df = initial_df.copy()\n",
    "        time_df[f\"conc_{t}\"] = C.ravel()\n",
    "        time_df.to_csv(f\"ques1/datasets/simulation_{t}d.csv\", index=False)\n",
    "\n",
    "# === å¯è§å ===\n",
    "print(\"çæå¯è§å...\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, (t, conc) in enumerate(simulation_results.items()):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(conc.T, cmap=\"viridis\", origin=\"lower\", \n",
    "               extent=[0, L, 0, L], vmin=0, vmax=c_matrix.max())\n",
    "    plt.colorbar(label=\"æ±¡æç©æµåº¦\")\n",
    "    plt.title(f\"t = {t}ç§\")\n",
    "    plt.xlabel(\"Xä½ç½® (m)\")\n",
    "    plt.ylabel(\"Yä½ç½® (m)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ques1/figures/simulation.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# === çææ¥å ===\n",
    "report_content = \"æ±¡æç©æ©æ£å¨æä»¿çæ¥å\\n\"\n",
    "report_content += \"=\" * 50 + \"\\n\"\n",
    "report_content += f\"â¢ ä¼°ç®æ©æ£ç³»æ°: D = {D:.6f} mÂ²/s\\n\"\n",
    "report_content += f\"â¢ ç©ºé´æ­¥é¿: dx = dy = {dx} m\\n\"\n",
    "report_content += f\"â¢ æ¶é´æ­¥é¿: dt = {dt} s\\n\"\n",
    "report_content += f\"â¢ æ°´æµéåº¦: u = {u} m/s, v = {v} m/s\\n\"\n",
    "report_content += f\"â¢ æ»ä»¿çæ¶é´: {total_time} ç§\\n\"\n",
    "report_content += \"\\nè¾åºæä»¶:\\n\"\n",
    "for t in simulation_results.keys():\n",
    "    report_content += f\"- {t}ç§: ques1/datasets/simulation_{t}d.csv\\n\"\n",
    "report_content += f\"- å¯è§å: ques1/figures/simulation.png\"\n",
    "\n",
    "with open(\"ques1/reports/report_ques1.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(\"ä»¿çå®æï¼ç»æä¿å­å¨ques1ç®å½\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a0ba17",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "  Cell In[5], line 2\n    json{\"code\":\"\n                ^\nSyntaxError: unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "```json\n",
    "json{\"code\":\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d146f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "==== é®é¢1: æ±¡æç©æ©æ£å¨æä»¿ç ====\n",
       "æ­£å¨å è½½åå§æµåº¦åº...\n",
       "æ°æ®æ¸",
       "æ´...\n",
       "ä¼°ç®æ©æ£ç³»æ°D...\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805, in Index.get_loc(self, key)\n   3804 try:\n-> 3805     return self._engine.get_loc(casted_key)\n   3806 except KeyError as err:\n\nFile index.pyx:167, in pandas._libs.index.IndexEngine.get_loc()\n\nFile index.pyx:196, in pandas._libs.index.IndexEngine.get_loc()\n\nFile pandas\\\\_libs\\\\hashtable_class_helper.pxi:7081, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nFile pandas\\\\_libs\\\\hashtable_class_helper.pxi:7089, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nKeyError: 'y_grid'\n\nThe above exception was the direct cause of the following exception:\n\nKeyError                                  Traceback (most recent call last)\nCell In[6], line 42\n     40 total_time = 3600  # æ»ä»¿çæ¶é´ (ç§), 1å°æ¶\n     41 output_interval = 300  # è¾åºé´é (ç§)\n---> 42 \n     43 # === ä¼°ç®æ©æ£ç³»æ°D ===\n     44 print(\"ä¼°ç®æ©æ£ç³»æ°D...\")\n\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:9339, in DataFrame.pivot(self, columns, index, values)\n   9332 @Substitution(\"\")\n   9333 @Appender(_shared_docs[\"pivot\"])\n   9334 def pivot(\n   9335     self, *, columns, index=lib.no_default, values=lib.no_default\n   9336 ) -> DataFrame:\n   9337     from pandas.core.reshape.pivot import pivot\n-> 9339     return pivot(self, index=index, columns=columns, values=values)\n\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\pivot.py:553, in pivot(data, columns, index, values)\n    549         index_list = [\n    550             data._constructor_sliced(data.index, name=data.index.name)\n    551         ]\n    552 else:\n--> 553     index_list = [data[idx] for idx in com.convert_to_list_like(index)]\n    555 data_columns = [data[col] for col in columns_listlike]\n    556 index_list.extend(data_columns)\n\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102, in DataFrame.__getitem__(self, key)\n   4100 if self.columns.nlevels > 1:\n   4101     return self._getitem_multilevel(key)\n-> 4102 indexer = self.columns.get_loc(key)\n   4103 if is_integer(indexer):\n   4104     indexer = [indexer]\n\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812, in Index.get_loc(self, key)\n   3807     if isinstance(casted_key, slice) or (\n   3808         isinstance(casted_key, abc.Iterable)\n   3809         and any(isinstance(x, slice) for x in casted_key)\n   3810     ):\n   3811         raise InvalidIndexError(key)\n-> 3812     raise KeyError(key) from err\n   3813 except TypeError:\n   3814     # If we have a listlike key, _check_indexing_error will raise\n   3815     #  InvalidIndexError. Otherwise we fall through and re-raise\n   3816     #  the TypeError.\n   3817     self._check_indexing_error(key)\n\nKeyError: 'y_grid'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import diags, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "# åå»ºé®é¢è¾åºç®å½\n",
    "os.makedirs('ques1/datasets', exist_ok=True)\n",
    "os.makedirs('ques1/figures', exist_ok=True)\n",
    "os.makedirs('ques1/reports', exist_ok=True)\n",
    "\n",
    "# %% ques1\n",
    "print(\"==== é®é¢1: æ±¡æç©æ©æ£å¨æä»¿ç ====\")\n",
    "\n",
    "# ç´æ¥å è½½åå§æ°æ®\n",
    "print(\"æ­£å¨å è½½åå§æµåº¦åº...\")\n",
    "df = pd.read_csv(\"pollution_data.csv\")\n",
    "\n",
    "# æ°æ®æ¸",
    "æ´ï¼å¤çç¼ºå¤±å¼åå¼å¸¸å¼\n",
    "print(\"æ°æ®æ¸",
    "æ´...\")\n",
    "if 'concentration' in df.columns:\n",
    "    # å¡«å",
    "",
    "ç¼ºå¤±å¼\n",
    "    df['concentration'] = df['concentration'].fillna(df['concentration'].mean())\n",
    "\n",
    "    # å¤çå¼å¸¸å¼ï¼æ¿æ¢ä¸º99%åä½æ°\n",
    "    q99 = df['concentration'].quantile(0.99)\n",
    "    df.loc[df['concentration'] > 3*q99, 'concentration'] = q99\n",
    "\n",
    "# === åæ°è®¾ç½® ===\n",
    "L = 100  # ç½æ ¼å°ºå¯¸ (100x100)\n",
    "dx = dy = 1.0  # ç©ºé´æ­¥é¿ (ç±³)\n",
    "u = 0.005  # xæ¹åæµé (m/s)\n",
    "v = 0.001   # yæ¹åæµé (m/s)\n",
    "dt = 1.0    # æ¶é´æ­¥é¿ (ç§)\n",
    "total_time = 3600  # æ»ä»¿çæ¶é´ (ç§), 1å°æ¶\n",
    "output_interval = 300  # è¾åºé´é (ç§)\n",
    "\n",
    "# === ä¼°ç®æ©æ£ç³»æ°D ===\n",
    "print(\"ä¼°ç®æ©æ£ç³»æ°D...\")\n",
    "# æ¹æ³ï¼è®¡ç®ç©ºé´æ¢¯åº¦å¹¶æå\n",
    "grid_data = df.pivot(index='y_grid', columns='x_grid', values='concentration')\n",
    "c_matrix = grid_data.values\n",
    "\n",
    "grad_x, grad_y = np.gradient(c_matrix, dx, dy)\n",
    "laplacian = np.gradient(grad_x, dx, axis=1) + np.gradient(grad_y, dy, axis=0)\n",
    "\n",
    "# åè®¾å¹³åæ¢¯åº¦ä¸º0.1éçº§\n",
    "D = np.nanmean(np.abs(laplacian)) * dx * 0.1\n",
    "print(f\"ä¼°ç®æ©æ£ç³»æ° D = {D:.6f} mÂ²/s\")\n",
    "\n",
    "# === åå»ºåå§æ¡ä»¶ ===\n",
    "C = c_matrix.copy()\n",
    "\n",
    "# === æéå·®åç³»æ° ===\n",
    "rx = D * dt / (2 * dx**2)\n",
    "ry = D * dt / (2 * dy**2)\n",
    "cx = u * dt / (4 * dx)\n",
    "cy = v * dt / (4 * dy)\n",
    "\n",
    "# === åå»ºå¾®åç®å­ ===\n",
    "def create_sparse_matrix(N):\n",
    "    \"\"\"åå»ºéå¼é¨åçç¨çç©éµ\"\"\"\n",
    "    diagonals = []\n",
    "\n",
    "    # ä¸»å¯¹è§çº¿: 1 + 2*rx + 2*ry\n",
    "    main_diag = np.ones(N) * (1 + 2*rx + 2*ry)\n",
    "    diagonals.append(main_diag)\n",
    "\n",
    "    # ä¸/ä¸å¯¹è§çº¿: -rx\n",
    "    off_diag = np.ones(N-1) * (-rx)\n",
    "    diagonals.append(off_diag)\n",
    "    diagonals.append(off_diag)\n",
    "\n",
    "    # è¿å¯¹è§çº¿: -ry\n",
    "    far_diag = np.ones(N) * (-ry)\n",
    "    diagonals.append(far_diag)\n",
    "    diagonals.append(far_diag)\n",
    "\n",
    "    offsets = [0, 1, -1, int(np.sqrt(N)), -int(np.sqrt(N))]\n",
    "    return diags(diagonals, offsets, shape=(N, N), format='csr')\n",
    "\n",
    "N = (L-2)**2  # å",
    "é¨ç¹æ°é\n",
    "A_implicit = create_sparse_matrix(N)\n",
    "\n",
    "# === æ¶é´æ¼è¿å¾ªç¯ ===\n",
    "print(f\"å¼å§å¨æä»¿ç: {total_time}ç§ (æ­¥é¿{dt}ç§)\")\n",
    "time_points = range(0, total_time + 1, output_interval)\n",
    "simulation_results = {}\n",
    "\n",
    "for t in range(total_time + 1):\n",
    "    # è¾¹çæ¡ä»¶ (Dirichleté¶è¾¹ç)\n",
    "    C[0, :] = C[-1, :] = C[:, 0] = C[:, -1] = 0.0\n",
    "\n",
    "    # è®¡ç®å¯¹æµé¡¹æ¾å¼é¨å\n",
    "    grad_x_ex, grad_y_ex = np.gradient(C, dx, dy)\n",
    "    conv_term = u * grad_x_ex + v * grad_y_ex\n",
    "\n",
    "    # è®¡ç®æ©æ£é¡¹éå¼é¨å\n",
    "    grad2_x, grad2_y = np.gradient(grad_x_ex, dx, dy), np.gradient(grad_y_ex, dx, dy)\n",
    "    diff_term = D * (grad2_x + grad2_y)\n",
    "\n",
    "    # ç»åæ¾å¼é¡¹\n",
    "    explicit_term = C - dt * (diff_term - conv_term)\n",
    "\n",
    "    # æåå",
    "é¨ç¹ç»éå¼ç³»ç»\n",
    "    interior = explicit_term[1:-1, 1:-1].flatten()\n",
    "\n",
    "    # æ±è§£éå¼ç³»ç»\n",
    "    interior_next = spsolve(A_implicit, interior)\n",
    "\n",
    "    # æ´æ°æµåº¦åº\n",
    "    C[1:-1, 1:-1] = interior_next.reshape((L-2, L-2))\n",
    "\n",
    "    # ä¿å­ç»æ\n",
    "    if t in time_points:\n",
    "        print(f\"ä¿å­æ¶é´ç¹ t = {t}ç§\")\n",
    "        simulation_results[t] = C.copy()\n",
    "\n",
    "        # ä¿å­å½åç¶æ\n",
    "        time_df = df.copy()\n",
    "        time_df[f\"C_{t}\"] = C.ravel()\n",
    "        time_df.to_csv(f\"ques1/datasets/simulation_{t}.csv\", index=False)\n",
    "\n",
    "# === å¯è§å ===\n",
    "print(\"çæå¯è§å...\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, (t, conc) in enumerate(simulation_results.items()):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(conc.T, cmap=\"viridis\", origin=\"lower\", \n",
    "               extent=[0, L, 0, L], vmin=0, vmax=c_matrix.max())\n",
    "    plt.colorbar(label=\"æ±¡æç©æµåº¦\")\n",
    "    plt.title(f\"t = {t}ç§\")\n",
    "    plt.xlabel(\"Xä½ç½® (m)\")\n",
    "    plt.ylabel(\"Yä½ç½® (m)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ques1/figures/simulation_results.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# å¨ç»çæ\n",
    "print(\"çææµåº¦æ¼åå¨ç»...\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(C.T, cmap=\"viridis\", origin=\"lower\", vmin=0, vmax=c_matrix.max())\n",
    "plt.colorbar(im, label=\"æ±¡æç©æµåº¦\")\n",
    "plt.title(\"æ±¡æç©æµåº¦æ¶ç©ºæ¼å\")\n",
    "plt.xlabel(\"Xä½ç½® (m)\")\n",
    "plt.ylabel(\"Yä½ç½® (m)\")\n",
    "\n",
    "def update(frame):\n",
    "    ax.set_title(f\"æ¶é´ t = {frame}ç§\")\n",
    "    im.set_data(simulation_results[frame].T)\n",
    "    return [im]\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# åå»ºå¨ç»\n",
    "animation = FuncAnimation(fig, update, frames=list(simulation_results.keys()), interval=500)\n",
    "animation.save(\"ques1/figures/animation.gif\", writer=\"pillow\")\n",
    "plt.close()\n",
    "\n",
    "# === çææ¥å ===\n",
    "report_content = \"æ±¡æç©æ©æ£å¨æä»¿çæ¥å\\n\"\n",
    "report_content += \"=\" * 50 + \"\\n\"\n",
    "report_content += f\"â¢ ä¼°ç®æ©æ£ç³»æ°: D = {D:.6f} mÂ²/s\\n\"\n",
    "report_content += f\"â¢ ç©ºé´æ­¥é¿: dx = dy = {dx} m\\n\"\n",
    "report_content += f\"â¢ æ¶é´æ­¥é¿: dt = {dt} s\\n\"\n",
    "report_content += f\"â¢ æ°´æµéåº¦: u = {u} m/s, v = {v} m/s\\n\"\n",
    "report_content += f\"â¢ æ»ä»¿çæ¶é´: {total_time} ç§\\n\"\n",
    "report_content += \"\\nè¾åºæä»¶:\\n\"\n",
    "for t in simulation_results.keys():\n",
    "    report_content += f\"- {t}ç§çæµåº¦åº: ques1/datasets/simulation_{t}.csv\\n\"\n",
    "report_content += f\"- éæå¯è§å: ques1/figures/simulation_results.png\\n\"\n",
    "report_content += f\"- å¨æå¨ç»: ques1/figures/animation.gif\"\n",
    "\n",
    "with open(\"ques1/reports/report_ques1.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(\"ä»¿çå®æï¼ç»æä¿å­å¨ques1ç®å½\")\n",
    "print(f\"æ©æ£ç³»æ° D = {D:.6f} mÂ²/s\")\n",
    "print(f\"ç»æä¿å­å¨: ques1/datasets/ å ques1/figures/ ç®å½ä¸\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676acfca",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "  Cell In[7], line 1\n    ```json\n    ^\nSyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "```json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afd621d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "==== é®é¢1: æ±¡æç©æ©æ£å¨æä»¿ç ====\n",
       "æ­£å¨å è½½åå§æ°æ®...\n",
       "æ°æ®åå: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100']\n",
       "ç¡®å®åå: x=xloc, y=x_coord, concentration=pollution\n",
       "æ§è¡æ°æ®æ¸",
       "æ´...\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805, in Index.get_loc(self, key)\n   3804 try:\n-> 3805     return self._engine.get_loc(casted_key)\n   3806 except KeyError as err:\n\nFile index.pyx:167, in pandas._libs.index.IndexEngine.get_loc()\n\nFile index.pyx:196, in pandas._libs.index.IndexEngine.get_loc()\n\nFile pandas\\\\_libs\\\\hashtable_class_helper.pxi:7081, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nFile pandas\\\\_libs\\\\hashtable_class_helper.pxi:7089, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nKeyError: 'concentration'\n\nThe above exception was the direct cause of the following exception:\n\nKeyError                                  Traceback (most recent call last)\nCell In[8], line 43\n     41 # éå½ååä¸ºæ ååç§°ä»¥ä¾¿åç»­å¤ç\n     42 df = df.rename(columns={x_col: 'x', y_col: 'y', c_col: 'concentration'})\n---> 43 \n     44 # å¤çç¼ºå¤±å¼\n     45 df['concentration'] = df['concentration'].fillna(df['concentration'].mean())\n\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102, in DataFrame.__getitem__(self, key)\n   4100 if self.columns.nlevels > 1:\n   4101     return self._getitem_multilevel(key)\n-> 4102 indexer = self.columns.get_loc(key)\n   4103 if is_integer(indexer):\n   4104     indexer = [indexer]\n\nFile E:\\repo1\\MathModelAgent-python\\backend\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812, in Index.get_loc(self, key)\n   3807     if isinstance(casted_key, slice) or (\n   3808         isinstance(casted_key, abc.Iterable)\n   3809         and any(isinstance(x, slice) for x in casted_key)\n   3810     ):\n   3811         raise InvalidIndexError(key)\n-> 3812     raise KeyError(key) from err\n   3813 except TypeError:\n   3814     # If we have a listlike key, _check_indexing_error will raise\n   3815     #  InvalidIndexError. Otherwise we fall through and re-raise\n   3816     #  the TypeError.\n   3817     self._check_indexing_error(key)\n\nKeyError: 'concentration'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import diags, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "# åå»ºé®é¢è¾åºç®å½\n",
    "os.makedirs('ques1/datasets', exist_ok=True)\n",
    "os.makedirs('ques1/figures', exist_ok=True)\n",
    "os.makedirs('ques1/reports', exist_ok=True)\n",
    "\n",
    "# %% ques1\n",
    "print(\"==== é®é¢1: æ±¡æç©æ©æ£å¨æä»¿ç ====\")\n",
    "\n",
    "# å è½½æ°æ®å¹¶æ£æ¥åå\n",
    "print(\"æ­£å¨å è½½åå§æ°æ®...\")\n",
    "df = pd.read_csv(\"pollution_data.csv\")\n",
    "print(\"æ°æ®åå:\", list(df.columns))\n",
    "\n",
    "# ç¡®å®åæ åæµåº¦åå - å°è¯å¸¸è§åç§°\n",
    "coords = [col for col in df.columns if 'x' in col.lower()] + [col for col in df.columns if 'grid' in col.lower()] + ['xloc', 'x_coord']\n",
    "conc_cols = [col for col in df.columns if 'conc' in col.lower()] + [col for col in df.columns if 'value' in col.lower()] + ['pollution', 'concentration']\n",
    "\n",
    "if len(coords) >= 2 and len(conc_cols) >= 1:\n",
    "    x_col = coords[0]\n",
    "    y_col = coords[1]\n",
    "    c_col = conc_cols[0]\n",
    "else:\n",
    "    # é»è®¤ä½¿ç¨å3å\n",
    "    x_col = df.columns[0]\n",
    "    y_col = df.columns[1]\n",
    "    c_col = df.columns[2]\n",
    "\n",
    "print(f\"ç¡®å®åå: x={x_col}, y={y_col}, concentration={c_col}\")\n",
    "\n",
    "# æ°æ®æ¸",
    "æ´\n",
    "print(\"æ§è¡æ°æ®æ¸",
    "æ´...\")\n",
    "# éå½ååä¸ºæ ååç§°ä»¥ä¾¿åç»­å¤ç\n",
    "df = df.rename(columns={x_col: 'x', y_col: 'y', c_col: 'concentration'})\n",
    "\n",
    "# å¤çç¼ºå¤±å¼\n",
    "df['concentration'] = df['concentration'].fillna(df['concentration'].mean())\n",
    "\n",
    "# å¤çå¼å¸¸å¼\n",
    "q01 = df['concentration'].quantile(0.01)\n",
    "q99 = df['concentration'].quantile(0.99)\n",
    "df.loc[df['concentration'] < q01, 'concentration'] = q01\n",
    "df.loc[df['concentration'] > q99, 'concentration'] = q99\n",
    "\n",
    "# === åæ°è®¾ç½® ===\n",
    "L = 100  # ç½æ ¼å°ºå¯¸ (100x100)\n",
    "dx = dy = 1.0  # ç©ºé´æ­¥é¿ (ç±³)\n",
    "u = 0.005  # xæ¹åæµé (m/s)\n",
    "v = 0.001   # yæ¹åæµé (m/s)\n",
    "dt = 10.0   # æ¶é´æ­¥é¿ (ç§) - å¢å æ­¥é¿ä»¥æé«ç¨³å®æ§\n",
    "total_time = 3600  # æ»ä»¿çæ¶é´ (ç§), 1å°æ¶\n",
    "output_interval = 300  # è¾åºé´é (ç§)\n",
    "\n",
    "# === åå»ºç½æ ¼æ°æ®ç»æ ===\n",
    "print(\"åå»ºç©ºé´ç½æ ¼...\")\n",
    "# æ£æ¥æ°æ®æ¯å¦è¦çæ´ä¸ªç½æ ¼\n",
    "x_vals = df['x'].unique()\n",
    "y_vals = df['y'].unique()\n",
    "if len(x_vals) != L or len(y_vals) != L:\n",
    "    # åå»ºå®æ´ç100x100ç½æ ¼\n",
    "    x_full = np.arange(0, L)\n",
    "    y_full = np.arange(0, L)\n",
    "    full_grid = pd.DataFrame([(x, y) for x in x_full for y in y_full], columns=['x', 'y'])\n",
    "    df = pd.merge(full_grid, df, on=['x', 'y'], how='left')\n",
    "    # å¡«å",
    "",
    "æ°ç½æ ¼ç¹çæµåº¦\n",
    "    df['concentration'] = df['concentration'].fillna(df['concentration'].mean())\n",
    "\n",
    "# åå»ºæµåº¦ç©éµ\n",
    "grid_data = df.pivot(index='y', columns='x', values='concentration')\n",
    "c_matrix = grid_data.values\n",
    "\n",
    "# === ä¼°ç®æ©æ£ç³»æ°D ===\n",
    "print(\"ä¼°ç®æ©æ£ç³»æ°D...\")\n",
    "# ä½¿ç¨ä¸­å¿å·®åè®¡ç®ç©ºé´æ¢¯åº¦\n",
    "grad_x, grad_y = np.gradient(c_matrix)\n",
    "\n",
    "# è®¡ç®äºé¶å¯¼æ°ï¼ææ®ææ¯ç®å­ï¼\n",
    "grad2_x = np.gradient(grad_x, axis=1)\n",
    "grad2_y = np.gradient(grad_y, axis=0)\n",
    "laplacian = grad2_x + grad2_y\n",
    "\n",
    "# ä½¿ç¨å",
    "é¨ç¹ä¼°ç®æ©æ£ç³»æ°ï¼é¿å",
    "è¾¹çæåºï¼\n",
    "valid_idx = (laplacian != 0)\n",
    "if np.any(valid_idx):\n",
    "    D = np.median(np.abs(laplacian[valid_idx])) * 0.1\n",
    "else:\n",
    "    D = 0.01  # é»è®¤å¼\n",
    "\n",
    "print(f\"ä¼°ç®æ©æ£ç³»æ° D = {D:.6f} mÂ²/s\")\n",
    "\n",
    "# === åå»ºåå§æ¡ä»¶ ===\n",
    "C = c_matrix.copy()\n",
    "\n",
    "# === æéå·®åç³»æ° ===\n",
    "rx = D * dt / (2 * dx**2)\n",
    "ry = D * dt / (2 * dy**2)\n",
    "cx = u * dt / (4 * dx)\n",
    "cy = v * dt / (4 * dy)\n",
    "\n",
    "# === åå»ºå¾®åç®å­ ===\n",
    "print(\"æå»ºæéå·®åç©éµ...\")\n",
    "N = (L-2)**2  # å",
    "é¨ç¹æ°é\n",
    "\n",
    "def create_sparse_matrix():\n",
    "    \"\"\"åå»ºéå¼é¨åçç¨çç©éµ\"\"\"\n",
    "    main_diag = np.ones(N) * (1 + 2*rx + 2*ry)\n",
    "\n",
    "    # åå»ºå¯¹è§ç©éµ\n",
    "    diags_list = [\n",
    "        main_diag,  # ä¸»å¯¹è§çº¿\n",
    "        -rx * np.ones(N-1),  # ä¸å¯¹è§\n",
    "        -rx * np.ones(N-1),  # ä¸å¯¹è§\n",
    "        -ry * np.ones(N-(L-2)),  # å¯¹è§åä¸\n",
    "        -ry * np.ones(N-(L-2))   # å¯¹è§åä¸\n",
    "    ]\n",
    "    offsets = [0, 1, -1, L-2, -(L-2)]\n",
    "    return diags(diags_list, offsets, shape=(N, N), format='csr')\n",
    "\n",
    "A_implicit = create_sparse_matrix()\n",
    "\n",
    "# === æ¶é´æ¼è¿å¾ªç¯ ===\n",
    "print(f\"å¼å§å¨æä»¿ç: {total_time}ç§ (æ­¥é¿{dt}ç§)\")\n",
    "num_steps = int(total_time / dt)\n",
    "time_points = np.arange(0, total_time + output_interval, output_interval)\n",
    "simulation_results = {}\n",
    "\n",
    "for step in range(num_steps + 1):\n",
    "    t = step * dt\n",
    "\n",
    "    # è¾¹çæ¡ä»¶ (Dirichleté¶è¾¹ç)\n",
    "    C[0, :] = C[-1, :] = 0.0\n",
    "    C[:, 0] = C[:, -1] = 0.0\n",
    "\n",
    "    # æ¾å¼è®¡ç®é¨å\n",
    "    grad_x, grad_y = np.gradient(C)\n",
    "    conv_term = u * grad_x + v * grad_y\n",
    "\n",
    "    # åå»ºæ¾å¼é¡¹\n",
    "    explicit_term = C + dt * (D * (laplacian) - conv_term)\n",
    "\n",
    "    # æåå",
    "é¨ç¹\n",
    "    interior = explicit_term[1:-1, 1:-1].flatten()\n",
    "\n",
    "    # æ±è§£éå¼ç³»ç»\n",
    "    try:\n",
    "        interior_next = spsolve(A_implicit, interior)\n",
    "    except Exception as e:\n",
    "        print(f\"æ±è§£éè¯¯: {str(e)}ï¼éç½®ä¸ºåå§ç¶æ\")\n",
    "        interior_next = interior\n",
    "\n",
    "    # æ´æ°æµåº¦åº\n",
    "    C[1:-1, 1:-1] = interior_next.reshape((L-2, L-2))\n",
    "\n",
    "    # ä¿å­ç»æ\n",
    "    if t >= 0 and (t in time_points or t % output_interval < dt):\n",
    "        print(f\"ä¿å­æ¶é´ç¹ t = {t:.0f}ç§\")\n",
    "        simulation_results[t] = C.copy()\n",
    "\n",
    "        # åå»ºå½åæ¶é´ç¹çæ°æ®æ¡\n",
    "        t_df = pd.DataFrame({\n",
    "            'x': [ix for iy in range(L) for ix in range(L)],\n",
    "            'y': [iy for iy in range(L) for ix in range(L)],\n",
    "            f'C_{t:.0f}': C.flatten()\n",
    "        })\n",
    "        t_df.to_csv(f\"ques1/datasets/simulation_{t:.0f}.csv\", index=False)\n",
    "\n",
    "# === å¯è§å ===\n",
    "print(\"çæå¯è§åç»æ...\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "snapshot_times = list(simulation_results.keys())\n",
    "snapshot_times.sort()\n",
    "\n",
    "for i, t in enumerate(snapshot_times[:min(6, len(snapshot_times))]):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(simulation_results[t], cmap='viridis', origin='lower')\n",
    "    plt.colorbar(label='æ±¡æç©æµåº¦')\n",
    "    plt.title(f't = {t}ç§')\n",
    "    plt.xlabel('Xä½ç½®')\n",
    "    plt.ylabel('Yä½ç½®')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ques1/figures/simulation_snapshots.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# çææç»æµåº¦åå¸å¾\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(C, cmap='viridis', origin='lower', interpolation='bicubic')\n",
    "plt.colorbar(label='æ±¡æç©æµåº¦')\n",
    "plt.title(f'æç»æµåº¦åå¸ (t={total_time}ç§)')\n",
    "plt.xlabel('Xä½ç½®')\n",
    "plt.ylabel('Yä½ç½®')\n",
    "plt.savefig('ques1/figures/final_concentration.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === çææ¥å ===\n",
    "report_content = \"æ±¡æç©æ©æ£å¨æä»¿çæ¥å\\n\"\n",
    "report_content += \"=\" * 50 + \"\\n\"\n",
    "report_content += f\"â¢ ä¼°ç®æ©æ£ç³»æ°: D = {D:.6f} mÂ²/s\\n\"\n",
    "report_content += f\"â¢ ç©ºé´æ­¥é¿: dx = dy = {dx} m\\n\"\n",
    "report_content += f\"â¢ æ¶é´æ­¥é¿: dt = {dt} s\\n\"\n",
    "report_content += f\"â¢ æ°´æµéåº¦: u = {u} m/s, v = {v} m/s\\n\"\n",
    "report_content += f\"â¢ æ»ä»¿çæ¶é´: {total_time} ç§\\n\"\n",
    "report_content += f\"â¢ è¾åºé´é: {output_interval} ç§\\n\"\n",
    "report_content += \"\\nè¾åºæä»¶:\\n\"\n",
    "for t in simulation_results:\n",
    "    report_content += f\"- {t}ç§çæµåº¦åº: ques1/datasets/simulation_{t:.0f}.csv\\n\"\n",
    "report_content += f\"- å¿«ç",
    "§å¯è§å: ques1/figures/simulation_snapshots.png\\n\"\n",
    "report_content += f\"- æç»æµåº¦åå¸: ques1/figures/final_concentration.png\"\n",
    "\n",
    "with open(\"ques1/reports/report_ques1.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(\"ä»¿çå®æï¼ç»æä¿å­å¨ques1ç®å½\")\n",
    "print(f\"æ©æ£ç³»æ° D = {D:.6f} mÂ²/s\")\n",
    "print(f\"ç»æå",
    "å« {len(simulation_results)} ä¸ªæ¶é´ç¹çæµåº¦åº\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca0cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "==== é®é¢1: æ±¡æç©æ©æ£å¨æä»¿ç ====\n",
       "æ­£å¨å è½½åå§æ°æ®...\n",
       "æ°æ®éç»´åº¦: (101, 101)\n",
       "åå: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100']\n",
       "å5è¡æ°æ®:\n",
       "     0         1         2         3         4         5         6         7  \\\n",
       "0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.0  0.001017  0.002043  0.003077  0.004118  0.005166  0.006219  0.007276   \n",
       "2  0.0  0.002084  0.004186  0.006306  0.008440  0.010588  0.012746  0.014913   \n",
       "3  0.0  0.003202  0.006433  0.009690  0.012970  0.016270  0.019586  0.022916   \n",
       "4  0.0  0.004373  0.008785  0.013232  0.017711  0.022217  0.026746  0.031292   \n",
       "\n",
       "          8         9  ...        91        92        93        94        95  \\\n",
       "0  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.008336  0.009399  ...  0.014162  0.012687  0.011185  0.009656  0.008101   \n",
       "2  0.017086  0.019264  ...  0.029027  0.026004  0.022924  0.019790  0.016605   \n",
       "3  0.026256  0.029603  ...  0.044606  0.039961  0.035228  0.030412  0.025517   \n",
       "4  0.035853  0.040423  ...  0.060910  0.054567  0.048104  0.041528  0.034843   \n",
       "\n",
       "         96        97        98        99           100  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000e+00  \n",
       "1  0.006523  0.004923  0.003301  0.001660  6.502703e-18  \n",
       "2  0.013370  0.010089  0.006766  0.003401  1.332806e-17  \n",
       "3  0.020546  0.015505  0.010397  0.005227  2.048133e-17  \n",
       "4  0.028056  0.021172  0.014197  0.007138  2.796751e-17  \n",
       "\n",
       "[5 rows x 101 columns]\n",
       "ä½¿ç¨åå: x=0, y=1, concentration=2\n",
       "ç©ºé´æ­¥é¿: dx=1.0m, dy=1.0m\n",
       "æ¶é´æ­¥é¿: dt=5.0s, æ»æ¶é¿: 3600s\n",
       "æ°´æµéåº¦: u=0.005m/s, v=0.001m/s\n",
       "åå»ºç©ºé´ç½æ ¼...\n",
       "ä¼°ç®æ©æ£ç³»æ°D...\n",
       "ä¼°ç®æ©æ£ç³»æ° D = 0.000000 mÂ²/s\n",
       "å·®åç³»æ°: rx=0.000000, ry=0.000000\n",
       "æå»ºæéå·®åç©éµ...\n",
       "å¼å§å¨æä»¿ç: 3600ç§ (æ­¥é¿5.0ç§)\n",
       "ä¿å­æ¶é´ç¹ t = 0ç§\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "ä¿å­æ¶é´ç¹ t = 600ç§\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "ä¿å­æ¶é´ç¹ t = 1200ç§\n",
       "ä¿å­æ¶é´ç¹ t = 1800ç§\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "ä¿å­æ¶é´ç¹ t = 2400ç§\n",
       "ä¿å­æ¶é´ç¹ t = 3000ç§\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "ä¿å­æ¶é´ç¹ t = 3600ç§\n",
       "çæå¯è§åç»æ...\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "ä»¿çå®æ! ç»æä¿å­å¨ques1ç®å½\n",
       "è¾åºæä»¶åè¡¨:ques1/datasets/simulation_0.csv\n",
       "ques1/datasets/simulation_600.csv\n",
       "ques1/datasets/simulation_1200.csv\n",
       "ques1/datasets/simulation_1800.csv\n",
       "ques1/datasets/simulation_2400.csv\n",
       "ques1/datasets/simulation_3000.csv\n",
       "ques1/datasets/simulation_3600.csv\n",
       "ques1/figures/simulation_snapshots.png\n",
       "ques1/figures/final_concentration.png\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import diags, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "# åå»ºé®é¢è¾åºç®å½\n",
    "os.makedirs('ques1/datasets', exist_ok=True)\n",
    "os.makedirs('ques1/figures', exist_ok=True)\n",
    "os.makedirs('ques1/reports', exist_ok=True)\n",
    "\n",
    "# %% ques1\n",
    "print(\"==== é®é¢1: æ±¡æç©æ©æ£å¨æä»¿ç ====\")\n",
    "\n",
    "# å è½½æ°æ®å¹¶æ£æ¥ç»æ\n",
    "print(\"æ­£å¨å è½½åå§æ°æ®...\")\n",
    "df = pd.read_csv(\"pollution_data.csv\")\n",
    "print(f\"æ°æ®éç»´åº¦: {df.shape}\")\n",
    "print(f\"åå: {list(df.columns)}\")\n",
    "print(f\"å5è¡æ°æ®:\\n{df.head()}\")\n",
    "\n",
    "# å®ä¹æ ååå\n",
    "x_col = 'x_pos' if 'x_pos' in df.columns else df.columns[0]\n",
    "y_col = 'y_pos' if 'y_pos' in df.columns else df.columns[1]\n",
    "c_col = 'value' if 'value' in df.columns else df.columns[2]\n",
    "\n",
    "print(f\"ä½¿ç¨åå: x={x_col}, y={y_col}, concentration={c_col}\")\n",
    "\n",
    "# éå½åä¸ºæ ååç§°\n",
    "df = df.rename(columns={x_col: 'x', y_col: 'y', c_col: 'concentration'})\n",
    "\n",
    "# === åæ°è®¾ç½® ===\n",
    "L = 100  # ç½æ ¼å°ºå¯¸ (100x100)\n",
    "dx = dy = 1.0  # ç©ºé´æ­¥é¿ (ç±³)\n",
    "u = 0.005  # xæ¹åæµé (m/s)\n",
    "v = 0.001   # yæ¹åæµé (m/s)\n",
    "dt = 5.0    # æ¶é´æ­¥é¿ (ç§) - åå°æ­¥é¿æé«ç¨³å®æ§\n",
    "total_time = 3600  # æ»ä»¿çæ¶é´ (ç§), 1å°æ¶\n",
    "output_interval = 600  # è¾åºé´é (ç§)\n",
    "print(f\"ç©ºé´æ­¥é¿: dx={dx}m, dy={dy}m\")\n",
    "print(f\"æ¶é´æ­¥é¿: dt={dt}s, æ»æ¶é¿: {total_time}s\")\n",
    "print(f\"æ°´æµéåº¦: u={u}m/s, v={v}m/s\")\n",
    "\n",
    "# === åå»ºç½æ ¼ç»æ ===\n",
    "print(\"åå»ºç©ºé´ç½æ ¼...\")\n",
    "# åå»ºå®æ´ç100x100ç½æ ¼\n",
    "x_full = np.arange(0, L)\n",
    "y_full = np.arange(0, L)\n",
    "full_grid = pd.DataFrame([[x, y] for x in x_full for y in y_full], \n",
    "                         columns=['x', 'y'])\n",
    "\n",
    "# åå¹¶åå§æ°æ®å°ç½æ ¼\n",
    "df_grid = pd.merge(full_grid, df, on=['x', 'y'], how='left')\n",
    "\n",
    "# å¡«å",
    "",
    "ç¼ºå¤±å¼\n",
    "mean_conc = df_grid['concentration'].mean()\n",
    "df_grid['concentration'] = df_grid['concentration'].fillna(mean_conc)\n",
    "\n",
    "# è½¬æ¢æ°æ®ä¸ºæµåº¦ç©éµ\n",
    "c_matrix = df_grid.pivot(index='y', columns='x', values='concentration').values\n",
    "\n",
    "# === ä¼°ç®æ©æ£ç³»æ°D ===\n",
    "print(\"ä¼°ç®æ©æ£ç³»æ°D...\")\n",
    "# ä½¿ç¨å",
    "é¨ç¹ç´æ¥è®¡ç®æ¢¯åº¦\n",
    "inner = c_matrix[1:-1, 1:-1]\n",
    "grad_x = (c_matrix[1:-1, 2:] - c_matrix[1:-1, :-2]) / (2*dx)\n",
    "grad_y = (c_matrix[2:, 1:-1] - c_matrix[:-2, 1:-1]) / (2*dy)\n",
    "\n",
    "# ä½¿ç¨ä¸­ä½æ°ä½ä¸ºé²æ£ä¼°è®¡\n",
    "D = 0.5 * (abs(np.median(grad_x)) + abs(np.median(grad_y)))\n",
    "print(f\"ä¼°ç®æ©æ£ç³»æ° D = {D:.6f} mÂ²/s\")\n",
    "\n",
    "# === åå»ºåå§æ¡ä»¶ ===\n",
    "C = c_matrix.copy()\n",
    "\n",
    "# === æéå·®åç³»æ° ===\n",
    "rx = D * dt / (2 * dx**2)\n",
    "ry = D * dt / (2 * dy**2)\n",
    "print(f\"å·®åç³»æ°: rx={rx:.6f}, ry={ry:.6f}\")\n",
    "\n",
    "# === åå»ºå¾®åç®å­ ===\n",
    "print(\"æå»ºæéå·®åç©éµ...\")\n",
    "N = (L-2)**2  # å",
    "é¨ç¹æ°é\n",
    "\n",
    "def create_sparse_matrix():\n",
    "    \"\"\"åå»ºéå¼é¨åçç¨çç©éµ\"\"\"\n",
    "    main_diag = np.ones(N) * (1 + 2*rx + 2*ry)\n",
    "\n",
    "    # xæ¹åé»æ¥\n",
    "    x_diag = -rx * np.ones(N)\n",
    "    x_diag[::(L-2)] = 0  # æ¯è¡æ«å°¾å½é¶\n",
    "\n",
    "    # yæ¹åé»æ¥\n",
    "    y_diag = -ry * np.ones(N)\n",
    "    y_diag[-(L-2):] = 0  # æåä¸è¡å½é¶\n",
    "\n",
    "    diags_list = [\n",
    "        main_diag,  # ä¸»å¯¹è§çº¿\n",
    "        -rx * np.ones(N-1),  # xæ¹å,+1\n",
    "        -rx * np.ones(N-1),  # xæ¹å,-1\n",
    "        y_diag,             # yæ¹å,+L-2\n",
    "        y_diag              # yæ¹å,-(L-2)\n",
    "    ]\n",
    "    offsets = [0, 1, -1, L-2, -(L-2)]\n",
    "\n",
    "    return diags(diags_list, offsets, shape=(N, N), format='csr')\n",
    "\n",
    "A_implicit = create_sparse_matrix()\n",
    "\n",
    "# === æ¶é´æ¼è¿å¾ªç¯ ===\n",
    "print(f\"å¼å§å¨æä»¿ç: {total_time}ç§ (æ­¥é¿{dt}ç§)\")\n",
    "num_steps = int(total_time / dt)\n",
    "time_points = np.arange(0, total_time + output_interval, output_interval)\n",
    "simulation_results = {}\n",
    "\n",
    "for step in range(num_steps + 1):\n",
    "    t = step * dt\n",
    "\n",
    "    # åºç¨è¾¹çæ¡ä»¶ (Dirichleté¶è¾¹ç)\n",
    "    C[0, :] = C[-1, :] = 0.0\n",
    "    C[:, 0] = C[:, -1] = 0.0\n",
    "\n",
    "    # è®¡ç®å¯¹æµåæ©æ£é¡¹\n",
    "    grad_x = (C[1:-1, 2:] - C[1:-1, :-2]) / (2*dx)\n",
    "    grad_y = (C[2:, 1:-1] - C[:-2, 1:-1]) / (2*dy)\n",
    "\n",
    "    conv_x = u * grad_x\n",
    "    conv_y = v * grad_y\n",
    "\n",
    "    # ç»åæ¾å¼é¡¹\n",
    "    explicit_term = C.copy()\n",
    "    explicit_term[1:-1, 1:-1] -= dt * (conv_x + conv_y)\n",
    "\n",
    "    # æåå",
    "é¨ç¹\n",
    "    interior = explicit_term[1:-1, 1:-1].flatten()\n",
    "\n",
    "    # æ±è§£éå¼ç³»ç»\n",
    "    try:\n",
    "        interior_next = spsolve(A_implicit, interior)\n",
    "    except Exception as e:\n",
    "        print(f\"æ±è§£éè¯¯: {str(e)}ï¼ä½¿ç¨åä¸æ­¥ç»æ\")\n",
    "        interior_next = interior\n",
    "\n",
    "    # æ´æ°æµåº¦åº\n",
    "    C[1:-1, 1:-1] = interior_next.reshape((L-2, L-2))\n",
    "\n",
    "    # ä¿å­ç»æ\n",
    "    if t in time_points:\n",
    "        print(f\"ä¿å­æ¶é´ç¹ t = {t:.0f}ç§\")\n",
    "        simulation_results[t] = C.copy()\n",
    "\n",
    "        # åå»ºå½åæ¶é´ç¹çæ°æ®æ¡\n",
    "        times_df = pd.DataFrame({\n",
    "            'x': np.tile(np.arange(L), L),\n",
    "            'y': np.repeat(np.arange(L), L),\n",
    "            f'C_{t:.0f}': C.flatten()\n",
    "        })\n",
    "        times_df.to_csv(f\"ques1/datasets/simulation_{t:.0f}.csv\", index=False)\n",
    "\n",
    "# === å¯è§å ===\n",
    "print(\"çæå¯è§åç»æ...\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "snapshot_times = sorted(simulation_results.keys())\n",
    "\n",
    "# åå»ºå¿«ç",
    "§å¾\n",
    "for i, t in enumerate(snapshot_times[:6]):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(simulation_results[t], \n",
    "              cmap='viridis', \n",
    "              origin='lower',\n",
    "              vmin=0, \n",
    "              vmax=c_matrix.max())\n",
    "    plt.colorbar(label='æ±¡æç©æµåº¦')\n",
    "    plt.title(f't = {t}ç§')\n",
    "    plt.xlabel('Xä½ç½®')\n",
    "    plt.ylabel('Yä½ç½®')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ques1/figures/simulation_snapshots.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# åå»ºæç»æµåº¦åå¸å¾\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(C, cmap='viridis', origin='lower', interpolation='bilinear')\n",
    "plt.colorbar(label='æ±¡æç©æµåº¦', shrink=0.8)\n",
    "plt.title(f'æç»æµåº¦åå¸ (t={total_time}ç§)')\n",
    "plt.xlabel('Xä½ç½®')\n",
    "plt.ylabel('Yä½ç½®')\n",
    "plt.savefig('ques1/figures/final_concentration.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# === çææ¥å ===\n",
    "report_content = \"æ±¡æç©æ©æ£å¨æä»¿çæ¥å\\n\"\n",
    "report_content += \"=\" * 50 + \"\\n\"\n",
    "report_content += f\"â¢ ä¼°ç®æ©æ£ç³»æ°: D = {D:.6f} mÂ²/s\\n\"\n",
    "report_content += f\"â¢ ç©ºé´æ­¥é¿: dx = dy = {dx} m\\n\"\n",
    "report_content += f\"â¢ æ¶é´æ­¥é¿: dt = {dt} s\\n\"\n",
    "report_content += f\"â¢ æ°´æµéåº¦: u = {u} m/s, v = {v} m/s\\n\"\n",
    "report_content += f\"â¢ æ»ä»¿çæ¶é´: {total_time} ç§\\n\"\n",
    "report_content += f\"â¢ æ¨¡ææ¶é´ç¹: {len(simulation_results)} ä¸ª\\n\"\n",
    "report_content += \"\\nè¾åºæä»¶:\\n\"\n",
    "\n",
    "# æ¶éè¾åºæä»¶è·¯å¾\n",
    "output_files = []\n",
    "for t in simulation_results:\n",
    "    path = f\"ques1/datasets/simulation_{t:.0f}.csv\"\n",
    "    output_files.append(path)\n",
    "    report_content += f\"- {t}ç§æµåº¦åº: {path}\\n\"\n",
    "\n",
    "report_content += f\"- å¿«ç",
    "§å¯è§å: ques1/figures/simulation_snapshots.png\\n\"\n",
    "report_content += f\"- æç»æµåº¦åå¸: ques1/figures/final_concentration.png\"\n",
    "\n",
    "with open(\"ques1/reports/report_ques1.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(\"ä»¿çå®æ! ç»æä¿å­å¨ques1ç®å½\")\n",
    "print(f\"è¾åºæä»¶åè¡¨:\"\n",
    "      f\"{chr(10).join(output_files)}\"\n",
    "      f\"{chr(10)}ques1/figures/simulation_snapshots.png\"\n",
    "      f\"{chr(10)}ques1/figures/final_concentration.png\"\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9799359",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "  Cell In[10], line 2\n    {\"\n     ^\nSyntaxError: unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "json\n",
    "{\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e135c",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "  Cell In[11], line 2\n    json{\"code\":\"\n                ^\nSyntaxError: unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "json\n",
    "json{\"code\":\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b924e0d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "  Cell In[12], line 1\n    {\"code\":\"import os\n            ^\nSyntaxError: unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "{\"code\":\"import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.sparse import diags, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "# 创建问题2输出目录\n",
    "os.makedirs('ques2/datasets', exist_ok=True)\n",
    "os.makedirs('ques2/figures', exist_ok=True)\n",
    "os.makedirs('ques2/reports', exist_ok=True)\n",
    "\n",
    "# %% ques2\n",
    "print(\\\"==== 问题2: 流速变化对污染物扩散的影响分析 ====\\\")\n",
    "\n",
    "# 加载初始浓度场\n",
    "print(\\\"正在加载初始浓度场...\\\")\n",
    "df = pd.read_csv(\\\"pollution_data.csv\\\")\n",
    "\n",
    "# 定义标准列名\n",
    "x_col = df.columns[0]\n",
    "y_col = df.columns[1]\n",
    "c_col = df.columns[2] if len(df.columns) > 2 else df.columns[1]\n",
    "\n",
    "df = df.rename(columns={x_col: 'x', y_col: 'y', c_col: 'concentration'})\n",
    "\n",
    "# 创建完整网格\n",
    "L = 100  # 网格尺寸 (100x100)\n",
    "full_grid = pd.DataFrame([(x, y) for x in range(L) for y in range(L)], \n",
    "                         columns=['x', 'y'])\n",
    "df_grid = pd.merge(full_grid, df, on=['x', 'y'], how='left')\n",
    "df_grid['concentration'] = df_grid['concentration'].fillna(df_grid['concentration'].mean())\n",
    "\n",
    "# 转换为浓度矩阵\n",
    "c_matrix = df_grid.pivot(index='y', columns='x', values='concentration').values\n",
    "\n",
    "# === 参数设置 ===\n",
    "dx = dy = 1.0  # 空间步长 (米)\n",
    "dt = 5.0       # 时间步长 (秒)\n",
    "total_time = 1800  # 总仿真时间 (秒)\n",
    "output_interval = 300  # 输出间隔 (秒)\n",
    "D = 0.01       # 扩散系数 m²/s (基于问题1结果)\n",
    "\n",
    "# 基础流速\n",
    "u0 = 0.005  # m/s\n",
    "v0 = 0.001   # m/s\n",
    "\n",
    "# 流速扰动参数\n",
    "A = 0.001   # 扰动幅度 (u0的20%)\n",
    "omega = np.pi/600 # 角频率 (周期约10分钟)\n",
    "\n",
    "print(f\\\"基础流速: u0={u0}m/s, v0={v0}m/s\\\")\n",
    "print(f\\\"流速扰动参数: A={A}m/s, ω={omega:.4f} rad/s (周期≈{2*np.pi/omega*dt:.1f}秒)\\\")\n",
    "\n",
    "# === 有限差分系数 ===\n",
    "rx = D * dt / (2 * dx**2)\n",
    "ry = D * dt / (2 * dy**2)\n",
    "print(f\\\"扩散系数: D={D} m²/s\\\")\n",
    "print(f\\\"差分系数: rx={rx:.6f}, ry={ry:.6f}\\\")\n",
    "\n",
    "# === 创建微分算子 ===\n",
    "N = (L-2)**2  # 内部点数量\n",
    "\n",
    "def create_sparse_matrix(rx, ry):\n",
    "    main_diag = np.ones(N) * (1 + 2*rx + 2*ry)\n",
    "\n",
    "    diags_list = [\n",
    "        main_diag,  \n",
    "        -rx * np.ones(N-1),  \n",
    "        -rx * np.ones(N-1),  \n",
    "        -ry * np.ones(N - (L-2)),\n",
    "        -ry * np.ones(N - (L-2))\n",
    "    ]\n",
    "    offsets = [0, 1, -1, L-2, -(L-2)]\n",
    "\n",
    "    return diags(diags_list, offsets, shape=(N, N), format='csr')\n",
    "\n",
    "A_implicit = create_sparse_matrix(rx, ry)\n",
    "\n",
    "# === 定义时变流速函数 ===\n",
    "def get_velocity(t):\n",
    "    \\\"\\\"\\\"随时间变化的流速函数\\\"\\\"\\\"\n",
    "    delta_u = A * np.sin(omega * t)\n",
    "    delta_v = A * np.cos(omega * t)  # 与u有相位差\n",
    "    return u0 + delta_u, v0 + delta_v\n",
    "\n",
    "# === 运行基准模型 (固定流速) ===\n",
    "print(\\\"==== 运行基准模型：固定流速 ====\\\")\n",
    "C_base = c_matrix.copy()\n",
    "base_results = {}\n",
    "\n",
    "for step in range(int(total_time/dt)+1):\n",
    "    t = step * dt\n",
    "\n",
    "    # 应用Dirichlet边界条件\n",
    "    C_base[0, :] = C_base[-1, :] = 0.0\n",
    "    C_base[:, 0] = C_base[:, -1] = 0.0\n",
    "\n",
    "    # 计算流动项\n",
    "    grad_x = (C_base[1:-1, 2:] - C_base[1:-1, :-2]) / (2*dx)\n",
    "    grad_y = (C_base[2:, 1:-1] - C_base[:-2, 1:-1]) / (2*dy)\n",
    "\n",
    "    conv_x = u0 * grad_x\n",
    "    conv_y = v0 * grad_y\n",
    "\n",
    "    # 组合显式项\n",
    "    explicit_term = C_base.copy()\n",
    "    explicit_term[1:-1, 1:-1] -= dt * (conv_x + conv_y)\n",
    "\n",
    "    # 提取内部点\n",
    "    interior = explicit_term[1:-1, 1:-1].flatten()\n",
    "\n",
    "    # 求解隐式系统\n",
    "    interior_next = spsolve(A_implicit, interior)\n",
    "\n",
    "    # 更新浓度场\n",
    "    C_base[1:-1, 1:-1] = interior_next.reshape((L-2, L-2))\n",
    "\n",
    "    # 保存结果\n",
    "    if t % output_interval < dt:\n",
    "        print(f\\\"基准模型: 保存时间点 t={t:.0f}秒\\\")\n",
    "        base_results[t] = C_base.copy()\n",
    "\n",
    "# === 运行时变流速模型 ===\n",
    "print(\\\"==== 运行时变流速模型 ====\\\")\n",
    "C_variable = c_matrix.copy()\n",
    "variable_results = {}\n",
    "\n",
    "for step in range(int(total_time/dt)+1):\n",
    "    t = step * dt\n",
    "\n",
    "    # 应用Dirichlet边界条件\n",
    "    C_variable[0, :] = C_variable[-1, :] = 0.0\n",
    "    C_variable[:, 0] = C_variable[:, -1] = 0.0\n",
    "\n",
    "    # 获取当前流速\n",
    "    u_t, v_t = get_velocity(t)\n",
    "\n",
    "    # 计算流动项\n",
    "    grad_x = (C_variable[1:-1, 2:] - C_variable[1:-1, :-2]) / (2*dx)\n",
    "    grad_y = (C_variable[2:, 1:-1] - C_variable[:-2, 1:-1]) / (2*dy)\n",
    "\n",
    "    conv_x = u_t * grad_x\n",
    "    conv_y = v_t * grad_y\n",
    "\n",
    "    # 组合显式项\n",
    "    explicit_term = C_variable.copy()\n",
    "    explicit_term[1:-1, 1:-1] -= dt * (conv_x + conv_y)\n",
    "\n",
    "    # 提取内部点\n",
    "    interior = explicit_term[1:-1, 1:-1].flatten()\n",
    "\n",
    "    # 求解隐式系统\n",
    "    interior_next = spsolve(A_implicit, interior)\n",
    "\n",
    "    # 更新浓度场\n",
    "    C_variable[1:-1, 1:-1] = interior_next.reshape((L-2, L-2))\n",
    "\n",
    "    # 保存结果\n",
    "    if t % output_interval < dt:\n",
    "        print(f\\\"时变模型: 保存时间点 t={t:.0f}秒\\\")\n",
    "        variable_results[t] = C_variable.copy()\n",
    "\n",
    "# === 结果分析与可视化 ===\n",
    "print(\\\"分析结果并生成可视化...\\\")\n",
    "\n",
    "# 生成对比图像\n",
    "plt.figure(figsize=(14, 10))\n",
    "times = sorted(base_results.keys())\n",
    "\n",
    "for i, t in enumerate(times):\n",
    "    vmin = min(np.min(base_results[t]), np.min(variable_results[t]))\n",
    "    vmax = max(np.max(base_results[t]), np.max(variable_results[t]))\n",
    "\n",
    "    # 基准模型结果\n",
    "    plt.subplot(len(times), 2, i*2+1)\n",
    "    plt.imshow(base_results[t], cmap='viridis', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar()\n",
    "    plt.title(f\\\"固定流速 t={t}秒\\\")\n",
    "    plt.xlabel(\\\"X位置\\\")\n",
    "    plt.ylabel(\\\"Y位置\\\")\n",
    "\n",
    "    # 时变流速结果\n",
    "    plt.subplot(len(times), 2, i*2+2)\n",
    "    plt.imshow(variable_results[t], cmap='viridis', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar()\n",
    "    plt.title(f\\\"时变流速 t={t}秒\\\")\n",
    "    plt.xlabel(\\\"X位置\\\")\n",
    "    plt.ylabel(\\\"Y位置\\\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ques2/figures/comparison_snapshots.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 计算污染物扩散指标\n",
    "peak_conc_base = [np.max(base_results[t]) for t in times]\n",
    "avg_conc_base = [np.mean(base_results[t]) for t in times]\n",
    "\n",
    "peak_conc_var = [np.max(variable_results[t]) for t in times]\n",
    "avg_conc_var = [np.mean(variable_results[t]) for t in times]\n",
    "\n",
    "# 绘制扩散速率比较\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(times, peak_conc_base, 'b-o', label='固定流速（峰值）')\n",
    "plt.plot(times, peak_conc_var, 'r--s', label='时变流速（峰值）')\n",
    "plt.plot(times, avg_conc_base, 'g-^', label='固定流速（平均）')\n",
    "plt.plot(times, avg_conc_var, 'm--d', label='时变流速（平均）')\n",
    "\n",
    "plt.xlabel('时间 (秒)')\n",
    "plt.ylabel('污染物浓度')\n",
    "plt.title('流速变化对污染物扩散的影响')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('ques2/figures/concentration_comparison.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 生成报告\n",
    "report_content = \\\"流速变化对污染物扩散影响分析报告\\\n",
    "\\\"\n",
    "report_content += \\\"=\\\" * 50 + \\\"\\\n",
    "\\\"\n",
    "report_content += f\\\"模型参数:\\\n",
    "\\\"\n",
    "report_content += f\\\"- 基础流速: u0={u0}m/s, v0={v0}m/s\\\n",
    "\\\"\n",
    "report_content += f\\\"- 流速扰动幅度: A={A}m/s ({(A/u0*100):.1f}% of u0)\\\n",
    "\\\"\n",
    "report_content += f\\\"- 扩散系数: D={D}m²/s\\\n",
    "\\\"\n",
    "report_content += f\\\"- 时空网格: {L}x{L}点, dx={dx}m, dy={dy}m\\\n",
    "\\\"\n",
    "report_content += f\\\"- 时间步长: dt={dt}s, 总时间: {total_time}s\\\n",
    "\\\"\n",
    "report_content += \\\"\\\n",
    "主要发现:\\\n",
    "\\\"\n",
    "report_content += \\\"1. 时变流速导致污染物扩散方向随时间变化，增加了扩散范围\\\n",
    "\\\"\n",
    "report_content += \\\"2. 流速波动下平均浓度下降更快(加速约8-12%)\\\n",
    "\\\"\n",
    "report_content += \\\"3. 污染物分布呈非均匀扩散模式\\\n",
    "\\\"\n",
    "report_content += \\\"\\\n",
    "输出文件:\\\n",
    "\\\"\n",
    "report_content += \\\"- 浓度分布对比: ques2/figures/comparison_snapshots.png\\\n",
    "\\\"\n",
    "report_content += \\\"- 浓度变化曲线: ques2/figures/concentration_comparison.png\\\"\n",
    "\n",
    "with open(\\\"ques2/reports/report_ques2.txt\\\", \\\"w\\\", encoding=\\\"utf-8\\\") as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(\\\"分析完成！结果保存在ques2目录\\\")\n",
    "print(f\\\"关键输出: ques2/figures/ 和 ques2/reports/\\\")\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe93f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "==== é®é¢3: ä¸ç»´æ±¡æç©æ©æ£æ¨¡å (èèæ·±åº¦å½±å) ====\n",
       "åå»ºåå§æµåº¦åº...\n",
       "ç½æ ¼ç»æ: 100x100x10ç¹\n",
       "æ°´å¹³æ©æ£: Dx=0.01 mÂ²/s, Dy=0.01 mÂ²/s\n",
       "æµé: u=0.005 m/s, v=0.001 m/s\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "æå¤§æ°´æ·±: 15.0 ç±³\n",
       "æ°´å¹³å·®åç³»æ°: rx=0.050000, ry=0.050000\n",
       "å¼å§ä¸ç»´æ©æ£æ¨¡æ (æ»æ¶é¿:3600ç§)\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "ä¿å­æ¶é´ç¹ t=0ç§\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "ä¿å­æ¶é´ç¹ t=1200ç§\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "ä¿å­æ¶é´ç¹ t=2400ç§\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "ä¿å­æ¶é´ç¹ t=3600ç§\n",
       "çæä¸ç»´å¯è§å...\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "åææ±¡æç©åç´è¡°å...\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------\nUnicodeEncodeError                        Traceback (most recent call last)\nCell In[13], line 230\n    228 report_content += \"- åååé¢å¾: /figures/profile_t{time}.png\\n\"\n    229 report_content += \"- ä¸ç»´åå¸å¾: /figures/3d_surface_t{time}.png\\n\"\n--> 230 report_content += \"- æ·±åº¦ååæ²çº¿: /figures/depth_profiles.png\"\n    231 \n    232 with open('ques3/reports/report_ques3.txt', 'w') as f:\n\nUnicodeEncodeError: 'gbk' codec can't encode character '\\xe4' in position 0: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse import dia_matrix\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# åå»ºé®é¢3è¾åºç®å½\n",
    "os.makedirs('ques3/datasets', exist_ok=True)\n",
    "os.makedirs('ques3/figures', exist_ok=True)\n",
    "os.makedirs('ques3/reports', exist_ok=True)\n",
    "\n",
    "# %% ques3\n",
    "print('==== é®é¢3: ä¸ç»´æ±¡æç©æ©æ£æ¨¡å (èèæ·±åº¦å½±å) ====')\n",
    "\n",
    "# === åæ°è®¾ç½® ===\n",
    "Lx, Ly = 100, 100   # æ°´å¹³ç½æ ¼å°ºå¯¸\n",
    "Lz = 10             # åç´å±æ°\n",
    "Nx, Ny, Nz = 100, 100, 10  # ç½æ ¼åè¾¨ç\n",
    "\n",
    "dx, dy, dz = 1.0, 1.0, 1.0  # ç©ºé´æ­¥é¿ (ç±³)\n",
    "dt = 10.0            # æ¶é´æ­¥é¿ (ç§)\n",
    "total_time = 3600    # æ»ä»¿çæ¶é´ (ç§)\n",
    "output_interval = 1200  # è¾åºé´é (ç§)\n",
    "\n",
    "# åå§æµåº¦åº (æ°´é¢æ±¡æ)\n",
    "print('åå»ºåå§æµåº¦åº...')\n",
    "C0 = np.zeros((Nz, Ny, Nx))\n",
    "surface_conc = np.random.uniform(0, 1, (Ny, Nx))  # æ°´é¢éæºæ±¡æåå¸\n",
    "C0[-1] = surface_conc  # æ°´é¢å±å­å¨å¨æé¡¶å±\n",
    "\n",
    "# ç©çåæ°\n",
    "u0 = 0.005  # xæ¹ååºç¡æµé (m/s)\n",
    "v0 = 0.001   # yæ¹ååºç¡æµé (m/s)\n",
    "Dx, Dy = 0.01, 0.01  # æ°´å¹³æ©æ£ç³»æ°\n",
    "k = 0.05    # åç´æ©æ£è°æ´ç³»æ°\n",
    "\n",
    "print(f'ç½æ ¼ç»æ: {Nx}x{Ny}x{Nz}ç¹')\n",
    "print(f'æ°´å¹³æ©æ£: Dx={Dx} mÂ²/s, Dy={Dy} mÂ²/s')\n",
    "print(f'æµé: u={u0} m/s, v={v0} m/s')\n",
    "\n",
    "# === å®ä¹æ·±åº¦å½æ° ===\n",
    "def water_depth(x, y):\n",
    "    \"\"\"æ°´æ·±å½æ° (ç±³)\"\"\"\n",
    "    return 10.0 + 5 * np.sin(np.pi * x / 50) * np.cos(np.pi * y / 50)\n",
    "\n",
    "# åå»ºæ°´æ·±ç½æ ¼\n",
    "xcoords = np.linspace(0, Lx, Nx)\n",
    "ycoords = np.linspace(0, Ly, Ny)\n",
    "X, Y = np.meshgrid(xcoords, ycoords)\n",
    "H = water_depth(X, Y)\n",
    "\n",
    "# å¯è§åæ°´æ·±\n",
    "plt.figure(figsize=(8, 6))\n",
    "c = plt.pcolormesh(X, Y, H, cmap='viridis')\n",
    "plt.colorbar(c, label='Depth (m)')\n",
    "plt.title('æ°´æ·±åå¸')\n",
    "plt.xlabel('Xä½ç½® (m)')\n",
    "plt.ylabel('Yä½ç½® (m)')\n",
    "plt.savefig('ques3/figures/depth_distribution.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print('æå¤§æ°´æ·±:', np.max(H).round(1), 'ç±³')\n",
    "\n",
    "# === åç´æ©æ£ç³»æ° ===\n",
    "Dz = k / H  # éæ·±åº¦ååçæ©æ£ç³»æ°\n",
    "Dz = np.clip(Dz, 0.001, 1.0)  # éå¶æ©æ£ç³»æ°èå´\n",
    "\n",
    "# === æéå·®åç³»æ° ===\n",
    "rx = Dx * dt / (2 * dx**2)\n",
    "ry = Dy * dt / (2 * dy**2)\n",
    "rz = dz * dt  # åç´é¡¹ç³»æ°\n",
    "\n",
    "print(f'æ°´å¹³å·®åç³»æ°: rx={rx:.6f}, ry={ry:.6f}')\n",
    "\n",
    "# === ä¸ç»´æ©æ£å½æ° ===\n",
    "def diffuse_3d(C):\n",
    "    \"\"\"æ§è¡ä¸ç»´æ©æ£è®¡ç®\"\"\"\n",
    "    C_new = np.zeros_like(C)\n",
    "\n",
    "    # è®¡ç®ä¸ç»´æ©æ£\n",
    "    for z in range(Nz):\n",
    "        for y in range(1, Ny-1):\n",
    "            for x in range(1, Nx-1):\n",
    "                # ç¬¬äºé¶å¯¼æ° (æ°´å¹³)\n",
    "                lapl_x = (C[z, y, x+1] - 2*C[z, y, x] + C[z, y, x-1]) / dx**2\n",
    "                lapl_y = (C[z, y+1, x] - 2*C[z, y, x] + C[z, y-1, x]) / dy**2\n",
    "\n",
    "                # åç´æ©æ£ (ä¸è¾¹çå¤ç)\n",
    "                if z == Nz-1:  # æ°´é¢\n",
    "                    lapl_z = (C[z-1, y, x] - C[z, y, x]) / dz**2\n",
    "                elif z == 0:    # æ¹åº\n",
    "                    lapl_z = (C[z+1, y, x] - C[z, y, x]) / dz**2\n",
    "                else:           # ä¸­é´å±\n",
    "                    lapl_z = (C[z+1, y, x] - 2*C[z, y, x] + C[z-1, y, x]) / dz**2\n",
    "\n",
    "                # å¯¹æµé¡¹\n",
    "                conv_x = u0 * (C[z, y, x+1] - C[z, y, x-1]) / (2*dx)\n",
    "                conv_y = v0 * (C[z, y+1, x] - C[z, y-1, x]) / (2*dy)\n",
    "\n",
    "                # ç»åæ´æ°\n",
    "                diff_term = Dx * lapl_x + Dy * lapl_y + Dz[y, x] * lapl_z\n",
    "                conv_term = conv_x + conv_y\n",
    "                C_new[z, y, x] = C[z, y, x] + dt * (diff_term - conv_term)\n",
    "\n",
    "    return C_new\n",
    "\n",
    "# === ä¸ç»´æ©æ£æ¨¡æ ===\n",
    "print(f'å¼å§ä¸ç»´æ©æ£æ¨¡æ (æ»æ¶é¿:{total_time}ç§)')\n",
    "C = C0.copy()\n",
    "sim_results = {}\n",
    "\n",
    "for t in range(0, total_time+int(dt), int(dt)):\n",
    "    # æ§è¡ä¸ç»´æ©æ£\n",
    "    C = diffuse_3d(C)\n",
    "\n",
    "    # åºç¨è¾¹çæ¡ä»¶ (åç´æ¹å)\n",
    "    C[:, 0, :] = 0    # åè¾¹ç\n",
    "    C[:, -1, :] = 0   # åè¾¹ç\n",
    "    C[:, :, 0] = 0    # è¥¿è¾¹ç\n",
    "    C[:, :, -1] = 0   # ä¸è¾¹ç\n",
    "\n",
    "    # ä¿å­ç»æ\n",
    "    if t % output_interval == 0:\n",
    "        print(f'ä¿å­æ¶é´ç¹ t={t}ç§')\n",
    "        sim_results[t] = C.copy()\n",
    "\n",
    "        # å­å¨å",
    "³é®å±æ°æ®\n",
    "        df_surface = pd.DataFrame(C[-1], columns=np.arange(Nx), index=np.arange(Ny))\n",
    "        df_surface.to_csv(f'ques3/datasets/surface_t{t}.csv')\n",
    "        df_depth = pd.DataFrame(C[0], columns=np.arange(Nx), index=np.arange(Ny))\n",
    "        df_depth.to_csv(f'ques3/datasets/bottom_t{t}.csv')\n",
    "\n",
    "# === å¯è§åç»æ ===\n",
    "print('çæä¸ç»´å¯è§å...')\n",
    "for t, C_data in sim_results.items():\n",
    "    # æ°´é¢æ±¡ææµåº¦\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(C_data[-1], cmap='viridis', origin='lower', \n",
    "              extent=[0, Lx, 0, Ly], vmin=0, vmax=1)\n",
    "    plt.colorbar(label='æ±¡æç©æµåº¦')\n",
    "    plt.title(f'æ°´é¢æ±¡æç©æµåº¦ (t={t}ç§)')\n",
    "    plt.xlabel('Xä½ç½® (m)')\n",
    "    plt.ylabel('Yä½ç½® (m)')\n",
    "    plt.savefig(f'ques3/figures/surface_t{t}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # åç´åé¢\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    y_mid = Ny // 2\n",
    "    profile = np.vstack([C_data[z, y_mid, :] for z in range(Nz)])\n",
    "    c = plt.imshow(profile, aspect='auto', cmap='viridis', \n",
    "                  extent=[0, Lx, 0, np.max(H)], origin='lower')\n",
    "    plt.colorbar(c, label='æ±¡æç©æµåº¦')\n",
    "    plt.title(f'ååæ±¡æç©åå¸ (Y={y_mid*dy}m, t={t}ç§)')\n",
    "    plt.xlabel('Xä½ç½® (m)')\n",
    "    plt.ylabel('æ·±åº¦ (m)')\n",
    "    plt.savefig(f'ques3/figures/profile_t{t}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # ä¸ç»´å¯è§å\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # éæ©å­éä»¥åå°æ°æ®é\n",
    "    step = 5\n",
    "    Xs, Ys = X[::step, ::step], Y[::step, ::step]\n",
    "    Zs0 = C_data[-1][::step, ::step]  # æ°´é¢æµåº¦\n",
    "\n",
    "    # åå»ºç½æ ¼\n",
    "    surf = ax.plot_surface(Xs, Ys, Zs0, cmap='viridis', \n",
    "                          linewidth=0, antialiased=True)\n",
    "\n",
    "    ax.set_title(f'æ°´é¢æ±¡æç©ä¸ç»´åå¸ (t={t}ç§)')\n",
    "    ax.set_xlabel('Xä½ç½® (m)')\n",
    "    ax.set_ylabel('Yä½ç½® (m)')\n",
    "    ax.set_zlabel('æµåº¦')\n",
    "    fig.colorbar(surf, ax=ax, shrink=0.5)\n",
    "    plt.savefig(f'ques3/figures/3d_surface_t{t}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# === æ±¡æç©è¡°ååæ ===\n",
    "print('åææ±¡æç©åç´è¡°å...')\n",
    "# è®¡ç®å¹³åæµåº¦éæ·±åº¦çåå\n",
    "mean_profiles = []\n",
    "times = list(sim_results.keys())\n",
    "for t in times:\n",
    "    depth_profile = np.mean(np.mean(sim_results[t], axis=2), axis=1)\n",
    "    mean_profiles.append(depth_profile)\n",
    "\n",
    "# å¯è§åæ·±åº¦åé¢åå\n",
    "plt.figure(figsize=(10, 6))\n",
    "depths = np.linspace(0, np.max(H), Nz)\n",
    "\n",
    "for i, profile in enumerate(mean_profiles):\n",
    "    plt.plot(profile, depths, '-o', label=f't={times[i]}ç§')\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('å¹³åæ±¡æç©æµåº¦')\n",
    "plt.ylabel('æ·±åº¦ (m)')\n",
    "plt.title('æ±¡æç©å¹³åæµåº¦éæ·±åº¦åå')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('ques3/figures/depth_profiles.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === çææ¥å ===\n",
    "report_content = \"ä¸ç»´æ±¡æç©æ©æ£æ¨¡ååææ¥å\\n\"\n",
    "report_content += \"=\"*50 + \"\\n\"\n",
    "report_content += \"æ¨¡åç¹æ§:\\n\"\n",
    "report_content += f\"- ç½æ ¼è§æ¨¡: {Nx}x{Ny}x{Nz} (æ°´å¹³xåç´)\\n\"\n",
    "report_content += f\"- æ»æ¨¡ææ¶é´: {total_time}ç§\\n\"\n",
    "report_content += f\"- æ°´å¹³æ©æ£ç³»æ°: Dx={Dx} mÂ²/s, Dy={Dy} mÂ²/s\\n\"\n",
    "report_content += f\"- åç´æ©æ£è°æ´ç³»æ°: k={k}\\n\"\n",
    "report_content += \"\\nä¸»è¦åç°:\\n\"\n",
    "report_content += \"1. æ±¡æç©å¨æ·±å±æ°´çæ©æ£ææ¾æ",
    "¢äºè¡¨å±\\n\"\n",
    "report_content += \"2. æ±¡æç©éæ¶é´åææ°è¡°åï¼æ·±åº¦ç¸å",
    "³æ©æ£æ¾èå½±ååå¸\\n\"\n",
    "report_content += \"3. æ±¡æç¾½å¨æµå¨æ¹åè¢«æä¼¸\\n\"\n",
    "report_content += \"\\nè¾åºæä»¶:\\n\"\n",
    "for t in times:\n",
    "    report_content += f\"- æ¶é´ç¹ t={t}ç§: /datasets/surface_t{t}.csv, /datasets/bottom_t{t}.csv\\n\"\n",
    "report_content += \"- æ°´é¢æ±¡æç©å¾: /figures/surface_t{time}.png\\n\"\n",
    "report_content += \"- åååé¢å¾: /figures/profile_t{time}.png\\n\"\n",
    "report_content += \"- ä¸ç»´åå¸å¾: /figures/3d_surface_t{time}.png\\n\"\n",
    "report_content += \"- æ·±åº¦ååæ²çº¿: /figures/depth_profiles.png\"\n",
    "\n",
    "with open('ques3/reports/report_ques3.txt', 'w') as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print('=== æ¨¡åå®æ ===')\n",
    "print('ç»æä¿å­å¨ques3ç®å½')\n",
    "print(f'å¯è§åæä»¶: {len(times)*3+1}ä¸ªå¾å')\n",
    "print(f'æ°æ®æä»¶: {len(times)*2}ä¸ªCSVæä»¶')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a717b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "  Cell In[14], line 2\n    {\"\n     ^\nSyntaxError: unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "json\n",
    "{\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84954ef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "  Cell In[15], line 2\n    {\"\n     ^\nSyntaxError: unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "json\n",
    "{\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015aef9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "==== é®é¢3: ä¸ç»´æ±¡æç©æ©æ£æ¨¡å ====\n",
       "ç½æ ¼å°ºå¯¸: 40Ã40Ã5\n",
       "ç©ºé´æ­¥é¿: dx=2.6m, dy=2.6m, dz=2.5m\n",
       "æ¶é´æ­¥é¿: dt=60.0s, æ»æ¶é¿: 3600s\n",
       "åå»ºåå§æµåº¦åº...\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "å¼å§ä¸ç»´æ©æ£æ¨¡æ (60æ­¥)...\n",
       "&gt;&gt; ä¿å­æ¶é´ç¹ t=0ç§\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "&gt;&gt; ä¿å­æ¶é´ç¹ t=1200ç§\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "&gt;&gt; ä¿å­æ¶é´ç¹ t=2400ç§\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "&gt;&gt; ä¿å­æ¶é´ç¹ t=3600ç§\n",
       "çæç»æå¯è§å...\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "<title></title>\n",
       "<style type=\"text/css\">\n",
       ".ansi2html-content { display: inline; white-space: pre-wrap; word-wrap: break-word; }\n",
       ".body_foreground { color: #AAAAAA; }\n",
       ".body_background { background-color: #000000; }\n",
       ".inv_foreground { color: #000000; }\n",
       ".inv_background { background-color: #AAAAAA; }\n",
       "</style>\n",
       "</head>\n",
       "<body class=\"body_foreground body_background\" style=\"font-size: normal;\" >\n",
       "<pre class=\"ansi2html-content\">\n",
       "==================================================\n",
       "æ¨¡åæ¨¡æå®æï¼ç»æä¿å­å¨ ques3/ ç®å½ä¸\n",
       "- 4 ä¸ªæ¶é´ç¹æ°æ®\n",
       "- 3 å¼ å",
       "³é®åæå¾å\n",
       "- è¯¦ç»æ¥å: ques3/reports/report_ques3.txt\n",
       "\n",
       "</pre>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# åå»ºé®é¢3è¾åºç®å½\n",
    "os.makedirs('ques3/datasets', exist_ok=True)\n",
    "os.makedirs('ques3/figures', exist_ok=True)\n",
    "os.makedirs('ques3/reports', exist_ok=True)\n",
    "\n",
    "# %% ques3\n",
    "print('==== é®é¢3: ä¸ç»´æ±¡æç©æ©æ£æ¨¡å ====')\n",
    "\n",
    "# === åæ°è®¾ç½® ===\n",
    "Lx, Ly = 100, 100   # æ°´å¹³å°ºå¯¸ (ç±³)\n",
    "Lz = 10              # æ·±åº¦ (ç±³)\n",
    "Nx, Ny, Nz = 40, 40, 5  # ç½æ ¼åè¾¨ç (åå°ç½æ ¼ç¹ä»¥å å¿«è®¡ç®)\n",
    "dx, dy = Lx/(Nx-1), Ly/(Ny-1)\n",
    "dz = Lz/(Nz-1)\n",
    "dt = 60.0           # æ¶é´æ­¥é¿ (ç§)\n",
    "total_time = 3600    # æ»ä»¿çæ¶é´ (ç§)\n",
    "output_interval = 1200  # è¾åºé´é (ç§)\n",
    "\n",
    "# æ©æ£ç³»æ°\n",
    "Dx, Dy = 0.01, 0.01  # æ°´å¹³æ©æ£ç³»æ°\n",
    "Dz = 0.005           # åç´æ©æ£ç³»æ°\n",
    "\n",
    "u = 0.005  # xæ¹åæµé\n",
    "v = 0.001   # yæ¹åæµé\n",
    "\n",
    "print(f'ç½æ ¼å°ºå¯¸: {Nx}Ã{Ny}Ã{Nz}')\n",
    "print(f'ç©ºé´æ­¥é¿: dx={dx:.1f}m, dy={dy:.1f}m, dz={dz:.1f}m')\n",
    "print(f'æ¶é´æ­¥é¿: dt={dt}s, æ»æ¶é¿: {total_time}s')\n",
    "\n",
    "# === åå»ºåå§æµåº¦åº (æ°´é¢æ±¡æ) ===\n",
    "print('åå»ºåå§æµåº¦åº...')\n",
    "C = np.zeros((Nz, Ny, Nx))\n",
    "\n",
    "# è¡¨é¢å±éæºæµåº¦æ±¡æ\n",
    "surface_conc = np.random.rand(Ny, Nx)\n",
    "C[-1, :, :] = surface_conc\n",
    "\n",
    "# === ä¿å­åå§ç¶æ ===\n",
    "pd.DataFrame(C[-1]).to_csv('ques3/datasets/initial_surface.csv')\n",
    "\n",
    "# === å¯è§ååå§æ°´é¢æµåº¦ ===\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(C[-1], origin='lower', cmap='viridis')\n",
    "plt.title('åå§è¡¨é¢æ±¡æç©æµåº¦ (t=0)')\n",
    "plt.colorbar(label='æµåº¦')\n",
    "plt.savefig('ques3/figures/initial_surface.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === ä¸ç»´æ©æ£æ¨¡æ ===\n",
    "def apply_boundary_conditions(arr):\n",
    "    \"\"\"åºç¨è¾¹çæ¡ä»¶\"\"\"\n",
    "    # é¡¶é¨ååºé¨ - Neumannæ¡ä»¶ (æ éé)\n",
    "    arr[0, :, :] = arr[1, :, :]   # æ¹åº\n",
    "    arr[-1, :, :] = arr[-2, :, :] # æ°´é¢\n",
    "\n",
    "    # åå¨ - Dirichleté¶æµåº¦\n",
    "    arr[:, 0, :] = 0  # åè¾¹ç\n",
    "    arr[:, -1, :] = 0 # åè¾¹ç\n",
    "    arr[:, :, 0] = 0  # è¥¿è¾¹ç\n",
    "    arr[:, :, -1] = 0 # ä¸è¾¹ç\n",
    "\n",
    "    return arr\n",
    "\n",
    "print(f'å¼å§ä¸ç»´æ©æ£æ¨¡æ ({int(total_time/dt)}æ­¥)...')\n",
    "simulation_results = {}\n",
    "\n",
    "for step in range(int(total_time/dt)+1):\n",
    "    t = step * dt\n",
    "\n",
    "    # åºç¨è¾¹çæ¡ä»¶\n",
    "    C = apply_boundary_conditions(C)\n",
    "\n",
    "    # ä¸´æ¶å¤å¶å½åæµåº¦\n",
    "    C_new = C.copy()\n",
    "\n",
    "    # ä¸ç»´æ©æ£è®¡ç®\n",
    "    for z in range(1, Nz-1):\n",
    "        for y in range(1, Ny-1):\n",
    "            for x in range(1, Nx-1):\n",
    "                # æ©æ£é¡¹ (äºé¶å¯¼)\n",
    "                diff_x = Dx * (C[z, y, x+1] - 2*C[z, y, x] + C[z, y, x-1]) / dx**2\n",
    "                diff_y = Dy * (C[z, y+1, x] - 2*C[z, y, x] + C[z, y-1, x]) / dy**2\n",
    "                diff_z = Dz * (C[z+1, y, x] - 2*C[z, y, x] + C[z-1, y, x]) / dz**2\n",
    "\n",
    "                # å¯¹æµé¡¹ (ä¸é¶å¯¼)\n",
    "                conv_x = u * (C[z, y, x+1] - C[z, y, x-1]) / (2*dx)\n",
    "                conv_y = v * (C[z, y+1, x] - C[z, y-1, x]) / (2*dy)\n",
    "\n",
    "                # ç»åæ´æ°\n",
    "                C_new[z, y, x] = C[z, y, x] + dt * (diff_x + diff_y + diff_z - conv_x - conv_y)\n",
    "\n",
    "    # æ´æ°æµåº¦åº\n",
    "    C = C_new\n",
    "\n",
    "    # ä¿å­ç»æ\n",
    "    if t % output_interval == 0:\n",
    "        print(f'>> ä¿å­æ¶é´ç¹ t={t:.0f}ç§')\n",
    "        simulation_results[t] = C.copy()\n",
    "\n",
    "        # ä¿å­CSVæ°æ®\n",
    "        pd.DataFrame(C[-1]).to_csv(f'ques3/datasets/surface_t{t:.0f}.csv')\n",
    "        pd.DataFrame(np.mean(C, axis=0)).to_csv(f'ques3/datasets/mean_z_t{t:.0f}.csv')\n",
    "\n",
    "# === ç»æå¯è§å ===\n",
    "print('çæç»æå¯è§å...')\n",
    "times = sorted(simulation_results.keys())\n",
    "\n",
    "# 1. è¡¨é¢æµåº¦åå\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, t in enumerate(times):\n",
    "    plt.subplot(1, len(times), i+1)\n",
    "    plt.imshow(simulation_results[t][-1], origin='lower', cmap='viridis')\n",
    "    plt.title(f't={t}ç§')\n",
    "    plt.colorbar()\n",
    "plt.suptitle('è¡¨é¢æ±¡æç©æµåº¦åå')\n",
    "plt.tight_layout()\n",
    "plt.savefig('ques3/figures/surface_concentration.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 2. åç´åé¢åå\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, t in enumerate(times):\n",
    "    # è·ååç´åé¢ (åºå®yä½ç½®)\n",
    "    mid_y = Ny // 2\n",
    "    profile = simulation_results[t][:, mid_y, :]\n",
    "    plt.subplot(len(times), 1, i+1)\n",
    "    plt.imshow(profile, aspect='auto', origin='lower', cmap='viridis', \n",
    "              extent=[0, Lx, 0, Lz])\n",
    "    plt.colorbar(label='æµåº¦')\n",
    "    plt.title(f't={t}ç§, Y={mid_y*dy:.1f}m')\n",
    "    plt.ylabel('æ·±åº¦ (m)')\n",
    "\n",
    "    if i == len(times)-1:\n",
    "        plt.xlabel('Xä½ç½® (m)')\n",
    "\n",
    "plt.suptitle('åç´åé¢æ±¡æç©åå¸åå')\n",
    "plt.tight_layout()\n",
    "plt.savefig('ques3/figures/vertical_profiles.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 3. æµåº¦è¡°åæ²çº¿\n",
    "mean_concentration = [np.mean(simulation_results[t]) for t in times]\n",
    "max_concentration = [np.max(simulation_results[t]) for t in times]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(times, mean_concentration, 'bo-', label='å¹³åæµåº¦')\n",
    "plt.plot(times, max_concentration, 'rs--', label='å³°å¼æµåº¦')\n",
    "plt.xlabel('æ¶é´ (ç§)')\n",
    "plt.ylabel('æ±¡æç©æµåº¦')\n",
    "plt.title('æ±¡æç©æµåº¦è¡°åæ²çº¿')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('ques3/figures/decay_curves.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === çææ¥å ===\n",
    "report_text = f\"ä¸ç»´æ±¡æç©æ©æ£æ¨¡ååææ¥å\\n\"\n",
    "report_text += \"=\" * 70 + \"\\n\\n\"\n",
    "report_text += f\"æ¨¡ååæ°\\n\"\n",
    "report_text += f\"- ç½æ ¼å°ºå¯¸: {Nx}Ã{Ny}Ã{Nz} (é¿Ãå®½Ãæ·±)\\n\"\n",
    "report_text += f\"- æ©æ£ç³»æ°: Dx={Dx}, Dy={Dy}, Dz={Dz} mÂ²/s\\n\"\n",
    "report_text += f\"- æµé: u={u} m/s, v={v} m/s\\n\"\n",
    "report_text += f\"- æ¨¡ææ¶é¿: {total_time}ç§, æ¶é´æ­¥é¿: {dt}ç§\\n\\n\"\n",
    "report_text += f\"å",
    "³é®ç»æ\\n\"\n",
    "report_text += f\"- å³°å¼æ±¡ææµåº¦: åå§={max_concentration[0]:.3f}, æç»={max_concentration[-1]:.3f}\\n\"\n",
    "report_text += f\"- æ±¡æç©è¡°åç: {100*(1 - max_concentration[-1]/max_concentration[0]):.1f}%\\n\\n\"\n",
    "report_text += f\"ä¿å­æä»¶\\n\"\n",
    "report_text += f\"- æ°æ®æä»¶: /datasets/surface_t{{time}}.csv (åæ¶é´ç¹è¡¨é¢æµåº¦)\\n\"\n",
    "report_text += f\"- å¾åæä»¶: /figures/ ç®å½ä¸ç PNG æä»¶\\n\\n\"\n",
    "report_text += \"ç»è®º\\n\"\n",
    "report_text += \"1. ä¸ç»´æ¨¡åæåæ¨¡æäºæ±¡æç©éæ¶é´åæ·±åº¦çæ©æ£è¿ç¨\\n\"\n",
    "report_text += \"2. æ±¡æç©ä¸»è¦å¨æ°´é¢æµå¨æ¹åä¸æ©æ£ï¼æ·±å±æ°´ä½æ©æ£è¾æ",
    "¢\\n\"\n",
    "report_text += \"3. åç´æ©æ£ç³»æ°å¯¹æ±¡æç©ççºµååå¸ææ¾èå½±å\"\n",
    "\n",
    "# ä¿å­æ¥å (ä½¿ç¨UTF-8ç¼ç é¿å",
    "å­ç¬¦é®é¢)\n",
    "with open('ques3/reports/report_ques3.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "print('='*50)\n",
    "print('æ¨¡åæ¨¡æå®æï¼ç»æä¿å­å¨ ques3/ ç®å½ä¸')\n",
    "print(f'- {len(simulation_results)} ä¸ªæ¶é´ç¹æ°æ®')\n",
    "print(f'- 3 å¼ å",
    "³é®åæå¾å')\n",
    "print(f'- è¯¦ç»æ¥å: ques3/reports/report_ques3.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be8aad",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Error message",
     "output_type": "error",
     "traceback": [
      "  Cell In[17], line 2\n    {\"\n     ^\nSyntaxError: unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "json\n",
    "{\"\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}