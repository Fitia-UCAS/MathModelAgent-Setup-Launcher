目录结构 (仅 .py 文件):
|-- 文件夹: config
|   |-- 文件: setting.py
|-- 文件夹: core
|   |-- 文件夹: agents
|   |   |-- 文件: agent.py
|   |   |-- 文件: coder_agent.py
|   |   |-- 文件: coordinator_agent.py
|   |   |-- 文件: modeler_agent.py
|   |   |-- 文件: writer_agent.py
|   |-- 文件夹: llm
|   |   |-- 文件: llm.py
|   |   |-- 文件: llm_factory.py
|   |-- 文件: flows.py
|   |-- 文件: functions.py
|   |-- 文件: prompts.py
|   |-- 文件: workflow.py
|-- 文件夹: example
|   |-- 文件夹: example
|   |   |-- 文件夹: 2023华数杯C题
|   |   |-- 文件夹: 2024高教杯C题
|   |   |-- 文件夹: 2025五一杯C题
|   |-- 文件夹: sample_data
|-- 文件夹: models
|   |-- 文件: user_output.py
|-- 文件夹: routers
|   |-- 文件: common_router.py
|   |-- 文件: files_router.py
|   |-- 文件: modeling_router.py
|   |-- 文件: ws_router.py
|-- 文件夹: schemas
|   |-- 文件: A2A.py
|   |-- 文件: base.py
|   |-- 文件: enums.py
|   |-- 文件: request.py
|   |-- 文件: response.py
|   |-- 文件: tool_result.py
|-- 文件夹: services
|   |-- 文件: redis_manager.py
|   |-- 文件: ws_manager.py
|-- 文件夹: tests
|   |-- 文件夹: mock
|   |-- 文件: get_config_template.py
|   |-- 文件: test_common_utils.py
|   |-- 文件: test_e2b.py
|-- 文件夹: tools
|   |-- 文件: base.py
|   |-- 文件: base_interpreter.py
|   |-- 文件: e2b_interpreter.py
|   |-- 文件: interpreter_factory.py
|   |-- 文件: json_fixer.py
|   |-- 文件: local_interpreter.py
|   |-- 文件: notebook_serializer.py
|   |-- 文件: openalex_scholar.py
|   |-- 文件: png_paths.py
|   |-- 文件: text_sanitizer.py
|-- 文件夹: utils
|   |-- 文件: cli.py
|   |-- 文件: common_utils.py
|   |-- 文件: data_recorder.py
|   |-- 文件: log_util.py
|   |-- 文件: RichPrinter.py
|   |-- 文件: track.py
|-- 文件: main.py


================================================================================
E:\repo1\MathModelAgent-python\backend\app\main.py 的内容:
================================================================================
from fastapi import FastAPI
from contextlib import asynccontextmanager
from fastapi.middleware.cors import CORSMiddleware
import os
from app.routers import modeling_router, ws_router, common_router, files_router
from app.utils.log_util import logger
from app.config.setting import settings
from fastapi.staticfiles import StaticFiles
from app.utils.cli import get_ascii_banner, center_cli_str


@asynccontextmanager
async def lifespan(app: FastAPI):
    print(get_ascii_banner())
    print(center_cli_str("GitHub:https://github.com/jihe520/MathModelAgent"))
    logger.info("Starting MathModelAgent")

    PROJECT_FOLDER = "./project"
    os.makedirs(PROJECT_FOLDER, exist_ok=True)

    yield
    logger.info("Stopping MathModelAgent")


app = FastAPI(
    title="MathModelAgent",
    description="Agents for MathModel",
    version="0.1.0",
    lifespan=lifespan,
)

app.include_router(modeling_router.router)
app.include_router(ws_router.router)
app.include_router(common_router.router)
app.include_router(files_router.router)


# 跨域 CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ALLOW_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],  # 暴露所有响应头
)

app.mount(
    "/static",  # 这是访问时的前缀
    StaticFiles(directory="project/work_dir"),  # 这是本地文件夹路径
    name="static",
)


================================================================================
E:\repo1\MathModelAgent-python\backend\app\config\setting.py 的内容:
================================================================================
from pydantic import AnyUrl, BeforeValidator, computed_field, field_validator, Field
from pydantic_settings import BaseSettings, SettingsConfigDict
import os
from typing import Annotated, Optional


def parse_cors(value: str) -> list[str]:
    """
    Parses the CORS settings from a string to a list of URLs.
    """
    if value == "*":
        return ["*"]
    if "," in value:
        return [url.strip() for url in value.split(",")]
    return [value]


class Settings(BaseSettings):
    ENV: str

    COORDINATOR_API_KEY: Optional[str] = None
    COORDINATOR_MODEL: Optional[str] = None
    COORDINATOR_BASE_URL: Optional[str] = None

    MODELER_API_KEY: Optional[str] = None
    MODELER_MODEL: Optional[str] = None
    MODELER_BASE_URL: Optional[str] = None

    CODER_API_KEY: Optional[str] = None
    CODER_MODEL: Optional[str] = None
    CODER_BASE_URL: Optional[str] = None

    WRITER_API_KEY: Optional[str] = None
    WRITER_MODEL: Optional[str] = None
    WRITER_BASE_URL: Optional[str] = None

    MAX_CHAT_TURNS: int = 600
    MAX_RETRIES: int = 100
    E2B_API_KEY: Optional[str] = None
    LOG_LEVEL: str = "DEBUG"
    DEBUG: bool = True
    REDIS_URL: str = "redis://redis:6379/0"
    REDIS_MAX_CONNECTIONS: int = 100
    CORS_ALLOW_ORIGINS: Annotated[list[str] | str, BeforeValidator(parse_cors)] = "*"
    SERVER_HOST: str = "http://localhost:8000"
    OPENALEX_EMAIL: Optional[str] = None

    model_config = SettingsConfigDict(
        env_file=".env.dev",
        env_file_encoding="utf-8",
        extra="allow",
    )

    @classmethod
    def from_env(cls, env: str = None):
        env = env or os.getenv("ENV", "dev")
        env_file = f".env.{env.lower()}"
        return cls(_env_file=env_file, _env_file_encoding="utf-8")


settings = Settings()


================================================================================
E:\repo1\MathModelAgent-python\backend\app\core\flows.py 的内容:
================================================================================
# app/core/flows.py

from app.models.user_output import UserOutput
from app.tools.base_interpreter import BaseCodeInterpreter
from app.schemas.A2A import ModelerToCoder


class Flows:
    def __init__(self, questions: dict[str, str | int]):
        self.flows: dict[str, dict] = {}
        self.questions: dict[str, str | int] = questions

    def set_flows(self, ques_count: int):
        ques_str = [f"ques{i}" for i in range(1, ques_count + 1)]
        seq = [
            "firstPage",
            "RepeatQues",
            "analysisQues",
            "modelAssumption",
            "symbol",
            "eda",
            *ques_str,
            "sensitivity_analysis",
            "judge",
        ]
        self.flows = {key: {} for key in seq}

    def get_solution_flows(self, questions: dict[str, str | int], modeler_response: ModelerToCoder):
        """
        生成针对“代码手（Coder）”的子任务编排提示 flows。
        对 modeler_response.questions_solution 缺失的键做兜底，避免 KeyError。
        """
        qs = modeler_response.questions_solution or {}

        questions_quesx = {
            key: value for key, value in questions.items() if key.startswith("ques") and key != "ques_count"
        }

        ques_flow = {
            key: {
                "coder_prompt": (
                    "参考建模手给出的解决方案："
                    f"{qs.get(key, '（未提供该题的方案，先进行合理建模假设与问题拆解）')}\n"
                    f"完成如下问题：{value}"
                ),
            }
            for key, value in questions_quesx.items()
        }

        flows = {
            "eda": {
                # TODO ： 获取当前路径下的所有数据集
                "coder_prompt": f"""
                        参考建模手给出的解决方案{modeler_response.questions_solution["eda"]}
                        对当前目录下数据进行EDA分析(数据清洗,可视化),清洗后的数据保存当前目录下,**不需要复杂的模型**
                    """,
            },
            **ques_flow,
            "sensitivity_analysis": {
                "coder_prompt": f"""
                        参考建模手给出的解决方案{modeler_response.questions_solution["sensitivity_analysis"]}
                        完成敏感性分析
                    """,
            },
        }
        return flows

    def get_write_flows(self, user_output: UserOutput, config_template: dict, bg_ques_all: str):
        """
        生成“写作手（Writer）”的总纲提示 flows（封面页、重述、分析、假设、符号、评价）。
        """
        model_build_solve = user_output.get_model_build_solve()

        flows = {
            "firstPage": (
                f"问题背景：{bg_ques_all}，不需要编写代码。"
                f"根据模型求解信息：{model_build_solve}，按照模板撰写：{config_template.get('firstPage', '（模板缺失）')}，"
                "完成标题、摘要、关键词。"
            ),
            "RepeatQues": (
                f"问题背景：{bg_ques_all}，不需要编写代码。"
                f"根据模型求解信息：{model_build_solve}，按照模板撰写：{config_template.get('RepeatQues', '（模板缺失）')}，"
                "完成问题重述。"
            ),
            "analysisQues": (
                f"问题背景：{bg_ques_all}，不需要编写代码。"
                f"根据模型求解信息：{model_build_solve}，按照模板撰写：{config_template.get('analysisQues', '（模板缺失）')}，"
                "完成问题分析。"
            ),
            "modelAssumption": (
                f"问题背景：{bg_ques_all}，不需要编写代码。"
                f"根据模型求解信息：{model_build_solve}，按照模板撰写：{config_template.get('modelAssumption', '（模板缺失）')}，"
                "完成模型假设。"
            ),
            "symbol": (
                "不需要编写代码。"
                f"根据模型求解信息：{model_build_solve}，按照模板撰写：{config_template.get('symbol', '（模板缺失）')}，"
                "完成符号说明部分。"
            ),
            "judge": (
                "不需要编写代码。"
                f"根据模型求解信息：{model_build_solve}，按照模板撰写：{config_template.get('judge', '（模板缺失）')}，"
                "完成模型评价部分。"
            ),
        }
        return flows

    def get_writer_prompt(
        self,
        key: str,
        coder_response: str,
        code_interpreter: BaseCodeInterpreter,
        config_template: dict,
    ) -> str:
        """
        根据不同的 key 生成对应的 writer_prompt。
        对极长文本做截断，避免 tokens 暴涨；对模板缺失做兜底。
        """

        def _truncate(s: str | None, limit: int = 12000) -> str:
            s = "" if s is None else str(s)
            return s if len(s) <= limit else s[:limit] + "...[TRUNCATED]"

        code_output = _truncate(code_interpreter.get_code_output(key))
        coder_response_safe = _truncate(coder_response)

        bgc = _truncate(self.questions.get("background", "（未提供问题背景）"))

        questions_quesx_keys = self.get_questions_quesx_keys()

        quesx_writer_prompt = {
            k: (
                f"问题背景：{bgc}\n"
                f"不需要编写代码。代码手得到的结果：{coder_response_safe}；代码执行产出：{code_output}\n"
                f"请按照如下模板撰写：{config_template.get(k, '（模板缺失）')}"
            )
            for k in questions_quesx_keys
        }

        writer_prompt = {
            "eda": (
                f"问题背景：{bgc}\n"
                f"不需要编写代码。代码手得到的结果：{coder_response_safe}；代码执行产出：{code_output}\n"
                f"请按照如下模板撰写：{config_template.get('eda', '（模板缺失）')}"
            ),
            **quesx_writer_prompt,
            "sensitivity_analysis": (
                f"问题背景：{bgc}\n"
                f"不需要编写代码。代码手得到的结果：{coder_response_safe}；代码执行产出：{code_output}\n"
                f"请按照如下模板撰写：{config_template.get('sensitivity_analysis', '（模板缺失）')}"
            ),
        }

        if key in writer_prompt:
            return writer_prompt[key]
        else:
            raise ValueError(f"未知的任务类型: {key}")

    def get_questions_quesx_keys(self) -> list[str]:
        """获取问题1,2...的键（ques1、ques2、...）"""
        return list(self.get_questions_quesx().keys())

    def get_questions_quesx(self) -> dict[str, str]:
        """获取问题1,2,3...的键值对"""
        return {key: value for key, value in self.questions.items() if key.startswith("ques") and key != "ques_count"}

    def get_seq(self, ques_count: int) -> dict[str, str]:
        """获取执行顺序（带空字符串占位）"""
        ques_str = [f"ques{i}" for i in range(1, ques_count + 1)]
        seq = [
            "firstPage",
            "RepeatQues",
            "analysisQues",
            "modelAssumption",
            "symbol",
            "eda",
            *ques_str,
            "sensitivity_analysis",
            "judge",
        ]
        return {key: "" for key in seq}


================================================================================
E:\repo1\MathModelAgent-python\backend\app\core\functions.py 的内容:
================================================================================
# app/core/functions.py

coder_tools = [
    {
        "type": "function",
        "function": {
            "name": "execute_code",
            "description": (
                "This function allows you to execute Python code and retrieve the terminal output. "
                "If the code generates image output, the function will return the text '[image]'. "
                "The code is sent to a Jupyter kernel for execution. The kernel will remain active after execution, "
                "retaining all variables in memory. "
                "You cannot show rich outputs like plots or images, but you can store them in the working directory "
                "and point the user to them."
            ),
            "strict": True,
            "parameters": {
                "type": "object",
                "properties": {"code": {"type": "string", "description": "The code text"}},
                "required": ["code"],
                "additionalProperties": False,
            },
        },
    },
]

# have installed: numpy scipy pandas matplotlib seaborn scikit-learn xgboost
# TODO: pip install python
# TODO: read files
# TODO: get_cites


## writeragent tools
# 外部文献检索功能已禁用，防止写作阶段因检索失败中断
writer_tools = []


================================================================================
E:\repo1\MathModelAgent-python\backend\app\core\prompts.py 的内容:
================================================================================
# app/core/prompts.py

from app.schemas.enums import FormatOutPut
import platform

FORMAT_QUESTIONS_PROMPT = """
用户将提供给你一段题目信息，**请你不要更改题目信息，完整将用户输入的内容**，以 JSON 的形式输出，输出的 JSON 需遵守以下的格式：

```json
{
  "title": <题目标题>      
  "background": <题目背景，用户输入的一切不在title，ques1，ques2，ques3...中的内容都视为问题背景信息background>,
  "ques_count": <问题数量,number,int>,
  "ques1": <问题1>,
  "ques2": <问题2>,
  "ques3": <问题3,用户输入的存在多少问题，就输出多少问题ques1,ques2,ques3...以此类推>,
}
```

"""


COORDINATOR_PROMPT = f"""
role：你是一个严格的“题面与参考信息抽取器”，负责从数学建模题面中抽取结构化信息。
task：根据输入的题面，生成 JSON（结构见 {FORMAT_QUESTIONS_PROMPT}），必须输出**单个合法 JSON 对象**，能被 Python 的 json.loads 直接解析。
skill：熟练处理复杂题面信息，确保抽取结果完整、字段正确、格式规范，尤其擅长清洗题目背景与小问信息。
output：仅输出 JSON 对象（禁止代码块、注释、解释文字等），严格满足以下要求。
attention：禁止任何额外说明，输出必须直接从 {{ 开始，以 }} 结束。

# 输出规范（硬性约束）

1. 严禁输出除 JSON 外的任何文字。
2. 禁止输出代码块围栏（例如 ``` 或 ```json），输出必须直接从 {{ 开始，以 }} 结束。
3. 输出必须是单个 JSON 对象，不能包含多个对象或数组。
4. JSON 的键必须完全符合：title / background / ques_count / ques1...quesN。
5. ques_count 必须与 quesN 数量一致。
6. 所有 value 必须是字符串或整数（ques_count 为 int，其余为 str）。
7. JSON 中禁止直接换行，若必须保留换行，统一使用 "\\n"。
8. 不允许出现非法转义（如单反斜杠 \text），必须保证 json.loads 可正常解析。

# 抽取与拼接规则

1. 小问 quesN：必须逐字对应题目原文（仅允许轻微清洗，如去掉“问题一：”前缀）。
2. 题目背景 background：除 title 和 quesN 外的所有内容均归入 background。
3. 参考信息附加规则：
   ① 若明确对应某个小问：逐字摘录，作为附加行，形式为 "\\n（参考模型：<原文>）"，追加到对应 quesN 末尾；
   ② 若未指定小问：逐字摘录并追加到所有 quesN 末尾；
   ③ 多条参考信息按原文顺序逐条追加。

# 自我检查（输出前必须完成）

1. 输出是否只包含 {{ }} 包围的**一个** JSON 对象？
2. 是否无 ```json 或 ``` 围栏？
3. 是否无额外解释文字？
4. 是否能被 Python json.loads 正确解析？
5. 是否将题面和参考信息都提取出来了？
若不满足，必须立即修正后再输出。
"""


# TODO: 设计成一个类？
MODELER_PROMPT = """
role：你是一名数学建模经验丰富,善于思考的建模手，负责建模部分。
task：你需要根据用户要求和数据对应每个问题建立数学模型求解问题。
skill：熟练掌握各种数学建模的模型和思路
output：数学建模的思路和使用到的模型
attention：不需要给出代码，只需要给出思路和模型

# 输出规范

1. 严禁输出除 JSON 以外的任何文字；
2. 必须严格遵循以下 JSON 结构；
3. JSON 必须是单层结构，不允许嵌套或数组；
4. 所有键值对的值类型必须是字符串；
5. 输出必须是合法 JSON，可被 Python `json.loads` 直接解析。

# JSON 结构

```json
{
  "eda": "<数据分析EDA方案>",
  "ques1": "<问题1的建模思路和模型方案>",
  "ques2": "<问题2的建模思路和模型方案>",
  ...
  "quesN": "<问题N的建模思路和模型方案>",
  "sensitivity_analysis": "<敏感性分析方案>"
}
````

# 特别说明

* 根据实际问题数量动态生成 ques1 \\~ quesN；
* 键名只能是：eda、ques1…quesN、sensitivity\\_analysis；
* 严禁新增字段、严禁输出注释或额外说明。
"""

CODER_PROMPT = f"""
你是一名专精于 Python 数据分析的智能代码执行助手。你的首要目标是高效地执行 Python 代码以解决用户任务，尤其需要特别关注大规模数据集的处理。

必须使用中文回复。

**运行环境**: {platform.system()}
**关键技能**: pandas, numpy, seaborn, matplotlib, scikit-learn, xgboost, scipy...
**可视化风格**: Nature/Science 期刊级别

1. 文件处理规则  
    ① 所有用户文件均已预先上传到工作目录  
    ② 不要检查文件是否存在 —— 假设文件已存在  
    ③ 使用相对路径直接访问文件 (例如：`pd.read_csv("data.csv")`)  
    ④ Excel 文件必须使用 `pd.read_excel()`  

2. 输出目录与文件规则  
    ① 在开始运行前，必须为 EDA、每个问题以及敏感性分析自动创建输出目录结构。  

    ② EDA 作为单独模块：  
        Ⅰ `eda/eda.py`  
        Ⅱ 包含 `datasets/`、`figures/`、`reports/`  
        Ⅲ 报告命名为 `report_eda.txt`  

    ③ 每个 `ques1 ... quesN` 目录下必须包含 3 个子目录：  
        Ⅰ `datasets/` ：存放中间计算数据（CSV、Excel、临时结果）  
        Ⅱ `figures/` ：存放图像（PNG、JPG、PDF 等）  
        Ⅲ `reports/` ：存放最终报告（统一为 TXT 文件，命名为 `report_ques1.txt` ... `report_quesN.txt`）  

3. 代码分块标记规则  
    ① 每个任务（问题）脚本文件开头必须写明分块标记：  
        Ⅰ EDA: `# %% eda`  
        Ⅱ 每个问题: `# %% quesN`  
        Ⅲ 敏感性分析: `# %% sensitivity_analysis`  

    ② 分块标记必须在文件开头第一行，且保持唯一。  

    ③ EDA 作为单独模块：  
        Ⅰ `eda/sensitivity_analysis.py`  
        Ⅱ 同样包含 `datasets/`、`figures/`、`reports/`  
        Ⅲ 报告命名为 `report_eda.txt`  

    ④ 文件命名规范：  
        Ⅰ 数据文件：`data_<描述>.csv` （如 `data_cleaned.csv`，`data_features.xlsx`）  
        Ⅱ 图像文件：`fig_<描述>.png` （如 `fig_correlation.png`，`fig_model_performance.png`）  
        Ⅲ 报告文件：`report_eda.txt`、`report_ques1.txt` ... `report_quesN.txt`、`report_sensitivity.txt`  

    ⑤ 目录结构示例（假设 ques_count=5）：  
        ```
        eda/
        ├── eda.py
        ├── datasets/
        ├── figures/
        └── reports/
        ques1/
        ├── ques1.py
        ├── datasets/
        ├── figures/
        └── reports/
        ques2/
        ├── ques2.py
        ├── datasets/
        ├── figures/
        └── reports/
        ques3/
        ├── ques3.py
        ├── datasets/
        ├── figures/
        └── reports/
        ques4/
        ├── ques4.py
        ├── datasets/
        ├── figures/
        └── reports/
        ques5/
        ├── ques5.py
        ├── datasets/
        ├── figures/
        └── reports/
        ques6/
        ├── ques6.py
        ├── datasets/
        ├── figures/
        └── reports/
        sensitivity_analysis/
        ├── sensitivity_analysis.py
        ├── datasets/
        ├── figures/
        └── reports/
        ```

4. 超大 CSV 文件处理协议  
    ① 使用 `pd.read_csv(chunksize=...)` 分块读取  
    ② 导入时优化 dtype (例如：`dtype={{'id': 'int32'}}`)  
    ③ 使用 `low_memory=False`  
    ④ 将字符串列转换为分类类型 (category)  
    ⑤ 按批次处理数据  
    ⑥ 避免对完整 DataFrame 就地操作  
    ⑦ 及时删除中间对象释放内存  

5. 编码规范  
    ① 正确示例  
        ```python
        df["婴儿行为特征"] = "矛盾型"  # 中文必须用双引号
        df = pd.read_csv("特大数据集.csv", chunksize=100000)
        ```

    ② 错误示例  
        ```python
        df['\\u5a74\\u513f\\u884c\\u4e3a\\u7279\\u5f81']  # 禁止使用 Unicode 转义
        ```

6. 可视化要求
   ① 优先使用 Seaborn（Nature/Science 风格）
   ② 次选 Matplotlib
   ③ 必须做到：
        Ⅰ 正确处理中文显示
        Ⅱ 文件命名语义化（如 "fig_correlation.png"）
        Ⅲ 图像保存到对应问题目录的 `figures/`
        Ⅳ 输出模型评估结果
    ④ 如果用到了sns以及matplotlib请必须注意导入顺序,sns风格必须要在中文设置转义字体之前中文字体才能正常渲染如下：
        ```
        import seaborn as sns
        import matplotlib.pyplot as plt

        # 设置科学出版风格的绘图
        sns.set_style("whitegrid")
        sns.set_context("paper", font_scale=1.2)

        # 设置中文字体支持
        plt.rcParams["font.sans-serif"] = ["SimHei", "Arial Unicode MS", "DejaVu Sans"]
        plt.rcParams["axes.unicode_minus"] = False
        ```

7. 执行原则
   ① 自动完成任务，不要等待用户确认
   ② 失败时：分析 → 调试 → 简化方法 → 验证可行 → 优化 → 继续
   ③ 回复必须保持中文
   ④ 在关键步骤生成可视化并保存
   ⑤ 完成前检查：
        Ⅰ 所有请求的输出是否生成
        Ⅱ 文件是否保存正确
        Ⅲ 数据处理流程是否完整

8. 性能优化关键点
   ① 优先使用向量化操作替代循环
   ② 使用高效数据结构（如稀疏矩阵 csr_matrix）
   ③ 尽可能进行并行计算
   ④ 监控内存使用
   ⑤ 及时释放未使用的资源
"""


def get_writer_prompt(
    format_output: FormatOutPut = FormatOutPut.Markdown,
):
    return f"""
1. 角色定义
    你是一名数学建模竞赛的专业写作者，擅长技术文档撰写与结果整合。必须使用中文回复。

2. 核心任务
    ① 使用提供的题目信息与解题内容撰写竞赛论文（基于 system 提供的 JSON + 各部分内容）
    ② 严格遵循 {format_output} 格式输出（输出必须是纯 {format_output} 内容，不包含代码块标记或多余的元信息）
    ③ 【重要】禁止任何联网检索或调用外部文献/工具；仅基于本地数据与已生成结果组织全文

3. 目录结构与素材来源（写作时仅能引用这些位置的素材）
    ① EDA：`eda/`（图像在 `eda/figures/`）
    ② 各问题：`ques1/`、`ques2/`、…、`quesN/`（图像在各自的 `quesN/figures/`）
    ③ 敏感性分析：`sensitivity_analysis/`（图像在 `sensitivity_analysis/figures/`）

4. 严格的图片引用规则（非常重要）
    ① **禁止**使用裸文件名或随意路径（例如 `![图](fig.png)`、`![图](../fig.png)`、或 URL）
    ② **必须**使用结构化相对路径，并且只能从系统提供的**可用图片清单**中选择：
        Ⅰ、来自 EDA 的图：`![说明文字](eda/figures/文件名.ext)`
        Ⅱ、来自第 N 问的图：`![说明文字](quesN/figures/文件名.ext)`（N 为具体数字）
        Ⅲ、来自敏感性分析的图：`![说明文字](sensitivity_analysis/figures/文件名.ext)`
    ③ 图片引用行格式与位置：
        a. 图片引用必须单独一行，且位于相关段落后的**下一行**；
        b. 文件名需语义化（例如 `fig_correlation.png`、`fig_model_performance.png`）；
        c. 禁止绝对路径、上级目录（`../`）或网络链接。
    ④ 校验要求（写作输出中必须自检）：
        Ⅰ、所有 `![]()` 链接必须完全匹配可用图片清单中的条目；
        Ⅱ、只允许出现在 **EDA、模型建立与求解（quesN）、敏感性分析** 这三类部分；
        Ⅲ、每张图在全文中**只能引用一次**；
        Ⅳ、不符合时不得自拟文件名

5. 数学与排版规范
    ① 行内公式：`$...$`；独立公式：`$$...$$`
    ② 表格：仅用 Markdown 表格语法（不要插入 HTML 表格）
    ③ 示例图片引用格式：  
        `![基线模型精度对比](ques2/figures/fig_model_performance.png)`

6. 引用与依据（本地优先，禁止联网）
    ① 禁止联网检索与任何外部 API；仅可使用用户提供/本地已有的资料作为依据
    ② 如确需引用，请使用“就地脚注”一次性给出：`{{[^k]: 资料说明或本地来源}}`
    ③ 若缺少可用来源，直接给出基于模型与结果的机理性解释，**不要**尝试补充外部文献

7. 写作与结构要求（每级说明其用途）
    ① 语言风格：中文、学术规范、条理清晰、句式适度紧凑
    ② 每一节需要处：
        Ⅰ、插入对应图像的**结构化路径**引用（见“图片引用规则”）
        Ⅱ、给出关键结论并基于图表进行量化说明

8. 质量与一致性自检（在输出前必须做）
    ① **图像路径一致性**：
        a. 允许前缀：`eda/figures/`、`quesN/figures/`（N 为正整数）、`sensitivity_analysis/figures/`；
        b. 其他前缀必须被修正；
    ② **引用唯一性**（若有脚注）：
        a. 确保 `[^k]` 编号不重复，且每条脚注仅出现一次；
        b. 确保每张图只在全文中出现一次；
    ③ **图片就近引用**：图片语句必须紧跟相关段落后的下一行；
    ④ **禁止额外文本**：输出必须为纯 {format_output} 内容，不得包含调试语句、内部说明或多余注释

9. 异常处理与执行原则
    ① 需要理论依据时：优先用本地结果/已有说明进行机理性论证；**不要**调用任何外部检索或工具
    ② 数据解释需进一步分析：引用现有本地分析结果与图表；如缺少素材，明确说明“待生成的本地图表占位”，但不要外部检索
"""


def get_reflection_prompt(error_message, code) -> str:
    return f"""The code execution encountered an error:
{error_message}

Please analyze the error, identify the cause, and provide a corrected version of the code. 
Consider:
1. Syntax errors
2. Missing imports
3. Incorrect variable names or types
4. File path issues
5. Any other potential issues
6. Don't ask user any thing about how to do and next to do,just do it by yourself.

Previous code:
{code}

Please provide an explanation of what went wrong and Remenber call the function tools to retry 
"""


def get_completion_check_prompt(prompt, text_to_gpt) -> str:
    return f"""
Please analyze the current state and determine if the task is fully completed:

Original task: {prompt}

Latest execution results:
{text_to_gpt}

Consider:
1. Have all required data processing steps been completed?
2. Have all necessary files been saved?
3. Are there any remaining steps needed?
4. Is the output satisfactory and complete?
5. If the task is complete, please provide a short summary of what was accomplished and don't call function tool.
6. If the task is not complete, please rethink how to do and call function tool
7. Don't ask user any thing about how to do and next to do,just do it by yourself
8. have a good visualization?
"""


================================================================================
E:\repo1\MathModelAgent-python\backend\app\core\workflow.py 的内容:
================================================================================
# app/core/workflow.py

from app.core.agents import WriterAgent, CoderAgent, CoordinatorAgent, ModelerAgent
from app.schemas.request import Problem
from app.schemas.response import SystemMessage
from app.tools.openalex_scholar import OpenAlexScholar
from app.utils.log_util import logger
from app.utils.common_utils import create_work_dir, get_config_template
from app.models.user_output import UserOutput
from app.config.setting import settings
from app.tools.interpreter_factory import create_interpreter
from app.services.redis_manager import redis_manager
from app.tools.notebook_serializer import NotebookSerializer
from app.core.flows import Flows
from app.core.llm.llm_factory import LLMFactory
from app.tools.png_paths import collect_png_paths_by_task  # 扫描 PNG 路径


class WorkFlow:
    def __init__(self):
        pass

    def execute(self) -> str:
        # RichPrinter.workflow_start()
        # RichPrinter.workflow_end()
        pass


class MathModelWorkFlow(WorkFlow):
    task_id: str  #
    work_dir: str  # workflow work dir
    ques_count: int = 0  # 问题数量
    questions: dict[str, str | int] = {}  # 问题

    async def execute(self, problem: Problem):
        self.task_id = problem.task_id
        self.work_dir = create_work_dir(self.task_id)

        llm_factory = LLMFactory(self.task_id)
        coordinator_llm, modeler_llm, coder_llm, writer_llm = llm_factory.get_all_llms()

        coordinator_agent = CoordinatorAgent(self.task_id, coordinator_llm)

        await redis_manager.publish_message(
            self.task_id,
            SystemMessage(content="识别用户意图和拆解问题 ing..."),
        )

        try:
            coordinator_response = await coordinator_agent.run(problem.ques_all)
            self.questions = coordinator_response.questions
            self.ques_count = coordinator_response.ques_count
        except Exception as e:
            logger.error(f"CoordinatorAgent 执行失败: {e}")
            await redis_manager.publish_message(
                self.task_id,
                SystemMessage(content=f"识别/拆解失败：{e}", type="error"),
            )
            raise

        await redis_manager.publish_message(
            self.task_id,
            SystemMessage(content="识别用户意图和拆解问题完成，任务转交给建模手"),
        )

        await redis_manager.publish_message(
            self.task_id,
            SystemMessage(content="建模手开始建模 ing..."),
        )

        modeler_agent = ModelerAgent(self.task_id, modeler_llm)

        try:
            modeler_response = await modeler_agent.run(coordinator_response)
        except Exception as e:
            logger.error(f"ModelerAgent 执行失败: {e}")
            await redis_manager.publish_message(
                self.task_id,
                SystemMessage(content=f"建模失败：{e}", type="error"),
            )
            raise

        user_output = UserOutput(work_dir=self.work_dir, ques_count=self.ques_count)

        await redis_manager.publish_message(
            self.task_id,
            SystemMessage(content="正在创建代码沙盒环境"),
        )

        notebook_serializer = NotebookSerializer(work_dir=self.work_dir)
        try:
            code_interpreter = await create_interpreter(
                kind="local",
                task_id=self.task_id,
                work_dir=self.work_dir,
                notebook_serializer=notebook_serializer,
                timeout=36000,
            )
        except Exception as e:
            await redis_manager.publish_message(
                self.task_id,
                SystemMessage(content=f"创建沙盒失败：{e}", type="error"),
            )
            raise

        # ❶ 删掉这一整段（学术检索实例创建）
        # scholar = OpenAlexScholar(task_id=self.task_id, email=settings.OPENALEX_EMAIL)

        await redis_manager.publish_message(
            self.task_id,
            SystemMessage(content="创建完成"),
        )

        await redis_manager.publish_message(
            self.task_id,
            SystemMessage(content="初始化代码手"),
        )

        coder_agent = CoderAgent(
            task_id=problem.task_id,
            model=coder_llm,
            work_dir=self.work_dir,
            max_chat_turns=settings.MAX_CHAT_TURNS,
            max_retries=settings.MAX_RETRIES,
            code_interpreter=code_interpreter,
        )

        # ❷ 创建 WriterAgent 时，不再注入 scholar（显式传 None，更直观）
        writer_agent = WriterAgent(
            task_id=problem.task_id,
            model=writer_llm,
            comp_template=problem.comp_template,
            format_output=problem.format_output,
            scholar=None,  # 禁用外部检索
        )

        flows = Flows(self.questions)

        # ============================ solution steps ============================
        solution_flows = flows.get_solution_flows(self.questions, modeler_response)
        config_template = get_config_template(problem.comp_template)

        for key, value in solution_flows.items():
            await redis_manager.publish_message(
                self.task_id,
                SystemMessage(content=f"代码手开始求解 {key}"),
            )

            try:
                coder_response = await coder_agent.run(prompt=value["coder_prompt"], subtask_title=key)
            except Exception as e:
                await redis_manager.publish_message(
                    self.task_id,
                    SystemMessage(content=f"代码手求解 {key} 失败：{e}", type="error"),
                )
                raise

            await redis_manager.publish_message(
                self.task_id,
                SystemMessage(content=f"代码手求解成功 {key}", type="success"),
            )

            writer_prompt = flows.get_writer_prompt(
                key,
                coder_response.code_response,
                code_interpreter,
                config_template,
            )

            await redis_manager.publish_message(
                self.task_id,
                SystemMessage(content=f"论文手开始写 {key} 部分"),
            )

            # 扫描全部可用图片
            all_images_raw = collect_png_paths_by_task(self.task_id) or []

            # 规范化为相对路径（去掉可能的 task_id/ 前缀）
            prefix = f"{self.task_id}/"
            all_images = [p[len(prefix) :] if p.startswith(prefix) else p for p in all_images_raw]

            if key == "eda":
                available_images = [p for p in all_images if p.startswith("eda/figures/")]
            elif key.startswith("ques"):
                available_images = [p for p in all_images if p.startswith(f"{key}/figures/")]
            elif key == "sensitivity_analysis":
                available_images = [p for p in all_images if p.startswith("sensitivity_analysis/figures/")]
            else:
                available_images = []

            try:
                writer_response = await writer_agent.run(
                    writer_prompt,
                    available_images=available_images,
                    sub_title=key,
                )
            except Exception as e:
                await redis_manager.publish_message(
                    self.task_id,
                    SystemMessage(content=f"论文手写作 {key} 失败：{e}", type="error"),
                )
                raise

            await redis_manager.publish_message(
                self.task_id,
                SystemMessage(content=f"论文手完成 {key} 部分"),
            )

            user_output.set_res(key, writer_response)

        # 关闭沙盒
        try:
            await code_interpreter.cleanup()
        except Exception as e:
            logger.warning(f"清理沙盒出现问题：{e}")
        finally:
            logger.info(user_output.get_res())

        # ============================ write steps ============================
        write_flows = flows.get_write_flows(user_output, config_template, problem.ques_all)
        for key, value in write_flows.items():
            await redis_manager.publish_message(
                self.task_id,
                SystemMessage(content=f"论文手开始写 {key} 部分"),
            )

            all_images = collect_png_paths_by_task(self.task_id) or []

            if key == "eda":
                available_images = [p for p in all_images if p.startswith("eda/figures/")]
            elif key.startswith("ques"):
                available_images = [p for p in all_images if p.startswith(f"{key}/figures/")]
            elif key == "sensitivity_analysis":
                available_images = [p for p in all_images if p.startswith("sensitivity_analysis/figures/")]
            else:
                available_images = []

            try:
                writer_response = await writer_agent.run(
                    prompt=value,
                    available_images=available_images,
                    sub_title=key,
                )
            except Exception as e:
                await redis_manager.publish_message(
                    self.task_id,
                    SystemMessage(content=f"论文手写作 {key} 失败：{e}", type="error"),
                )
                raise

            user_output.set_res(key, writer_response)

        logger.info(user_output.get_res())
        user_output.save_result()


================================================================================
E:\repo1\MathModelAgent-python\backend\app\core\agents\agent.py 的内容:
================================================================================
# app/core/agents/agent.py

import json
from app.core.llm.llm import LLM, simple_chat
from app.utils.log_util import logger
from icecream import ic
from litellm import token_counter  # 用于按 token 估算

# 统一文本工具 / JSON 修复器
from app.tools.text_sanitizer import TextSanitizer as TS
from app.tools.json_fixer import JsonFixer  # 提供 LLM 重建修复 + 本地兜底

# 软阈值：优先在到达硬上限前做清理，避免 400/ContextWindowExceeded
SOFT_TOKEN_LIMIT = 100_000  # 可按需调整


class Agent:
    def __init__(
        self,
        task_id: str,
        model: LLM,
        max_chat_turns: int = 500,  # 单个agent最大对话轮次
        max_memory: int = 100,  # 最大记忆轮次（条数兜底）
    ) -> None:
        self.task_id = task_id
        self.model = model
        self.chat_history: list[dict] = []  # 存储对话历史（只包含 system/user/assistant/tool）
        self.max_chat_turns = max_chat_turns
        self.current_chat_turns = 0
        self.max_memory = max_memory
        self._inited = False  # 仅首次注入 system

    # ---------------- 公用小工具（供子类直接调用） ---------------- #

    @staticmethod
    def sanitize_text_for_history(text: str) -> str:
        """统一的历史入库清洗：去控制字符（保留 \t \n \r）+ 去 ANSI 颜色控制序列。"""
        if text is None:
            return ""
        text = TS.clean_control_chars(text, keep_whitespace=True)
        text = TS.strip_ansi(text)
        return text

    async def fix_and_parse_json(self, raw_text: str):
        """
        一步完成：提取/剥离围栏 → 修非法转义 → json.loads → 失败则 JsonFixer（含一次 LLM 重建修复）
        返回: (obj, stage)；obj 解析失败时为 None，stage 记录修复阶段。
        """
        # 预清洗：控制字符 + 常见瑕疵
        prepared = TS.clean_control_chars(raw_text or "", keep_whitespace=True)
        prepared = TS.normalize_common_glitches(prepared)

        # 直接交给 JsonFixer（其内部会 strip fences、修非法转义，并尝试 json.loads；
        # 如失败，再调用一次 LLM 进行重建修复）
        obj, stage = await JsonFixer.fix_and_parse(
            raw=prepared,
            llm=self.model,  # 若不想用二次 LLM，可改为 llm=None
            agent_name=f"{self.__class__.__name__}.JsonFixer",
        )
        return obj, stage

    # ---------------- 基类默认对话 ---------------- #

    async def run(self, prompt: str, system_prompt: str, sub_title: str) -> str:
        """
        执行agent的对话并返回结果（基类简单实现；复杂流程请在子类覆盖）
        """
        try:
            logger.info(f"{self.__class__.__name__}:开始:执行对话")
            self.current_chat_turns = 0  # 重置对话轮次计数器

            # 只在首次运行注入 system，避免同一 system 多次堆叠
            if not self._inited:
                await self.append_chat_history({"role": "system", "content": system_prompt})
                self._inited = True

            await self.append_chat_history({"role": "user", "content": prompt})

            # 获取历史消息用于本次对话
            response = await self.model.chat(
                history=self.chat_history,
                agent_name=self.__class__.__name__,
                sub_title=sub_title,
            )
            response_content = getattr(response.choices[0].message, "content", "") or ""
            response_content = self.sanitize_text_for_history(response_content)

            self.chat_history.append({"role": "assistant", "content": response_content})
            logger.info(f"{self.__class__.__name__}:完成:执行对话")
            return response_content
        except Exception as e:
            error_msg = f"执行过程中遇到错误: {str(e)}"
            logger.error(f"Agent执行失败: {str(e)}")
            return error_msg

    # ---------------- 历史入库：统一清洗与规范化 ---------------- #

    async def append_chat_history(self, msg: dict) -> None:
        """
        稳健的消息追加函数 - 标准化为 OpenAI Chat Completions 规范（只用 system/user/assistant/tool）
        功能：
        1) 规范化入参（对象→dict）
        2) 强制保证 msg['content'] 为字符串（绝不为 None）
        3) 对工具响应（role='tool'）尽量抽取可读文本
        4) 标准化 tool_calls（arguments→字符串；type=function）
        5) 入库前统一清洗（控制字符/ANSI）
        6) 合并相邻 user / 触发内存清理
        """
        # —— 规范化入参 —— #
        if not isinstance(msg, dict):
            try:
                content = getattr(msg, "content", "") or ""
                role = getattr(msg, "role", "assistant")
                tool_calls = getattr(msg, "tool_calls", None)
                msg = {"role": role, "content": content, "tool_calls": tool_calls}
            except Exception:
                msg = {"role": "assistant", "content": repr(msg)}

        # 保证 role 字段存在且为字符串
        msg["role"] = msg.get("role", "assistant") or "assistant"

        # —— 确保 content 是字符串 —— #
        raw_content = msg.get("content", "")
        if raw_content is None:
            raw_content = ""

        # 如果是 tool 且 content 为空，尝试从常见字段中抽取文本
        if msg["role"] == "tool" and (not raw_content or str(raw_content).strip() == ""):
            extracted_parts = []

            # 1) 优先查看 msg.get("output") 或常见别名
            out = msg.get("output") or msg.get("outputs") or msg.get("result") or msg.get("results")
            if out is not None:
                if isinstance(out, (list, tuple)):
                    for item in out:
                        if isinstance(item, dict):
                            for k in ("msg", "message", "text", "result", "content"):
                                v = item.get(k)
                                if v:
                                    extracted_parts.append(str(v))
                                    break
                            else:
                                try:
                                    extracted_parts.append(json.dumps(item, ensure_ascii=False))
                                except Exception:
                                    extracted_parts.append(str(item))
                        else:
                            extracted_parts.append(str(item))
                elif isinstance(out, dict):
                    for k in ("msg", "message", "text", "result", "content"):
                        v = out.get(k)
                        if v:
                            extracted_parts.append(str(v))
                            break
                    else:
                        try:
                            extracted_parts.append(json.dumps(out, ensure_ascii=False))
                        except Exception:
                            extracted_parts.append(str(out))
                else:
                    extracted_parts.append(str(out))

            # 2) 再尝试其它常见字段
            if not extracted_parts:
                for k in ("text", "stdout", "stderr", "data", "value"):
                    v = msg.get(k)
                    if v:
                        if isinstance(v, (list, dict)):
                            try:
                                extracted_parts.append(json.dumps(v, ensure_ascii=False))
                            except Exception:
                                extracted_parts.append(str(v))
                        else:
                            extracted_parts.append(str(v))

            # 3) 尝试从嵌套的 tool_result / tool_response / tool_outputs 中抽取
            if not extracted_parts:
                tc = msg.get("tool_result") or msg.get("tool_response") or msg.get("tool_outputs")
                if tc is not None:
                    try:
                        extracted_parts.append(json.dumps(tc, ensure_ascii=False))
                    except Exception:
                        extracted_parts.append(str(tc))

            # 最终填充 content（去重并按行拼接）
            if extracted_parts:
                seen = set()
                parts = []
                for p in extracted_parts:
                    s = (p or "").strip()
                    if not s:
                        continue
                    if s in seen:
                        continue
                    seen.add(s)
                    parts.append(s)
                raw_content = "\n".join(parts)

        # 最终确保为字符串
        try:
            if isinstance(raw_content, str):
                final_content = raw_content
            else:
                final_content = str(raw_content)
        except Exception:
            final_content = ""

        # 入库前统一清洗：控制字符 + ANSI
        final_content = self.sanitize_text_for_history(final_content)
        msg["content"] = final_content

        # —— 合并相邻 user —— #
        ic(f"添加消息: role={msg.get('role')}, 当前历史长度={len(self.chat_history)}")
        last = self.chat_history[-1] if self.chat_history else None
        if last and last.get("role") == "user" and msg.get("role") == "user":
            last["content"] = (last.get("content") or "") + "\n\n" + (msg.get("content") or "")
            ic("相邻 user 合并，避免连续 user 触发 400")
            return

        # —— 标准化 tool_calls —— #
        if "tool_calls" in msg and isinstance(msg["tool_calls"], (list, tuple)):
            try:
                lightweight = []
                for tc in msg["tool_calls"]:
                    # 兼容对象或字典
                    tc_id = getattr(tc, "id", None) or (tc.get("id") if isinstance(tc, dict) else None)
                    fn = getattr(tc, "function", None) or (tc.get("function") if isinstance(tc, dict) else None)
                    fn_name = (
                        getattr(fn, "name", None)
                        if fn is not None
                        else (fn.get("name") if isinstance(fn, dict) else None)
                    )
                    fn_args = (
                        getattr(fn, "arguments", None)
                        if fn is not None
                        else (fn.get("arguments") if isinstance(fn, dict) else None)
                    )

                    # arguments 必须是字符串
                    if isinstance(fn_args, (dict, list)):
                        try:
                            fn_args = json.dumps(fn_args, ensure_ascii=False)
                        except Exception:
                            fn_args = str(fn_args)
                    elif fn_args is None:
                        fn_args = ""

                    # 必须包含 type: "function"
                    lightweight.append(
                        {"id": tc_id, "type": "function", "function": {"name": fn_name, "arguments": fn_args}}
                    )
                msg["tool_calls"] = lightweight
            except Exception:
                # 出错就移除，避免发不出去
                msg.pop("tool_calls", None)

        # 为 tool 消息尽可能设置 tool_call_id（如果存在）
        if msg.get("role") == "tool" and "tool_call_id" not in msg:
            msg["tool_call_id"] = msg.get("tool_call_id") or msg.get("id") or msg.get("tool_id") or None

        # 最终把消息追加
        self.chat_history.append(msg)
        ic(f"添加后历史长度={len(self.chat_history)}")
        self.chat_history = self._ensure_first_after_system_user(self.chat_history)

        # —— 触发内存清理 —— #
        def _approx_total_tokens(messages):
            total = 0
            for m in messages:
                if not isinstance(m, dict):
                    continue
                c = m.get("content") or ""
                try:
                    total += token_counter(self.model.model, c)
                except Exception:
                    total += max(1, len(c) // 3)
            return total

        # 工具响应（tool）不触发内存清理
        if msg.get("role") != "tool":
            ic("触发内存清理判定")
            try:
                total_tokens = _approx_total_tokens(self.chat_history)
            except Exception:
                total_tokens = SOFT_TOKEN_LIMIT - 1
            if total_tokens > SOFT_TOKEN_LIMIT:
                ic(f"超过软阈值 {SOFT_TOKEN_LIMIT} tokens，执行 clear_memory()")
                await self.clear_memory()
            elif len(self.chat_history) > self.max_memory:
                ic("超过消息条数兜底阈值，执行 clear_memory()")
                await self.clear_memory()
        else:
            ic("跳过内存清理(tool 消息)")

    # ---------------- 内存清理：重量版总结 + 安全切割 ---------------- #

    async def clear_memory(self):
        """当聊天历史超过限制时，使用 simple_chat 进行“重量版”总结压缩"""
        ic(f"检查内存清理: 当前={len(self.chat_history)}, 最大(条数兜底)={self.max_memory}")
        ic("开始内存清理")
        logger.info(f"{self.__class__.__name__}:开始清除记忆，当前记录数：{len(self.chat_history)}")

        try:
            # 保留第一条系统消息
            system_msg = (
                self.chat_history[0] if self.chat_history and self.chat_history[0].get("role") == "system" else None
            )

            # 查找需要保留的消息范围 - 保留最后几条完整的对话和工具调用
            preserve_start_idx = self._find_safe_preserve_point()
            ic(f"保留起始索引: {preserve_start_idx}")

            # 需要总结的消息范围
            start_idx = 1 if system_msg else 0
            end_idx = preserve_start_idx
            ic(f"总结范围: {start_idx} -> {end_idx}")

            if end_idx > start_idx:
                # 构造摘要提示，仅传“需要总结的片段”
                summarize_history = []
                if system_msg:
                    summarize_history.append(system_msg)

                summarize_history.append(
                    {
                        "role": "user",
                        "content": (
                            "请简洁总结以下对话的关键内容和重要结论，保留重要的上下文信息：\n\n"
                            f"{self._format_history_for_summary(self.chat_history[start_idx:end_idx])}"
                        ),
                    }
                )

                # 调用 simple_chat 进行总结
                summary = await simple_chat(self.model, summarize_history)

                # 重构聊天历史：系统消息 + 摘要 + 保留的消息（最后若干条）
                new_history = []
                if system_msg:
                    new_history.append(system_msg)

                new_history.append({"role": "user", "content": f"[历史对话总结-仅供上下文，无需回复]\n{summary}"})
                new_history.extend(self.chat_history[preserve_start_idx:])

                # 确保 system 后第一条是 user
                new_history = self._ensure_first_after_system_user(new_history)

                self.chat_history = new_history
                ic(f"内存清理完成，新历史长度: {len(self.chat_history)}")
                logger.info(f"{self.__class__.__name__}:记忆清除完成，压缩至：{len(self.chat_history)}条记录")
            else:
                logger.info(f"{self.__class__.__name__}:无需清除记忆，记录数量合理")

        except Exception as e:
            logger.error(f"记忆清除失败，使用简单切片策略: {str(e)}")
            # 如果总结失败，回退到安全的策略：保留系统消息和最后几条消息，确保工具调用完整性
            safe_history = self._get_safe_fallback_history()
            self.chat_history = safe_history

    # ---------------- 切割点选择与辅助 ---------------- #

    def _find_safe_preserve_point(self) -> int:
        """找到安全的保留起始点，确保不会破坏工具调用序列"""
        # 最少保留最后10条消息，确保基本对话完整性
        min_preserve = min(10, len(self.chat_history))
        preserve_start = len(self.chat_history) - min_preserve
        ic(f"寻找安全保留点: 历史长度={len(self.chat_history)}, 最少保留={min_preserve}, 开始位置={preserve_start}")

        # 从后往前查找，确保不会在工具调用序列中间切断
        for i in range(preserve_start, -1, -1):
            if i >= len(self.chat_history):
                continue

            is_safe = self._is_safe_cut_point(i)
            ic(f"检查位置 {i}: 安全={is_safe}")
            if is_safe:
                ic(f"找到安全保留点: {i}")
                return i

        # 如果找不到安全点，至少保留最后1条消息
        fallback = len(self.chat_history) - 1
        ic(f"未找到安全点，使用备用位置: {fallback}")
        return fallback

    def _is_safe_cut_point(self, start_idx: int) -> bool:
        """检查从指定位置开始切割是否安全（不会产生孤立的 tool 消息）"""
        if start_idx >= len(self.chat_history):
            ic(f"切割点 {start_idx} >= 历史长度，安全")
            return True

        # 检查切割后的消息序列是否有孤立的 tool 消息
        tool_messages = []
        for i in range(start_idx, len(self.chat_history)):
            msg = self.chat_history[i]
            if isinstance(msg, dict) and msg.get("role") == "tool":
                tool_call_id = msg.get("tool_call_id")
                tool_messages.append((i, tool_call_id))
                ic(f"发现工具响应消息在位置 {i}, tool_call_id={tool_call_id}")

                # 向前查找对应的tool_calls消息
                if tool_call_id:
                    found_tool_call = False
                    for j in range(start_idx, i):
                        prev_msg = self.chat_history[j]
                        if isinstance(prev_msg, dict) and "tool_calls" in prev_msg and prev_msg["tool_calls"]:
                            for tool_call in prev_msg["tool_calls"]:
                                tid = None
                                if isinstance(tool_call, dict):
                                    tid = tool_call.get("id")
                                else:
                                    tid = getattr(tool_call, "id", None)
                                if tid == tool_call_id:
                                    found_tool_call = True
                                    ic(f"找到对应的tool_call在位置 {j}")
                                    break
                            if found_tool_call:
                                break

                    if not found_tool_call:
                        ic(f"❌ 工具响应 {tool_call_id} 没有找到对应的tool_call，切割点不安全")
                        return False

        ic(f"切割点 {start_idx} 安全，检查了 {len(tool_messages)} 个工具响应消息")
        return True

    def _get_safe_fallback_history(self) -> list:
        """获取安全的后备历史记录，确保不会有孤立的 tool 消息"""
        if not self.chat_history:
            return []

        safe_history = []
        if self.chat_history and self.chat_history[0].get("role") == "system":
            safe_history.append(self.chat_history[0])

        # 从后往前查找安全的消息序列
        for preserve_count in range(1, min(4, len(self.chat_history)) + 1):
            start_idx = len(self.chat_history) - preserve_count
            if self._is_safe_cut_point(start_idx):
                safe_history.extend(self.chat_history[start_idx:])
                return safe_history

        # 如果都不安全，只保留最后一条非 tool 消息
        for i in range(len(self.chat_history) - 1, -1, -1):
            msg = self.chat_history[i]
            if isinstance(msg, dict) and msg.get("role") != "tool":
                safe_history.append(msg)
                break

        return safe_history

    def _find_last_unmatched_tool_call(self) -> int | None:
        """查找最后一个未匹配的tool call的索引"""
        ic("开始查找未匹配的tool_call")

        for i in range(len(self.chat_history) - 1, -1, -1):
            msg = self.chat_history[i]

            # 检查是否是包含tool_calls的消息
            if isinstance(msg, dict) and "tool_calls" in msg and msg["tool_calls"]:
                ic(f"在位置 {i} 发现tool_calls消息")

                # 检查每个tool call是否都有对应的 response（function/tool）
                for tool_call in msg["tool_calls"]:
                    tool_call_id = (
                        tool_call.get("id") if isinstance(tool_call, dict) else getattr(tool_call, "id", None)
                    )
                    ic(f"检查tool_call_id: {tool_call_id}")

                    if tool_call_id:
                        response_found = False
                        for j in range(i + 1, len(self.chat_history)):
                            response_msg = self.chat_history[j]
                            if (
                                isinstance(response_msg, dict)
                                and response_msg.get("role") in ("tool", "function")
                                and response_msg.get("tool_call_id") == tool_call_id
                            ):
                                ic(f"找到匹配的工具响应在位置 {j}")
                                response_found = True
                                break

                        if not response_found:
                            ic(f"❌ 发现未匹配的tool_call在位置 {i}, id={tool_call_id}")
                            return i

        ic("没有发现未匹配的tool_call")
        return None

    def _format_history_for_summary(self, history: list[dict]) -> str:
        """格式化历史记录用于总结（控制长度）"""
        formatted = []
        for msg in history:
            role = msg.get("role")
            content = msg.get("content") or ""
            content = content[:500] + "..." if len(content) > 500 else content
            formatted.append(f"{role}: {content}")
        return "\n".join(formatted)

    def _ensure_first_after_system_user(self, history: list) -> list:
        """确保在 system 之后，第一条是 user（除非第一条 assistant 正在发起 tool_calls）"""
        if not history:
            return [{"role": "user", "content": "[空对话启动] 继续。"}]

        i = 0
        while i < len(history) and isinstance(history[i], dict) and history[i].get("role") == "system":
            i += 1

        if i >= len(history):
            return history + [{"role": "user", "content": "[承接上文上下文] 继续。"}]

        first_msg = history[i]
        if first_msg.get("role") != "user":
            if first_msg.get("role") == "assistant" and first_msg.get("tool_calls"):
                return history
            content = (first_msg.get("content") or "").strip()
            if first_msg.get("role") == "assistant" and content.startswith("[历史对话总结"):
                first_msg["role"] = "user"
                history[i] = first_msg
            else:
                history = history[:i] + [{"role": "user", "content": "[承接上文上下文] 继续。"}] + history[i:]
        return history


================================================================================
E:\repo1\MathModelAgent-python\backend\app\core\agents\coder_agent.py 的内容:
================================================================================
# app/core/agents/coder_agent.py

from app.core.agents.agent import Agent
from app.config.setting import settings
from app.utils.log_util import logger
from app.services.redis_manager import redis_manager
from app.schemas.response import SystemMessage, InterpreterMessage
from app.tools.base_interpreter import BaseCodeInterpreter
from app.core.llm.llm import LLM
from app.schemas.A2A import CoderToWriter
from app.core.prompts import CODER_PROMPT
from app.utils.common_utils import get_current_files
import json
from app.core.prompts import get_reflection_prompt, get_completion_check_prompt
from app.core.functions import coder_tools
from icecream import ic

# 统一的文本/代码清洗器（集中管理正则等）
from app.tools.text_sanitizer import TextSanitizer as TS


def _safe_get_code_from_arguments(args_raw) -> str:
    """
    尽可能稳妥地从 tool.arguments 中拿到 code。
    现在全部委托给 TextSanitizer.extract_code_from_arguments，以保证提取逻辑集中并可维护。
    """
    return TS.extract_code_from_arguments(args_raw)


class CoderAgent(Agent):  # 同样继承自Agent类
    def __init__(
        self,
        task_id: str,
        model: LLM,
        work_dir: str,  # 工作目录
        max_chat_turns: int = settings.MAX_CHAT_TURNS,  # 最大聊天次数
        max_retries: int = settings.MAX_RETRIES,  # 最大反思次数
        code_interpreter: BaseCodeInterpreter = None,
    ) -> None:
        super().__init__(task_id, model, max_chat_turns)
        self.work_dir = work_dir
        self.max_retries = max_retries
        self.is_first_run = True
        self.system_prompt = CODER_PROMPT
        self.code_interpreter = code_interpreter

    async def run(self, prompt: str, subtask_title: str) -> CoderToWriter:
        logger.info(f"{self.__class__.__name__}:开始:执行子任务: {subtask_title}")
        # 标记当前子任务区段，便于 interpreter 管理输出文件/图片
        self.code_interpreter.add_section(subtask_title)

        retry_count = 0
        last_error_message = ""
        executed_tool_calls = False  # 是否至少执行过一次 execute_code
        merged_prompt = None  # 首轮合并提示（如果有）
        assistant_content = ""  # 兜底：循环外返回时使用

        # 如果是第一次运行，则添加系统提示；并把“文件列表 + 子任务提示”合并为一条 user 消息
        if self.is_first_run:
            logger.info("首次运行，添加系统提示和数据集文件信息")
            self.is_first_run = False

            # 1) system 消息
            await self.append_chat_history({"role": "system", "content": self.system_prompt})

            # 2) 合并后的首条 user 消息（避免连续 user）
            files_info = f"当前文件夹下的数据集文件{get_current_files(self.work_dir, 'data')}"
            merged_prompt = f"{files_info}\n\n{subtask_title}：\n{prompt}"
            logger.info(f"添加首轮合并子任务提示: {merged_prompt}")
            await self.append_chat_history({"role": "user", "content": merged_prompt})
        else:
            # 非首次运行，正常追加一条 user 提示
            logger.info(f"添加子任务提示: {prompt}")
            await self.append_chat_history({"role": "user", "content": prompt})

        # 早期保护：若已超出最大轮次则直接报错
        if self.current_chat_turns >= self.max_chat_turns:
            logger.error(f"超过最大聊天次数: {self.max_chat_turns}")
            await redis_manager.publish_message(
                self.task_id,
                SystemMessage(content="超过最大聊天次数", type="error"),
            )
            raise Exception(f"Reached maximum number of chat turns ({self.max_chat_turns}). Task incomplete.")

        # 主循环：通过模型交互 + 工具调用完成任务
        while retry_count < self.max_retries and self.current_chat_turns < self.max_chat_turns:
            self.current_chat_turns += 1
            logger.info(f"当前对话轮次: {self.current_chat_turns}")

            response = await self.model.chat(
                history=self.chat_history,
                tools=coder_tools,
                tool_choice="auto",
                agent_name=self.__class__.__name__,
            )

            # 规范化 assistant 消息对象
            assistant_msg_obj = response.choices[0].message
            assistant_content_raw = getattr(assistant_msg_obj, "content", "") or ""
            assistant_tool_calls = getattr(assistant_msg_obj, "tool_calls", None)

            # 对 assistant 文本做三步清洗：控制字符 → 常见瑕疵 → 外层围栏
            assistant_content_clean = TS.clean_control_chars(assistant_content_raw, keep_whitespace=True)
            assistant_content_clean = TS.normalize_common_glitches(assistant_content_clean)
            assistant_content_clean = TS.strip_fences_outer_or_all(assistant_content_clean)

            # 有工具调用（常见路径）
            if assistant_tool_calls:
                logger.info("检测到工具调用")
                # 先把 assistant 内容规范化写入历史（append_chat_history 会把 tool_calls 规范化）
                await self.append_chat_history(
                    {"role": "assistant", "content": assistant_content_clean, "tool_calls": assistant_tool_calls}
                )

                # 🔍 从 tool_calls 中优先寻找第一个 execute_code 调用（更稳妥）
                tool_call = None
                for tc in assistant_tool_calls:
                    try:
                        fn = getattr(tc.function, "name", None)
                        if fn == "execute_code":
                            tool_call = tc
                            break
                    except Exception:
                        continue

                if tool_call is None:
                    # 未发现 execute_code，按未知工具处理
                    first_tc = assistant_tool_calls[0]
                    tool_id = getattr(first_tc, "id", None)
                    fn_name = getattr(first_tc.function, "name", None)
                    logger.warning(f"未发现 execute_code 调用（收到 {len(assistant_tool_calls)} 个工具），跳过处理。")
                    await self.append_chat_history(
                        {
                            "role": "tool",
                            "tool_call_id": tool_id,
                            "name": fn_name or "unknown",
                            "content": "未检测到可执行的 execute_code 调用，未执行。",
                        }
                    )
                    retry_count += 1
                    continue

                # ========= execute_code 路径 =========
                tool_id = getattr(tool_call, "id", None)
                fn_name = getattr(tool_call.function, "name", None)

                if fn_name == "execute_code":
                    executed_tool_calls = True
                    logger.info(f"调用工具: {fn_name}")
                    await redis_manager.publish_message(
                        self.task_id,
                        SystemMessage(content=f"代码手调用{fn_name}工具"),
                    )

                    # 解析代码参数（稳健版）
                    try:
                        raw_code = _safe_get_code_from_arguments(getattr(tool_call.function, "arguments", None))
                        if not isinstance(raw_code, str):
                            raw_code = str(raw_code or "")
                    except Exception as e:
                        raw_code = ""
                        logger.exception("解析 tool.arguments 失败")
                        # 工具解析报错 → 工具结果消息（role='tool'）写回
                        await self.append_chat_history(
                            {
                                "role": "tool",
                                "tool_call_id": tool_id,
                                "name": "execute_code",
                                "content": f"解析工具参数失败: {e}",
                            }
                        )
                        retry_count += 1
                        last_error_message = f"解析工具参数失败: {e}"
                        continue

                    # 兜底：若 code 为空，跳过工具调用
                    if not raw_code.strip():
                        logger.warning("代码为空，跳过工具调用")
                        await redis_manager.publish_message(
                            self.task_id,
                            SystemMessage(content="任务跳过：代码为空，未执行工具调用", type="warning"),
                        )
                        # 引导模型提供实际代码
                        await self.append_chat_history(
                            {
                                "role": "user",
                                "content": (
                                    "你提供的 execute_code.arguments 里没有有效的代码，请重新调用 execute_code 并给出可运行的 Python 代码。"
                                ),
                            }
                        )
                        retry_count += 1
                        continue

                    # ====== 下发给执行器前统一修复/规范化代码 ======
                    try:
                        # 使用 TextSanitizer 的 normalize_for_execution（集中管理）
                        code = TS.normalize_for_execution(raw_code, language="python")
                    except Exception as e:
                        # 若修复器出错，则退回到原始代码（保守策略），并记录日志
                        logger.exception(f"代码修复器失败，使用原始代码继续执行: {e}")
                        code = raw_code

                    # 将修复后的代码先发布为 InterpreterMessage（便于前端查看将要执行的代码）
                    await redis_manager.publish_message(
                        self.task_id,
                        InterpreterMessage(input={"code": code}),
                    )

                    # 执行工具调用（实际运行代码）
                    logger.info("执行工具调用")
                    try:
                        text_to_gpt, error_occurred, error_message = await self.code_interpreter.execute_code(code)
                    except Exception as e:
                        text_to_gpt, error_occurred, error_message = "", True, f"执行工具时异常: {e}"

                    # 将工具执行结果写回历史（role='tool'）
                    if error_occurred:
                        await self.append_chat_history(
                            {
                                "role": "tool",
                                "tool_call_id": tool_id,
                                "name": "execute_code",
                                "content": error_message,
                            }
                        )

                        logger.warning(f"代码执行错误: {error_message}")
                        retry_count += 1
                        logger.info(f"当前尝试次:{retry_count} / {self.max_retries}")
                        last_error_message = error_message
                        reflection_prompt = get_reflection_prompt(error_message, code)

                        await redis_manager.publish_message(
                            self.task_id,
                            SystemMessage(content="代码手反思纠正错误", type="error"),
                        )

                        # 追加 user 反思提示让模型修正（前一条是 tool 响应，顺序合法）
                        await self.append_chat_history({"role": "user", "content": reflection_prompt})
                        # 继续下一轮
                        continue
                    else:
                        # 成功执行的工具响应写回历史（role='tool'）
                        text_to_gpt_str = (
                            "\n".join(text_to_gpt) if isinstance(text_to_gpt, (list, tuple)) else str(text_to_gpt)
                        )
                        await self.append_chat_history(
                            {
                                "role": "tool",
                                "tool_call_id": tool_id,
                                "name": "execute_code",
                                "content": text_to_gpt_str,
                            }
                        )

                        # 成功执行后，让模型进行完成度自检（使用 get_completion_check_prompt）
                        prompt_for_check = merged_prompt if merged_prompt is not None else prompt
                        completion_prompt = get_completion_check_prompt(prompt_for_check, text_to_gpt_str)
                        await self.append_chat_history({"role": "user", "content": completion_prompt})

                        # 进入下一轮，由模型决定是否继续调用工具或直接总结结束
                        continue

                else:
                    # 理论上不会到这里（上面已筛过 execute_code），留做防御
                    logger.warning(f"收到未知工具调用: {fn_name}，跳过处理。")
                    await self.append_chat_history(
                        {
                            "role": "tool",  # 工具结果消息必须是 role='tool'
                            "tool_call_id": tool_id,
                            "name": fn_name or "unknown",
                            "content": "收到未知工具调用，未执行。",
                        }
                    )
                    retry_count += 1
                    continue

            else:
                # 没有 tool_calls 的 assistant 响应 —— 不要马上判定完成
                logger.info("收到 assistant 没有 tool_calls 的响应，进入完成性判定逻辑")

                # 先把 assistant 内容（清洗后）写入历史
                await self.append_chat_history({"role": "assistant", "content": assistant_content_clean})

                # 如果从未执行过任何 execute_code，则强制要求模型先执行代码
                if not executed_tool_calls:
                    logger.info("尚未执行过 execute_code，要求模型实际调用工具再总结（避免未经执行就报告完成）")
                    await redis_manager.publish_message(
                        self.task_id,
                        SystemMessage(
                            content=f"代码手尚未运行代码，请调用 execute_code 并执行用于 {subtask_title} 的代码",
                            type="info",
                        ),
                    )

                    run_code_request = (
                        "注意：你此前仅以文字说明了计划，但没有实际执行任何代码。"
                        "现在请立刻调用 `execute_code` 工具并提供要执行的 Python 代码（确保生成本子任务需要的文件/图像/报告），"
                        "不要直接总结为“任务完成”，必须先运行并在工具响应中返回执行结果。"
                    )

                    await self.append_chat_history({"role": "user", "content": run_code_request})

                    retry_count += 1
                    logger.info(f"要求模型执行代码后的重试计数: {retry_count}/{self.max_retries}")

                    if retry_count >= self.max_retries:
                        logger.error("模型多次未实际执行工具，达到最大重试次数")
                        await redis_manager.publish_message(
                            self.task_id,
                            SystemMessage(content="模型未实际执行代码，达到最大重试次数，任务失败", type="error"),
                        )
                        raise Exception(f"Model refused to execute code after {self.max_retries} attempts.")

                    # 继续下一轮，等待模型发出 tool_calls
                    continue
                else:
                    # 已至少执行过一次工具，而这次 assistant 没有发起工具调用，可视为模型在做总结
                    logger.info("已执行过工具，本次 assistant 无 tool_calls，被视为任务完成")
                    return CoderToWriter(
                        coder_response=assistant_content_clean,
                        created_images=await self.code_interpreter.get_created_images(subtask_title),
                    )

        # —— while 循环结束后的安全检查 —— #
        if retry_count >= self.max_retries:
            logger.error(f"超过最大尝试次数: {self.max_retries}")
            await redis_manager.publish_message(
                self.task_id,
                SystemMessage(content="超过最大尝试次数", type="error"),
            )
            return f"Failed to complete task after {self.max_retries} attempts. Last error: {last_error_message}"

        if self.current_chat_turns >= self.max_chat_turns:
            logger.error(f"超过最大对话轮次: {self.max_chat_turns}")
            await redis_manager.publish_message(
                self.task_id,
                SystemMessage(content="超过最大对话轮次", type="error"),
            )
            return f"Reached maximum number of chat turns ({self.max_chat_turns}). Task incomplete."

        # 循环正常结束（兜底返回最后一次 assistant 内容）
        logger.info(f"{self.__class__.__name__}:完成:执行子任务: {subtask_title}")
        return CoderToWriter(
            coder_response=assistant_content,
            created_images=await self.code_interpreter.get_created_images(subtask_title),
        )


================================================================================
E:\repo1\MathModelAgent-python\backend\app\core\agents\coordinator_agent.py 的内容:
================================================================================
# app/core/agents/coordinator_agent.py

from app.core.agents.agent import Agent
from app.core.llm.llm import LLM
from app.core.prompts import COORDINATOR_PROMPT
import json
import re
from app.utils.log_util import logger
from app.schemas.A2A import CoordinatorToModeler

# 统一的文本清洗工具
from app.tools.text_sanitizer import TextSanitizer as TS

# 通用 JSON 提取/修复/解析工具
from app.tools.json_fixer import JsonFixer


class CoordinatorAgent(Agent):
    def __init__(
        self,
        task_id: str,
        model: LLM,
        max_chat_turns: int = 100,
    ) -> None:
        super().__init__(task_id, model, max_chat_turns)
        self.system_prompt = COORDINATOR_PROMPT

    async def run(self, ques_all: str) -> CoordinatorToModeler:
        """
        将用户原始问题经 LLM 结构化为 questions(JSON)：
        1) 调用 LLM 生成结构化回答
        2) 使用 JsonFixer：提取 + 修复非法转义/围栏/坏 JSON + 解析
           - 内置本地兜底与（可选）一次 LLM 重建修复
        3) 校验字段并推断 ques_count
        4) 返回 CoordinatorToModeler
        """
        # 只注入一次 system，避免重复堆叠
        if not self._inited:
            await self.append_chat_history({"role": "system", "content": self.system_prompt})
            self._inited = True

        # 用户问题作为 user 消息
        await self.append_chat_history({"role": "user", "content": ques_all})

        # 调用模型
        response = await self.model.chat(
            history=self.chat_history,
            agent_name=self.__class__.__name__,  # LLM 层会做统一 metadata 处理
        )
        raw_text = getattr(response.choices[0].message, "content", "") or ""

        # 基础清理（尽量不破坏可读性；后续 JsonFixer 内部还有一轮清洗与抽取）
        prepared_text = TS.clean_control_chars(raw_text, keep_whitespace=True)
        prepared_text = TS.normalize_common_glitches(prepared_text)

        # 统一走 JsonFixer：一步完成 提取→修复→解析（含一次 LLM 重建与本地兜底）
        questions, stage = await JsonFixer.fix_and_parse(
            raw=prepared_text,
            llm=self.model,  # 若不希望二次调用 LLM 进行“重建修复”，可改为 llm=None
            agent_name="CoordinatorAgent.JsonFixer",
        )
        logger.info(f"[CoordinatorAgent] JsonFixer stage: {stage}")

        if questions is None:
            # 记录原始文本，便于排查
            logger.error(f"[CoordinatorAgent] 无法解析为 JSON。raw_text preview: {raw_text[:500]}")
            raise ValueError(f"JSON 解析错误（{stage}）")

        if not isinstance(questions, dict):
            raise ValueError("解析结果不是 JSON 对象（dict）。")

        # 兜底：确保 ques_count 存在且为 int
        ques_count = questions.get("ques_count")
        if not isinstance(ques_count, int):
            # 自动推断 quesN 键数量
            ques_keys = [k for k in questions.keys() if re.fullmatch(r"ques\d+", k)]
            if not ques_keys:
                raise ValueError("缺少 ques_count 且未找到任何 quesN 键。")
            ques_count = max(int(k[4:]) for k in ques_keys)
            questions["ques_count"] = ques_count

        logger.info(f"[CoordinatorAgent] questions: {json.dumps(questions, ensure_ascii=False)[:800]}")

        # 返回给后续的 ModelerAgent
        return CoordinatorToModeler(questions=questions, ques_count=ques_count)


================================================================================
E:\repo1\MathModelAgent-python\backend\app\core\agents\modeler_agent.py 的内容:
================================================================================
# app/core/agents/modeler_agent.py

from app.core.agents.agent import Agent
from app.core.llm.llm import LLM
from app.core.prompts import MODELER_PROMPT
from app.schemas.A2A import CoordinatorToModeler, ModelerToCoder
from app.utils.log_util import logger
from app.services.redis_manager import redis_manager  # 用于右侧面板
from app.schemas.response import ModelerMessage  # 右侧“建模手册”用
import json
from icecream import ic

# 将正则/清理逻辑集中到 TextSanitizer
from app.tools.text_sanitizer import TextSanitizer as TS
from app.tools.json_fixer import JsonFixer


# === 工具函数（行为与原实现等价，但委托给 TS） ===


def _cleanup_control_chars(s: str) -> str:
    """去掉会导致 json.loads 失败的控制字符"""
    return TS.clean_control_chars(s, keep_whitespace=True)


def _strip_fences(s: str) -> str:
    """去掉 ```json / ``` 围栏"""
    return TS.strip_fences_outer_or_all(s)


def _extract_first_json(text: str) -> str:
    """
    用“栈法”提取首个配平的 JSON 对象字符串，比 {.*} 更稳健：
    """
    if not text:
        return ""
    # 原实现先去掉围栏再做栈法；为了等价，直接让 TS 在外部不重复 strip（我们已在调用处 strip 过）
    # 这里假定传入 text 已为去栅栏后的字符串（与原实现一致）。
    return TS.extract_first_json_block(text, strip_fences_first=False)


def _try_json_loads(s: str):
    """尝试解析 JSON，失败返回 None"""
    try:
        return json.loads(s)
    except Exception:
        return None


class ModelerAgent(Agent):  # 继承自Agent类
    def __init__(
        self,
        task_id: str,
        model: LLM,
        max_chat_turns: int = 600,  # 添加最大对话轮次限制
    ) -> None:
        super().__init__(task_id, model, max_chat_turns)
        self.system_prompt = MODELER_PROMPT

    async def run(self, coordinator_to_modeler: CoordinatorToModeler) -> ModelerToCoder:
        """
        解析大模型返回的 JSON：
        - 清理 Markdown 围栏与控制字符
        - JsonFixer 提取+修复+解析（含 LLM 重建 & 本地兜底）
        - 严格校验为 dict，成功后发布 ModelerMessage
        """
        # 只注入一次 system
        if not self._inited:
            await self.append_chat_history({"role": "system", "content": self.system_prompt})
            self._inited = True

        await self.append_chat_history(
            {
                "role": "user",
                "content": json.dumps(coordinator_to_modeler.questions, ensure_ascii=False),
            }
        )

        # 调用模型（无需工具）
        response = await self.model.chat(
            history=self.chat_history,
            agent_name=self.__class__.__name__,
        )

        raw_content = getattr(response.choices[0].message, "content", "") or ""
        logger.debug(f"[ModelerAgent] raw preview: {raw_content[:2000]}")

        # Step1: 清理围栏与控制字符
        content = _strip_fences(_cleanup_control_chars(raw_content))

        # Step2: 一步到位：提取 + 修复 + 解析（含 LLM 重建与本地兜底）
        questions_solution, stage = await JsonFixer.fix_and_parse(
            raw=content,
            llm=self.model,  # 允许用当前 LLM 做一次“重建修复”；若不想用，可改为 llm=None
            agent_name=f"{self.__class__.__name__}.JsonFixer",
        )
        logger.info(f"[ModelerAgent] JsonFixer stage: {stage}")

        # Step3: 严格校验
        if questions_solution is None:
            raise ValueError(f"JSON 修复完全失败，无法解析（{stage}）。")
        if not isinstance(questions_solution, dict):
            raise ValueError("解析结果不是 JSON 对象（dict）。")

        ic(questions_solution)

        # Step4: 显式发布结构化 ModelerMessage —— 右侧“建模手册”面板需要这一条
        try:
            await redis_manager.publish_message(
                self.task_id,
                ModelerMessage(content=questions_solution),
            )
        except Exception as e:
            logger.warning(f"发布 ModelerMessage 失败（继续返回给后续流程）: {e}")

        # 返回给下一步（CoderAgent）
        return ModelerToCoder(questions_solution=questions_solution)


================================================================================
E:\repo1\MathModelAgent-python\backend\app\core\agents\writer_agent.py 的内容:
================================================================================
# app/core/agents/writer_agent.py

from app.core.agents.agent import Agent
from app.core.llm.llm import LLM
from app.core.prompts import get_writer_prompt
from app.schemas.enums import CompTemplate, FormatOutPut
from app.tools.openalex_scholar import OpenAlexScholar, paper_to_footnote_tuple
from app.utils.log_util import logger
from app.services.redis_manager import redis_manager
from app.schemas.response import SystemMessage, WriterMessage
import json
import uuid
from app.core.functions import writer_tools
from icecream import ic
from app.schemas.A2A import WriterResponse
import re
from typing import List, Tuple

# 统一文本清洗（与 Coordinator/Modeler 保持一致思路）
from app.tools.text_sanitizer import TextSanitizer as TS


class WriterAgent(Agent):
    """
    写作手：
    - 不暴露任何外部工具；只产出正文（Markdown）
    - 统一做文本清洗（控制字符、常见瑕疵、外层围栏）
    - 校验图片引用，仅允许来自“可用图片清单”，且每张只用一次
    """

    def __init__(
        self,
        task_id: str,
        model: LLM,
        max_chat_turns: int = 600,
        comp_template: CompTemplate = CompTemplate,
        format_output: FormatOutPut = FormatOutPut.Markdown,
        scholar: OpenAlexScholar = None,
        max_memory: int = 100,
    ) -> None:
        super().__init__(task_id, model, max_chat_turns, max_memory)
        self.format_out_put = format_output
        self.comp_template = comp_template
        self.scholar = scholar
        self.is_first_run = True
        self.system_prompt = get_writer_prompt(format_output)
        self.available_images: List[str] = []

        # 图片校验
        self._img_regex = re.compile(r"!\[.*?\]\((.*?)\)")
        self._allowed_prefixes = ("eda/figures/", "sensitivity_analysis/figures/")

    async def run(
        self,
        prompt: str,
        available_images: list[str] = None,
        sub_title: str = None,
    ) -> WriterResponse:
        logger.info(f"WriterAgent subtitle: {sub_title}")

        # 首次注入 system
        if self.is_first_run:
            self.is_first_run = False
            await self.append_chat_history({"role": "system", "content": self.system_prompt})

        # 注入可用图片清单（仅作为上下文）
        if available_images:
            self.available_images = available_images
            image_list = "\n".join(available_images)
            prompt = (
                prompt
                + "\n可用图片清单（仅可引用下列图片，且每张图片在整篇只可引用一次）：\n"
                + image_list
                + "\n\n写作时请严格使用这些图片的相对路径（示例：`![说明](ques2/figures/fig_model_performance.png)`），且不要重复引用同一张图片。"
            )
            logger.info(f"image_prompt prepared with {len(available_images)} images")

        # 轮次 + user
        self.current_chat_turns += 1
        await self.append_chat_history({"role": "user", "content": prompt})

        # 禁用工具暴露（不允许任何外部工具被调用）
        response = await self.model.chat(
            history=self.chat_history,
            tools=[],  # 不暴露任何工具
            tool_choice=None,  # 不允许选择工具
            agent_name=self.__class__.__name__,
            sub_title=sub_title,
        )

        # 从源头即使用严格类型：List[Tuple[str, str]]
        footnotes: List[Tuple[str, str]] = []

        assistant_msg_obj = response.choices[0].message
        assistant_content_raw = getattr(assistant_msg_obj, "content", "") or ""
        assistant_tool_calls = getattr(assistant_msg_obj, "tool_calls", None)

        # 若模型仍“幻想”生成了 tool_calls，记录并忽略，继续正文
        if assistant_tool_calls:
            logger.info("WriterAgent 收到工具调用（已禁用，忽略）")
            await redis_manager.publish_message(
                self.task_id,
                SystemMessage(content="写作手收到工具调用，但已禁用所有外部工具，已忽略。", type="warning"),
            )
            await self.append_chat_history(
                {
                    "role": "tool",
                    "name": "disabled",
                    "tool_call_id": f"call_{uuid.uuid4().hex[:12]}",
                    "content": "所有外部工具已禁用，忽略此次调用。",
                }
            )

        # 文本清洗（与其它 Agent 保持一致的三步：控制字符 → 常见瑕疵 → 外层围栏）
        assistant_content = TS.clean_control_chars(assistant_content_raw, keep_whitespace=True)
        assistant_content = TS.normalize_common_glitches(assistant_content)
        assistant_content = TS.strip_fences_outer_or_all(assistant_content)

        # 直接追加 assistant 内容（清洗后）
        await self.append_chat_history({"role": "assistant", "content": assistant_content})

        # 最终文本初始化
        response_content = assistant_content or ""

        # 图片引用校验与纠错迭代（把上限调小，避免不必要的长循环）
        max_fix_attempts = 5
        attempt = 0
        while attempt <= max_fix_attempts:
            img_paths = self._extract_image_paths(response_content)
            invalids, duplicates = self._validate_image_paths(img_paths)

            if not invalids and not duplicates:
                logger.info("WriterAgent: 图片引用校验通过")
                break

            attempt += 1
            error_lines = []
            if invalids:
                error_lines.append("以下图片引用不在可用图片清单或路径前缀不合法：")
                for p in invalids:
                    error_lines.append(f"  - {p}")
            if duplicates:
                error_lines.append("以下图片被重复引用（每张图片只能引用一次）：")
                for p in duplicates:
                    error_lines.append(f"  - {p}")

            error_msg = "\n".join(error_lines)
            logger.warning(f"图片引用校验未通过（尝试 {attempt}/{max_fix_attempts}）：\n{error_msg}")
            await redis_manager.publish_message(
                self.task_id, SystemMessage(content=f"写作校验：图片引用问题，{error_msg}", type="error")
            )

            correction_prompt = (
                "检测到图片引用不合规。请根据可用图片清单修正文章中的图片引用：\n"
                "1. 只从下列可用图片中选择并使用（每张图片只能引用一次）：\n"
                + "\n".join(self.available_images or [])
                + "\n\n"
                "2. 对于当前不在清单中的引用，请用占位格式替换：\n"
                "   （占位：请在 <合法前缀>/figures/<期望文件名.png> 生成图后替换本段图片引用）\n"
                "3. 对于重复引用，请保留第一次引用并将后续引用替换为占位或删除。\n"
                "请仅返回修正后的完整文章（纯文本，不要包含额外说明）。"
            )

            await self.append_chat_history({"role": "user", "content": correction_prompt})
            # 纠错对话也禁用工具
            fix_resp = await self.model.chat(
                history=self.chat_history,
                tools=[],  # 不暴露任何工具
                tool_choice=None,  # 不允许选择工具
                agent_name=self.__class__.__name__,
                sub_title=sub_title,
            )
            fix_assistant_raw = getattr(fix_resp.choices[0].message, "content", "") or ""

            # 对纠错返回也做同样的清洗，避免把控制字符/围栏再次带回上下文
            fix_assistant = TS.clean_control_chars(fix_assistant_raw, keep_whitespace=True)
            fix_assistant = TS.normalize_common_glitches(fix_assistant)
            fix_assistant = TS.strip_fences_outer_or_all(fix_assistant)

            await self.append_chat_history({"role": "assistant", "content": fix_assistant})
            response_content = fix_assistant

        # 源头即严格类型，无需再归一化
        return WriterResponse(response_content=response_content, footnotes=footnotes)

    # ============== 图片工具 ==============

    def _extract_image_paths(self, text: str) -> List[str]:
        if not text:
            return []
        matches = self._img_regex.findall(text)
        return [m.strip() for m in matches if m and isinstance(m, str)]

    def _validate_image_paths(self, img_paths: List[str]) -> Tuple[List[str], List[str]]:
        invalids: List[str] = []
        duplicates: List[str] = []
        if not img_paths:
            return invalids, duplicates

        counts = {}
        for p in img_paths:
            counts[p] = counts.get(p, 0) + 1

        for p, c in counts.items():
            if c > 1:
                duplicates.append(p)

        allowed_set = set(self.available_images or [])
        for p in counts.keys():
            if p not in allowed_set:
                invalids.append(p)
                continue
            ok_prefix = False
            # 显式允许常见两类路径；或 quesN/figures/
            if p.startswith("eda/figures/") or p.startswith("sensitivity_analysis/figures/"):
                ok_prefix = True
            else:
                if re.match(r"^ques\d+/figures/", p):
                    ok_prefix = True
            if not ok_prefix:
                invalids.append(p)

        return invalids, duplicates


================================================================================
E:\repo1\MathModelAgent-python\backend\app\core\llm\llm.py 的内容:
================================================================================
# app/core/llm/llm.py

import json
import codecs
import string
import asyncio
import random
import uuid
from typing import Any, List, Dict

from app.utils.common_utils import transform_link, split_footnotes
from app.utils.log_util import logger
from app.schemas.response import (
    CoderMessage,
    WriterMessage,
    ModelerMessage,
    SystemMessage,
    CoordinatorMessage,
)
from app.services.redis_manager import redis_manager
from litellm import acompletion, token_counter
import litellm
from app.schemas.enums import AgentType
from app.utils.track import agent_metrics
from icecream import ic

# 引入集中式清洗/正则工具
from app.tools.text_sanitizer import TextSanitizer as TS
from app.tools.json_fixer import JsonFixer

# ====== 全局：请求与重试配置（可按需调大/调小）======
REQUEST_TIMEOUT = 300.0  # 单次请求整体超时（秒）
HTTPX_TIMEOUTS = {
    "connect": 120,
    "read": 60,
    "write": 120,
    "pool": 60,
}
DEFAULT_MAX_RETRIES = 100
BACKOFF_BASE = 0.8  # 指数退避基数，实际 backoff = base * (2**attempt) + jitter

# ====== 上下文长度保护（给 DeepSeek/GPT 等留余量）======
# 模型标称最大 131072，这里保守限制在 120000 左右，避免触发 400
CONTEXT_TOKEN_HARD_LIMIT = 120_000

litellm.callbacks = [agent_metrics]

# ========= 最后一跳消息清洗（确保 messages 可被 OpenAI/DeepSeek 正确反序列化） =========
# 仅保留顶层允许的字段：role/content/name/tool_calls/tool_call_id
_ALLOWED_KEYS = {"role", "content", "name", "tool_calls", "tool_call_id"}


def _json_dumps_safe(obj: Any) -> str:
    try:
        return json.dumps(obj, ensure_ascii=False)
    except Exception:
        return str(obj)


def _extract_tool_text(msg: Dict[str, Any]) -> str:
    """尽量从 tool 消息的各类字段中提炼可读文本"""
    extracted = []

    # 常见：output/outputs/result/results
    out = msg.get("output") or msg.get("outputs") or msg.get("result") or msg.get("results")
    if out is not None:
        if isinstance(out, (list, tuple)):
            for it in out:
                if isinstance(it, dict):
                    for k in ("msg", "message", "text", "result", "content"):
                        v = it.get(k)
                        if v:
                            extracted.append(str(v))
                            break
                    else:
                        extracted.append(_json_dumps_safe(it))
                else:
                    extracted.append(str(it))
        elif isinstance(out, dict):
            for k in ("msg", "message", "text", "result", "content"):
                v = out.get(k)
                if v:
                    extracted.append(str(v))
                    break
            else:
                extracted.append(_json_dumps_safe(out))
        else:
            extracted.append(str(out))

    # 备选：text/stdout/stderr/data/value
    for k in ("text", "stdout", "stderr", "data", "value"):
        v = msg.get(k)
        if v:
            if isinstance(v, (list, dict)):
                extracted.append(_json_dumps_safe(v))
            else:
                extracted.append(str(v))

    # 备选：tool_result/tool_response/tool_outputs
    tc = msg.get("tool_result") or msg.get("tool_response") or msg.get("tool_outputs")
    if tc is not None:
        extracted.append(_json_dumps_safe(tc))

    # 去重+拼接
    parts, seen = [], set()
    for s in (x.strip() for x in extracted if isinstance(x, str)):
        if s and s not in seen:
            seen.add(s)
            parts.append(s)
    return "\n".join(parts)


def _looks_like_literal_escapes(s: str) -> bool:
    """
    委托给 TextSanitizer 的实现，保持行为一致。
    """
    return TS.looks_like_literal_escapes(s)


def _stringify_tool_calls(tc_list: Any) -> Any:
    """把 assistant 消息里的 tool_calls.arguments 强制转成字符串，并兜底 function.name / type / id"""
    if not isinstance(tc_list, (list, tuple)):
        return tc_list
    cleaned = []
    for tc in tc_list:
        if not isinstance(tc, dict):
            cleaned.append(tc)
            continue

        tc = dict(tc)

        # type 兜底
        if tc.get("type") != "function":
            tc["type"] = "function"

        # id 兜底（若上游不给，我们自己给，后续 tool 消息用同一个 id）
        if not isinstance(tc.get("id"), str) or not tc.get("id"):
            tc["id"] = f"call_{uuid.uuid4().hex[:12]}"

        # function 兜底
        fn = tc.get("function") or {}
        if not isinstance(fn, dict):
            fn = {"name": "unknown", "arguments": _json_dumps_safe(fn)}
        name = fn.get("name")
        if not isinstance(name, str) or not name:
            name = "unknown"
        args = fn.get("arguments")
        if isinstance(args, (dict, list)):
            args = _json_dumps_safe(args)
        if args is None:
            args = ""

        tc["function"] = {"name": name, "arguments": args}
        cleaned.append(tc)
    return cleaned


def sanitize_messages_for_openai(history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    最后一跳强制清洗（OpenAI/DeepSeek 兼容）改良版：保留原有行为。
    1) 不会无脑转义或移除换行
    2) 如果 content 是 list-of-lines，保留并合并为真实换行
    3) 若 content 为字符串且仅包含字面 '\\n'（没有真实 '\n'），则保守地尝试一次反转义为真实换行
    4) 其它行为与原版一致：规范角色、处理 assistant.tool_calls、绑定 tool_call_id、丢弃孤儿消息等
    """
    result: List[Dict[str, Any]] = []
    if not history:
        return result

    pending_tool_ids: List[str] = []  # assistant.tool_calls 产生的待消费 id 队列

    for idx, orig in enumerate(history):
        base = {} if not isinstance(orig, dict) else dict(orig)

        # 先裁剪到允许字段（保留原 base 用于抽取文本）
        m = {k: v for k, v in base.items() if k in _ALLOWED_KEYS}

        # -------- 角色规范化 --------
        role = m.get("role") or base.get("role") or "assistant"
        if role == "function":
            role = "tool"
            if not isinstance(m.get("name"), str) or not m.get("name"):
                m["name"] = base.get("name") or "tool"
        elif role == "tool":
            pass
        elif role not in ("system", "user", "assistant"):
            logger.warning(f"[sanitize] unexpected role={role} at idx={idx}, fallback to 'assistant'")
            role = "assistant"
        m["role"] = role

        # -------- assistant.tool_calls 处理 --------
        if role == "assistant" and base.get("tool_calls"):
            tool_calls = _stringify_tool_calls(base.get("tool_calls"))
            m["tool_calls"] = tool_calls
            for tc in tool_calls or []:
                tc_id = (tc or {}).get("id")
                if isinstance(tc_id, str) and tc_id:
                    pending_tool_ids.append(tc_id)

        # -------- content 规范化（所有角色）--------
        content = None
        # Prefer explicit content from m (already filtered); fallback to base variety
        if "content" in m:
            content = m.get("content")
        else:
            # try to find likely textual fields in original object
            if isinstance(base, dict):
                # keep the same priority as _extract_tool_text but don't over-dumps strings
                for k in ("content", "text", "result", "message", "msg"):
                    if k in base and base.get(k) is not None:
                        content = base.get(k)
                        break

        # Normalize content to a single string while preserving existing newlines:
        normalized_content = ""
        if content is None:
            normalized_content = ""
        elif isinstance(content, list):
            # If already list-of-lines, join preserving explicit line breaks.
            # Allow items to be either strings or objects (non-strings -> json dumps)
            parts = []
            for it in content:
                if isinstance(it, str):
                    parts.append(it)
                else:
                    parts.append(_json_dumps_safe(it))
            normalized_content = "\n".join(parts)
        elif isinstance(content, dict):
            # dict -> json string (no ascii escape)
            normalized_content = _json_dumps_safe(content)
        else:
            # it's a scalar (likely string or number)
            try:
                normalized_content = str(content)
            except Exception:
                normalized_content = ""

        # 保守反转义：仅当内容看起来是“字面转义的 ASCII 文本”时再处理；
        # 且对 tool 消息一律跳过（避免破坏代码/二进制）
        if role != "tool" and _looks_like_literal_escapes(normalized_content):
            try:
                # 只做一次 unicode_escape 解码（不再先 .encode('utf-8')）
                candidate = codecs.decode(normalized_content, "unicode_escape")
                # 要求至少出现真实换行，避免把正常文本搞坏
                if "\n" in candidate or "\r\n" in candidate or "\t" in candidate:
                    normalized_content = candidate
                else:
                    normalized_content = (
                        normalized_content.replace("\\r\\n", "\n").replace("\\n", "\n").replace("\\t", "\t")
                    )
            except Exception:
                normalized_content = (
                    normalized_content.replace("\\r\\n", "\n").replace("\\n", "\n").replace("\\t", "\t")
                )

        # Now we have normalized_content with real '\n' where appropriate. Do NOT strip or remove newlines.
        # 对“tool（含遗留 function）消息”尝试从其它字段提取可读文本（仅在 content 为空时）
        if role == "tool" and (not normalized_content or not normalized_content.strip()):
            extracted = _extract_tool_text(base) if isinstance(base, dict) else ""
            if extracted:
                # _extract_tool_text returns joined parts with "\n" already
                normalized_content = extracted

        # 对“assistant 且包含 tool_calls”的消息，允许没有 content（多数模型就是空 content）
        if not (role == "assistant" and m.get("tool_calls")):
            # 其它角色一律写回 content
            m["content"] = normalized_content

        # -------- 为 tool 消息确保 tool_call_id 配对 --------
        if role == "tool":
            tcid = m.get("tool_call_id")
            if not isinstance(tcid, str) or not tcid:
                if pending_tool_ids:
                    assigned = pending_tool_ids.pop(0)
                    m["tool_call_id"] = assigned
                    logger.debug(f"[sanitize] tool msg auto-bound tool_call_id={assigned} at idx={idx}")
                else:
                    # 没有可匹配的 id，属于孤儿工具响应：直接丢弃，避免非法消息
                    logger.warning(f"[sanitize] dropping orphan tool message at idx={idx} (no matching tool_call_id)")
                    continue

        # -------- 剔除 None 值，避免严格校验问题 --------
        for k in list(m.keys()):
            if m[k] is None:
                del m[k]

        # -------- 丢弃纯空消息（除 system 外）--------
        is_meaningless = (
            (role != "system")
            and (not m.get("content", "") or not m.get("content", "").strip())
            and (not m.get("tool_calls"))
            and (role != "tool" or not (m.get("name") or m.get("tool_call_id")))
        )
        if is_meaningless:
            logger.debug(f"[sanitize] drop empty message at idx={idx}, role={role}")
            continue

        # 记录 debug（保持原来的调试输出）
        if (m.get("content", "") or "") == "":
            logger.debug(f"[sanitize] empty content kept at idx={idx}, role={role}")

        result.append(m)

    # 调试：打印前几条，确认没有 None / 异常
    try:
        for i, mm in enumerate(result[:4]):
            logger.debug(
                f"[sanitize] #{i}: role={mm.get('role')}, "
                f"type(content)={type(mm.get('content'))}, "
                f"len(content)={len(mm.get('content') or '')}"
            )
    except Exception:
        pass

    return result


# =======================================================================================


class LLM:
    def __init__(
        self,
        api_key: str,
        model: str,
        base_url: str,
        task_id: str,
    ):
        self.api_key = api_key
        self.model = model
        self.base_url = base_url
        self.chat_count = 0
        self.max_tokens: int | None = None
        self.task_id = task_id

    async def chat(
        self,
        history: list = None,
        tools: list = None,
        tool_choice: str = None,
        max_retries: int = DEFAULT_MAX_RETRIES,
        retry_delay: float = BACKOFF_BASE,
        top_p: float | None = None,
        agent_name: AgentType | str = AgentType.SYSTEM,
        sub_title: str | None = None,
        publish: bool = True,  # 关键新增：是否发布到 Redis/WebSocket
    ) -> object:  # 返回 ModelResponse
        logger.info(f"subtitle是:{sub_title}")

        # 1) 工具配对修复 + 截断 + system后首条user
        if history:
            history = self._validate_and_fix_tool_calls(history)
            history = self._truncate_history_by_tokens(history, CONTEXT_TOKEN_HARD_LIMIT)
            history = self._ensure_first_after_system_user(history)

        # 2) 最后一跳清洗
        safe_messages = sanitize_messages_for_openai(history or [])

        # 3) 组装请求参数
        kwargs = {
            "api_key": self.api_key,
            "model": self.model,
            "messages": safe_messages,
            "stream": False,
            "top_p": top_p,
            "metadata": {"agent_name": getattr(agent_name, "name", str(agent_name))},
            "request_timeout": REQUEST_TIMEOUT,
            "client_args": {"timeout": HTTPX_TIMEOUTS},
        }
        if tools:
            kwargs["tools"] = tools
            if tool_choice is not None:
                kwargs["tool_choice"] = tool_choice
        if self.max_tokens:
            kwargs["max_tokens"] = self.max_tokens
        if self.base_url:
            kwargs["base_url"] = self.base_url

        # 4) 调用 + 重试
        for attempt in range(max_retries):
            try:
                response = await acompletion(**kwargs)
                logger.info(f"API返回: {response}")

                if not response or not hasattr(response, "choices"):
                    raise ValueError("无效的API响应")

                # 仅在 publish=True 时，才入库并广播
                if publish:
                    self.chat_count += 1
                    await self.send_message(response, agent_name, sub_title)

                return response

            except asyncio.CancelledError:
                logger.warning("请求被上层取消（CancelledError），不重试。")
                raise
            except (litellm.BadRequestError, litellm.AuthenticationError, litellm.NotFoundError) as e:
                msg = str(e)
                if "maximum context length" in msg or "context length" in msg or "ContextWindowExceeded" in msg:
                    logger.error("非重试错误：上下文超限，请确保在进入 acompletion 前已充分截断。")
                else:
                    logger.error(f"非重试错误：{e}")
                raise
            except (
                litellm.RateLimitError,
                litellm.Timeout,
                litellm.APIConnectionError,
                litellm.InternalServerError,
                json.JSONDecodeError,
            ) as e:
                logger.error(f"第 {attempt + 1}/{max_retries} 次重试: {e}")
                if attempt >= max_retries - 1:
                    logger.debug(f"请求参数: {kwargs}")
                    raise
                delay = retry_delay * (2**attempt) + random.random() * 0.3
                await asyncio.sleep(delay)
            except Exception as e:
                logger.error(f"第 {attempt + 1}/{max_retries} 次重试（未知异常）: {e}")
                if attempt >= max_retries - 1:
                    logger.debug(f"请求参数: {kwargs}")
                    raise
                delay = retry_delay * (2**attempt) + random.random() * 0.3
                await asyncio.sleep(delay)

    def _validate_and_fix_tool_calls(self, history: list) -> list:
        """
        验证并修复工具调用完整性（OpenAI 新规范）：
        1) 合法角色只允许：system / user / assistant / tool
        2) assistant 消息里的 tool_calls[*].id 必须与后续某条 role='tool' 的消息的 tool_call_id 匹配
        3) 若发现历史遗留的 role='function'，在此阶段就地改为 role='tool'
        4) 未匹配到的“孤儿 tool 消息”丢弃；assistant 中未被消费的 tool_calls 也会被移除
        """
        if not history:
            return history

        ic(f"🔍 开始验证工具调用，历史消息数量: {len(history)}")

        fixed_history = []
        i = 0

        def _is_tool_resp(m: dict) -> bool:
            # 兼容历史：把 'function' 视为 'tool' 并在写入时改回 'tool'
            return isinstance(m, dict) and m.get("role") in ("tool", "function")

        while i < len(history):
            msg = history[i]

            # 1) assistant 带 tool_calls 的消息：逐一检查是否有后续响应（tool）
            if isinstance(msg, dict) and msg.get("tool_calls"):
                ic(f"📞 发现tool_calls消息在位置 {i}")
                valid_tool_calls, invalid_tool_calls = [], []

                for tc in msg["tool_calls"]:
                    tool_call_id = (tc or {}).get("id")
                    ic(f"  检查tool_call_id: {tool_call_id}")
                    if not tool_call_id:
                        invalid_tool_calls.append(tc)
                        continue

                    found_response = False
                    for j in range(i + 1, len(history)):
                        m2 = history[j]
                        if _is_tool_resp(m2):
                            # 若是遗留 'function'，仅用于判断，稍后写回统一改 'tool'
                            m2_id = m2.get("tool_call_id")
                            if m2_id == tool_call_id:
                                ic(f"  ✅ 找到匹配响应在位置 {j}")
                                found_response = True
                                break

                    if found_response:
                        valid_tool_calls.append(tc)
                    else:
                        ic(f"  ❌ 未找到匹配响应: {tool_call_id}")
                        invalid_tool_calls.append(tc)

                if valid_tool_calls:
                    fixed_msg = msg.copy()
                    fixed_msg["tool_calls"] = valid_tool_calls
                    fixed_history.append(fixed_msg)
                    ic(f"  🔧 保留 {len(valid_tool_calls)} 个有效tool_calls，移除 {len(invalid_tool_calls)} 个无效的")
                else:
                    # 没有有效 tool_call：如果还有文本，就保留文本；否则丢弃整条
                    cleaned_msg = {k: v for k, v in msg.items() if k != "tool_calls"}
                    content = (cleaned_msg.get("content") or "").strip()
                    if content:
                        fixed_history.append(cleaned_msg)
                        ic(f"  🔧 移除所有tool_calls，保留消息内容")
                    else:
                        ic(f"  🗑️ 完全移除空的tool_calls消息")

            # 2) tool/function 响应：确认是否与上游 tool_calls 配对；无配对则丢弃
            elif _is_tool_resp(msg):
                role = msg.get("role")
                tool_call_id = msg.get("tool_call_id")
                ic(f"🔧 检查工具响应消息: role={role}, tool_call_id={tool_call_id}")

                # 在 fixed_history 中回溯查找是否存在匹配的 assistant.tool_calls
                found_call = False
                for k in range(len(fixed_history) - 1, -1, -1):
                    prev = fixed_history[k]
                    if isinstance(prev, dict) and prev.get("tool_calls"):
                        if any((tc or {}).get("id") == tool_call_id for tc in prev["tool_calls"]):
                            found_call = True
                            break

                if found_call:
                    # 统一将遗留的 'function' 改为 'tool'，与 OpenAI 规范一致
                    if role == "function":
                        msg = dict(msg)
                        msg["role"] = "tool"
                    fixed_history.append(msg)
                    ic(f"  ✅ 保留有效的工具响应（role=tool）")
                else:
                    ic(f"  🗑️ 移除孤立的工具响应: {tool_call_id}")

            else:
                # 普通消息，直接保留
                fixed_history.append(msg)

            i += 1

        if len(fixed_history) != len(history):
            ic(f"🔧 修复完成: {len(history)} -> {len(fixed_history)} 条消息")
        else:
            ic(f"✅ 验证通过，无需修复")

        return fixed_history

    def _truncate_history_by_tokens(self, history: list, token_limit: int) -> list:
        """
        按 token 数量裁剪 messages（保留首条 system + 尾部若干条）。
        为避免破坏工具消息配对，采用“取对话尾部连续片段”的策略，再做一次完整性校验。
        """
        if not history:
            return history

        # 计算 token 的辅助函数
        def msg_tokens(msg: dict) -> int:
            # 仅对 content 计数（role/tool_calls 元数据不计）
            content = msg.get("content") or ""
            try:
                return token_counter(content, self.model)
            except Exception:
                # 兜底估算（大致 3~4 字符 ~ 1 token）
                return max(1, len(content) // 3)

        # 首条可能是 system，尽量保留
        system_msg = None
        start_idx = 0
        if history[0].get("role") == "system":
            system_msg = history[0]
            start_idx = 1

        # 先尝试全量计数
        total = (msg_tokens(system_msg) if system_msg else 0) + sum(msg_tokens(m) for m in history[start_idx:])
        if total <= token_limit:
            return history

        # 从尾部向前累积，直到达到上限
        kept = []
        running = msg_tokens(system_msg) if system_msg else 0

        for i in range(len(history) - 1, start_idx - 1, -1):
            t = msg_tokens(history[i])
            if running + t > token_limit:
                break
            kept.append(history[i])
            running += t

        kept.reverse()
        new_history = [system_msg] + kept if system_msg else kept

        # 再次做工具调用完整性修复，避免产生孤立 tool 消息
        new_history = self._validate_and_fix_tool_calls(new_history)
        return new_history

    async def send_message(self, response, agent_name, sub_title=None):
        logger.info(f"subtitle是:{sub_title}")
        raw_content = getattr(response.choices[0].message, "content", "") or ""

        # 字符串 -> AgentType 的归一化（保持你现有逻辑）
        if isinstance(agent_name, str):
            key = agent_name.lower().replace(" ", "")
            mapping = {
                "coordinatoragent": AgentType.COORDINATOR,
                "modeleragent": AgentType.MODELER,
                "writeragent": AgentType.WRITER,
                "coderagent": AgentType.CODER,
                "jsonfixer": AgentType.MODELER,
                "jsonfixerheavy": AgentType.MODELER,
            }
            agent_name = mapping.get(key, None) or (
                AgentType.COORDINATOR
                if "coord" in key
                else (
                    AgentType.MODELER
                    if ("model" in key or "jsonfixer" in key)
                    else (
                        AgentType.WRITER if "writer" in key else AgentType.CODER if "coder" in key else AgentType.SYSTEM
                    )
                )
            )

        # ------- 对 Coordinator / Modeler 做严格 JSON 规范化（右侧面板要吃干净 JSON） -------
        content_to_send = raw_content

        if agent_name in (AgentType.COORDINATOR, AgentType.MODELER):
            stripped = TS.strip_fences_outer_or_all(raw_content)
            try:
                # 关键：把 llm=self 交给 JsonFixer，由它内部用 publish=False 调 self.chat
                obj, stage = await JsonFixer.fix_and_parse(
                    stripped,
                    llm=self,
                    agent_name=f"{getattr(agent_name, 'name', str(agent_name))}.JsonFixer",
                )
            except Exception as e:
                logger.exception(f"JsonFixer 调用失败: {e}")
                err_obj = {"error": "jsonfixer_exception", "exc": str(e)}
                content_to_send = json.dumps(err_obj, ensure_ascii=False)
            else:
                if isinstance(obj, dict):
                    # 成功：发布纯 JSON 字符串（仅一层序列化），不要再包 ```json 围栏
                    content_to_send = json.dumps(obj, ensure_ascii=False)
                else:
                    # 解析失败：发布结构化错误对象（避免把脏原文再次传回引起循环）
                    preview = (stripped[:600] + "…") if len(stripped) > 600 else stripped
                    err_obj = {"error": "json_unparseable", "stage": stage, "raw_preview": preview}
                    content_to_send = json.dumps(err_obj, ensure_ascii=False)
                    logger.warning(f"send_message: JSON 解析失败 stage={stage}; 已发布错误对象供上游处理.")

        # 发布给前端（保持原有分支）
        match agent_name:
            case AgentType.CODER:
                agent_msg: CoderMessage = CoderMessage(content=content_to_send)
            case AgentType.WRITER:
                c, _ = split_footnotes(content_to_send)
                c = transform_link(self.task_id, c)
                agent_msg: WriterMessage = WriterMessage(content=c, sub_title=sub_title)
            case AgentType.MODELER:
                agent_msg: ModelerMessage = ModelerMessage(content=content_to_send)
            case AgentType.COORDINATOR:
                agent_msg: CoordinatorMessage = CoordinatorMessage(content=content_to_send)
            case AgentType.SYSTEM:
                agent_msg: SystemMessage = SystemMessage(content=content_to_send)
            case _:
                agent_msg: SystemMessage = SystemMessage(content=content_to_send)

        await redis_manager.publish_message(self.task_id, agent_msg)

    def _ensure_first_after_system_user(self, history: list) -> list:
        """
        保证：任意数量的 system 之后，第一条非 system 必须是 user。
        1) 若首条非 system 是 assistant 且内容像“历史对话总结…”，则就地改成 user；
        2) 否则在其前面插入一条简短的 user 承接消息；
        3) 若全是 system（或空），也插入一条最小 user 启动语。
        """
        if not history:
            return [{"role": "user", "content": "[空对话启动] 继续。"}]

        # 找到首个非 system 的索引
        i = 0
        while i < len(history) and isinstance(history[i], dict) and history[i].get("role") == "system":
            i += 1

        # 情况A：全是 system
        if i >= len(history):
            return history + [{"role": "user", "content": "[承接上文上下文] 继续。"}]

        # 情况B：首个非 system 不是 user
        first = history[i] if isinstance(history[i], dict) else {}
        role = first.get("role")
        if role != "user":
            content = (first.get("content") or "").strip()
            # 如果像我们的“历史对话总结…”，直接就地改成 user 更自然
            if role == "assistant" and content.startswith("[历史对话总结"):
                first["role"] = "user"
                history[i] = first
            else:
                # 否则在其前面插入一条最小 user 承接消息
                history = history[:i] + [{"role": "user", "content": "[承接上文上下文] 继续。"}] + history[i:]

        return history


async def simple_chat(model: LLM, history: list) -> str:
    """
    重量版 simple_chat：
    1) 先修复工具消息完整性（避免孤立 tool / 未匹配的 tool_call）
    2) 在总 token 超限时，采用：保留 system + 尾部完整对话片段 + 中段自动摘要
    3) 迭代压缩，直到 <= CONTEXT_TOKEN_HARD_LIMIT 后再发起最终补全
    """

    def quick_count(msg):
        content = (msg or {}).get("content") or ""
        try:
            return token_counter(content, model.model)
        except Exception:
            return max(1, len(content) // 3)

    def tokens_of(messages):
        if not messages:
            return 0
        return sum(quick_count(m) for m in messages if isinstance(m, dict))

    def pair_safe_tail(messages):
        MAX_TAIL_MSGS = 100
        start = max(0, len(messages) - MAX_TAIL_MSGS)
        tail = messages[start:]
        return model._validate_and_fix_tool_calls(tail)

    async def summarize_chunk(chunk_msgs):
        sys_prompt = {
            "role": "system",
            "content": (
                "你是一个对话摘要器。请将以下对话压缩为一段简洁的中文总结，"
                "保留任务目标、关键约束、重要结论和已完成步骤，去除无关细节。"
                "输出不超过 300~600 字。"
            ),
        }
        user_prompt = {
            "role": "user",
            "content": "\n".join(
                f"{m.get('role')}: { (m.get('content') or '')[:2000] }" for m in chunk_msgs if isinstance(m, dict)
            ),
        }
        msgs = sanitize_messages_for_openai([sys_prompt, user_prompt])
        kwargs = {
            "api_key": model.api_key,
            "model": model.model,
            "messages": msgs,
            "stream": False,
            "request_timeout": REQUEST_TIMEOUT,
            "client_args": {"timeout": HTTPX_TIMEOUTS},
        }
        if model.base_url:
            kwargs["base_url"] = model.base_url

        resp = await acompletion(**kwargs)
        return resp.choices[0].message.content.strip()

    # ========== 预处理：工具完整性修复 ==========
    history = history or []
    history = model._validate_and_fix_tool_calls(history)

    # 拆出 system（若存在则保留）
    sys_msg = history[0] if (history and history[0].get("role") == "system") else None
    start_idx = 1 if sys_msg else 0
    body = history[start_idx:]

    # 快速通过：未超限直接请求
    total_tokens = (quick_count(sys_msg) if sys_msg else 0) + tokens_of(body)
    if total_tokens <= CONTEXT_TOKEN_HARD_LIMIT:
        # **保证 system 后第一条是 user**
        ready = [sys_msg] + body if sys_msg else body
        ready = model._ensure_first_after_system_user(ready)
        msgs = sanitize_messages_for_openai(ready)

        kwargs = {
            "api_key": model.api_key,
            "model": model.model,
            "messages": msgs,
            "stream": False,
            "request_timeout": REQUEST_TIMEOUT,
            "client_args": {"timeout": HTTPX_TIMEOUTS},
        }
        if model.base_url:
            kwargs["base_url"] = model.base_url
        resp = await acompletion(**kwargs)
        return resp.choices[0].message.content

    # ========== 重量压缩流程 ==========
    MAX_SUMMARY_ROUNDS = 3
    for round_idx in range(MAX_SUMMARY_ROUNDS):
        tail = pair_safe_tail(body)
        SUMMARY_BUDGET_HINT = 1500

        def tail_tokens(t):
            return tokens_of(t)

        keep = len(tail)
        while keep > 0:
            candidate_tail = tail[-keep:]
            rough_total = (quick_count(sys_msg) if sys_msg else 0) + SUMMARY_BUDGET_HINT + tail_tokens(candidate_tail)
            if rough_total <= CONTEXT_TOKEN_HARD_LIMIT:
                tail = model._validate_and_fix_tool_calls(candidate_tail)
                break
            keep //= 2
        else:
            tail = []

        cut_at = len(body) - len(tail)
        head = body[: max(cut_at, 0)]

        summary_text = ""
        if head:
            try:
                summary_text = await summarize_chunk(head)
            except Exception as e:
                logger.error(f"摘要失败，回退使用简短占位：{e}")
                summary_text = "（对话中段摘要：包含若干步骤、错误修复与中间结论，已省略细节以节省上下文。）"

        # **关键修改：把“历史总结”作为 user 消息喂给模型，仅作上下文**
        summary_msg = {"role": "user", "content": f"[历史对话总结-仅供上下文，无需回复]\n{summary_text}"}

        new_history = ([sys_msg] if sys_msg else []) + [summary_msg] + tail
        new_history = model._validate_and_fix_tool_calls(new_history)

        # **再次保证 system 后第一条是 user**
        new_history = model._ensure_first_after_system_user(new_history)
        exact_total = tokens_of(new_history)

        if exact_total <= CONTEXT_TOKEN_HARD_LIMIT:
            msgs = sanitize_messages_for_openai(new_history)
            kwargs = {
                "api_key": model.api_key,
                "model": model.model,
                "messages": msgs,
                "stream": False,
                "request_timeout": REQUEST_TIMEOUT,
                "client_args": {"timeout": HTTPX_TIMEOUTS},
            }
            if model.base_url:
                kwargs["base_url"] = model.base_url
            resp = await acompletion(**kwargs)
            return resp.choices[0].message.content

        body = head + tail  # 下一轮继续压缩

    # 多轮仍超限：退而求其次 —— 仅保留 system + 极短摘要（仍为 user）
    try:
        minimal_summary = await summarize_chunk(body[:200])
    except Exception:
        minimal_summary = "（超长上下文，已压缩为极短摘要。）"

    final_history = ([sys_msg] if sys_msg else []) + [
        {"role": "user", "content": f"[历史对话极简总结-仅供上下文，无需回复]\n{minimal_summary}"}
    ]
    final_history = model._ensure_first_after_system_user(final_history)
    msgs = sanitize_messages_for_openai(final_history)

    kwargs = {
        "api_key": model.api_key,
        "model": model.model,
        "messages": msgs,
        "stream": False,
        "request_timeout": REQUEST_TIMEOUT,
        "client_args": {"timeout": HTTPX_TIMEOUTS},
    }
    if model.base_url:
        kwargs["base_url"] = model.base_url
    resp = await acompletion(**kwargs)
    return resp.choices[0].message.content


================================================================================
E:\repo1\MathModelAgent-python\backend\app\core\llm\llm_factory.py 的内容:
================================================================================
# app/core/llm/llm_factory.py

from app.config.setting import settings
from app.core.llm.llm import LLM


class LLMFactory:
    task_id: str

    def __init__(self, task_id: str) -> None:
        self.task_id = task_id

    def get_all_llms(self) -> tuple[LLM, LLM, LLM, LLM]:
        coordinator_llm = LLM(
            api_key=settings.COORDINATOR_API_KEY,
            model=settings.COORDINATOR_MODEL,
            base_url=settings.COORDINATOR_BASE_URL,
            task_id=self.task_id,
        )

        modeler_llm = LLM(
            api_key=settings.MODELER_API_KEY,
            model=settings.MODELER_MODEL,
            base_url=settings.MODELER_BASE_URL,
            task_id=self.task_id,
        )

        coder_llm = LLM(
            api_key=settings.CODER_API_KEY,
            model=settings.CODER_MODEL,
            base_url=settings.CODER_BASE_URL,
            task_id=self.task_id,
        )

        writer_llm = LLM(
            api_key=settings.WRITER_API_KEY,
            model=settings.WRITER_MODEL,
            base_url=settings.WRITER_BASE_URL,
            task_id=self.task_id,
        )

        return coordinator_llm, modeler_llm, coder_llm, writer_llm


================================================================================
E:\repo1\MathModelAgent-python\backend\app\models\user_output.py 的内容:
================================================================================
# app/models/user_output.py

import os
import re
from app.utils.data_recorder import DataRecorder
from app.schemas.A2A import WriterResponse
import json
import uuid


class UserOutput:
    def __init__(self, work_dir: str, ques_count: int, data_recorder: DataRecorder | None = None):
        self.work_dir = work_dir
        # 存储各小节结果：{ key: {"response_content": str, "footnotes": list[str]} }
        self.res: dict[str, dict] = {}
        self.data_recorder = data_recorder
        self.cost_time = 0.0
        self.initialized = True
        self.ques_count: int = ques_count
        # 全局脚注：{ uuid: {"content": str, "number": int?} }
        self.footnotes: dict[str, dict] = {}
        self._init_seq()

    def _init_seq(self):
        """按论文结构定义章节顺序；用于最终拼接"""
        ques_str = [f"ques{i}" for i in range(1, self.ques_count + 1)]
        self.seq = [
            "firstPage",  # 标题、摘要、关键词
            "RepeatQues",  # 一、问题重述
            "analysisQues",  # 二、问题分析
            "modelAssumption",  # 三、模型假设
            "symbol",  # 四、符号说明
            "eda",  # 数据预处理（EDA）
            *ques_str,  # 模型建立与求解（问题1,2,...）
            "sensitivity_analysis",  # 模型分析与检验
            "judge",  # 模型评价、改进与推广
        ]

    def set_res(self, key: str, writer_response: WriterResponse):
        """写入某个章节的生成结果"""
        if not isinstance(writer_response, WriterResponse):
            # 容错：允许传入兼容结构的字典
            try:
                rc = (writer_response or {}).get("response_content", "")  # type: ignore
                fn = (writer_response or {}).get("footnotes", [])  # type: ignore
            except Exception:
                rc, fn = "", []
        else:
            rc = writer_response.response_content or ""
            fn = writer_response.footnotes or []

        self.res[key] = {
            "response_content": rc,
            "footnotes": fn,
        }

    def get_res(self):
        return self.res

    def get_model_build_solve(self) -> str:
        """
        获取“模型建立与求解”的简要串，用于写作 prompt。
        仅拼接各 quesX 的 response_content（截断到较短，以免 prompt 过长）。
        """
        parts: list[str] = []
        for k, v in self.res.items():
            if k.startswith("ques"):
                text = (v or {}).get("response_content", "") or ""
                if len(text) > 400:
                    text = text[:400] + "..."
                parts.append(f"{k}: {text}")
        return " | ".join(parts)

    # ============ 引用解析与合并 ============
    def replace_references_with_uuid(self, text: str) -> str:
        """
        将文中形如 `{[^1]: 引用内容}` 的“就地引用定义”替换为 `[<uuid>]` 占位，
        并把引用内容存入 self.footnotes[uuid] = {"content": ...}。
        若相同内容已存在，则复用已有 uuid（去重）。
        """
        if not text:
            return ""

        # 匹配 {[^数字]: 引用内容}，允许跨行
        pattern = re.compile(r"\{\[\^(\d+)\]:\s*(.*?)\}", re.DOTALL)

        def _find_existing_uuid(content: str) -> str | None:
            for u, data in self.footnotes.items():
                if data.get("content") == content:
                    return u
            return None

        def _repl(m: re.Match) -> str:
            ref_num = m.group(1)
            ref_content = (m.group(2) or "").strip().rstrip(".").strip()
            if not ref_content:
                return ""  # 空内容直接移除

            existed = _find_existing_uuid(ref_content)
            if existed:
                return f"[{existed}]"

            new_uuid = str(uuid.uuid4())
            self.footnotes[new_uuid] = {"content": ref_content}
            return f"[{new_uuid}]"

        return pattern.sub(_repl, text)

    def sort_text_with_footnotes(self, replace_res: dict) -> dict:
        """
        将各章节文本中的 [uuid] 按出现顺序重新编号为 [^1], [^2], ...
        并在 self.footnotes[uuid]['number'] 写入编号。
        """
        sort_res: dict = {}
        ref_index = 1
        for seq_key in self.seq:
            # 章节缺失时用空串兜底
            section = replace_res.get(seq_key, {"response_content": ""})
            text = section.get("response_content", "") or ""

            # 找所有 uuid 形式的引用
            uuid_list = re.findall(r"\[([a-f0-9-]{36})\]", text)
            for uid in uuid_list:
                # 第一次见到该 uuid 才赋编号
                if self.footnotes.get(uid) is not None and self.footnotes[uid].get("number") is None:
                    self.footnotes[uid]["number"] = ref_index
                    ref_index += 1
                # 将所有该 uuid 的占位替换为 [^number]（若没编号，保持原样）
                number = (self.footnotes.get(uid) or {}).get("number")
                text = text.replace(f"[{uid}]", f"[^{number}]" if number else f"[{uid}]")

            sort_res[seq_key] = {
                "response_content": text,
            }
        return sort_res

    def append_footnotes_to_text(self, text: str) -> str:
        """
        将全局脚注按编号追加到文末；仅输出已有 number 的脚注。
        """
        # 仅保留已编号的脚注
        numbered = [(u, d) for u, d in self.footnotes.items() if "number" in (d or {})]
        if not numbered:
            return text

        text += "\n\n## 参考文献"
        # 按编号排序
        numbered.sort(key=lambda x: x[1]["number"])
        for _, footnote in numbered:
            text += f"\n\n[^{footnote['number']}]: {footnote['content']}"
        return text

    # ============ 汇总/保存 ============
    def get_result_to_save(self) -> str:
        """
        1) 将每个章节内联的 {[^n]: ...} 引用替换为 [uuid] 并汇总全局 footnotes
        2) 按出现顺序给 uuid 赋编号，正文替换为 [^n]
        3) 文末追加“参考文献”条目
        """
        replace_res: dict[str, dict] = {}

        # 逐章替换“就地引用定义”为 uuid
        for key in self.seq:
            section = self.res.get(key, {"response_content": ""})
            original = section.get("response_content", "") or ""
            new_text = self.replace_references_with_uuid(original)
            replace_res[key] = {"response_content": new_text}

        # 按出现顺序编号 & 正文替换
        sort_res = self.sort_text_with_footnotes(replace_res)

        # 按章节顺序拼接正文
        full_res_body = "\n\n".join(sort_res.get(k, {}).get("response_content", "") for k in self.seq)

        # 追加参考文献
        full_res = self.append_footnotes_to_text(full_res_body)
        return full_res

    def save_result(self):
        """保存 res.json 与 res.md 到工作目录"""
        # 1) 保存结构化 JSON
        with open(os.path.join(self.work_dir, "res.json"), "w", encoding="utf-8") as f:
            json.dump(self.res, f, ensure_ascii=False, indent=4)

        # 2) 保存最终 Markdown
        res_path = os.path.join(self.work_dir, "res.md")
        with open(res_path, "w", encoding="utf-8") as f:
            f.write(self.get_result_to_save())


================================================================================
E:\repo1\MathModelAgent-python\backend\app\routers\common_router.py 的内容:
================================================================================
# app/router/common_router.py

from fastapi import APIRouter
from app.config.setting import settings
from app.utils.common_utils import get_config_template
from app.schemas.enums import CompTemplate

router = APIRouter()


@router.get("/")
async def root():
    return {"message": "Hello World"}


@router.get("/config")
async def config():
    return {
        "environment": settings.ENV,
        "deepseek_model": settings.DEEPSEEK_MODEL,
        "deepseek_base_url": settings.DEEPSEEK_BASE_URL,
        "max_chat_turns": settings.MAX_CHAT_TURNS,
        "max_retries": settings.MAX_RETRIES,
        "CORS_ALLOW_ORIGINS": settings.CORS_ALLOW_ORIGINS,
    }


@router.get("/writer_seque")
async def get_writer_seque():
    # 返回论文顺序
    config_template: dict = get_config_template(CompTemplate.CHINA)
    return list(config_template.keys())


@router.get("/track")
async def track(task_id: str):
    # 获取任务的token使用情况

    pass


================================================================================
E:\repo1\MathModelAgent-python\backend\app\routers\files_router.py 的内容:
================================================================================
# app/router/files_router.py

from fastapi import APIRouter
from app.utils.common_utils import get_current_files, get_work_dir
import os
import subprocess
from icecream import ic
from fastapi import HTTPException

router = APIRouter()


@router.get("/files")
async def get_files(task_id: str):
    work_dir = get_work_dir(task_id)
    files = get_current_files(work_dir, "all")

    return {"files": files}


@router.get("/open_folder")
async def open_folder(task_id: str):
    ic(task_id)
    # 打开工作目录
    work_dir = get_work_dir(task_id)

    # 打开工作目录
    if os.name == "nt":
        subprocess.run(["explorer", work_dir])
    elif os.name == "posix":
        subprocess.run(["open", work_dir])
    else:
        raise HTTPException(status_code=500, detail=f"不支持的操作系统: {os.name}")

    return {"message": "打开工作目录成功", "work_dir": work_dir}


================================================================================
E:\repo1\MathModelAgent-python\backend\app\routers\modeling_router.py 的内容:
================================================================================
# app/router/modeling_router.py

from fastapi import APIRouter, BackgroundTasks, File, Form, UploadFile
from app.core.workflow import MathModelWorkFlow
from app.schemas.enums import CompTemplate, FormatOutPut
from app.utils.log_util import logger
from app.services.redis_manager import redis_manager
from app.schemas.request import Problem
from app.schemas.response import SystemMessage
from app.utils.common_utils import (
    create_task_id,
    create_work_dir,
    get_current_files,
    md_2_docx,
)
import os
import asyncio
from fastapi import HTTPException
from icecream import ic
from app.schemas.request import ExampleRequest
from pydantic import BaseModel
import litellm
from app.config.setting import settings

router = APIRouter()


class ValidateApiKeyRequest(BaseModel):
    api_key: str
    base_url: str = "https://api.openai.com/v1"
    model_id: str


class ValidateApiKeyResponse(BaseModel):
    valid: bool
    message: str


class SaveApiConfigRequest(BaseModel):
    coordinator: dict
    modeler: dict
    coder: dict
    writer: dict


@router.post("/save-api-config")
async def save_api_config(request: SaveApiConfigRequest):
    """
    保存验证成功的 API 配置到 settings
    """
    try:
        # 更新各个模块的设置
        if request.coordinator:
            settings.COORDINATOR_API_KEY = request.coordinator.get("apiKey", "")
            settings.COORDINATOR_MODEL = request.coordinator.get("modelId", "")
            settings.COORDINATOR_BASE_URL = request.coordinator.get("baseUrl", "")

        if request.modeler:
            settings.MODELER_API_KEY = request.modeler.get("apiKey", "")
            settings.MODELER_MODEL = request.modeler.get("modelId", "")
            settings.MODELER_BASE_URL = request.modeler.get("baseUrl", "")

        if request.coder:
            settings.CODER_API_KEY = request.coder.get("apiKey", "")
            settings.CODER_MODEL = request.coder.get("modelId", "")
            settings.CODER_BASE_URL = request.coder.get("baseUrl", "")

        if request.writer:
            settings.WRITER_API_KEY = request.writer.get("apiKey", "")
            settings.WRITER_MODEL = request.writer.get("modelId", "")
            settings.WRITER_BASE_URL = request.writer.get("baseUrl", "")

        return {"success": True, "message": "配置保存成功"}
    except Exception as e:
        logger.error(f"保存配置失败: {str(e)}")
        raise HTTPException(status_code=500, detail=f"保存配置失败: {str(e)}")


@router.post("/validate-api-key", response_model=ValidateApiKeyResponse)
async def validate_api_key(request: ValidateApiKeyRequest):
    """
    验证 API Key 的有效性
    """
    try:
        # 使用 litellm 发送测试请求
        await litellm.acompletion(
            model=request.model_id,
            messages=[{"role": "user", "content": "Hi"}],
            max_tokens=1,
            api_key=request.api_key,
            base_url=request.base_url if request.base_url != "https://api.openai.com/v1" else None,
        )

        return ValidateApiKeyResponse(valid=True, message="✓ 模型 API 验证成功")
    except Exception as e:
        error_msg = str(e)

        # 解析不同类型的错误
        if "401" in error_msg or "Unauthorized" in error_msg:
            return ValidateApiKeyResponse(valid=False, message="✗ API Key 无效或已过期")
        elif "404" in error_msg or "Not Found" in error_msg:
            return ValidateApiKeyResponse(valid=False, message="✗ 模型 ID 不存在或 Base URL 错误")
        elif "429" in error_msg or "rate limit" in error_msg.lower():
            return ValidateApiKeyResponse(valid=False, message="✗ 请求过于频繁，请稍后再试")
        elif "403" in error_msg or "Forbidden" in error_msg:
            return ValidateApiKeyResponse(valid=False, message="✗ API 权限不足或账户余额不足")
        else:
            return ValidateApiKeyResponse(valid=False, message=f"✗ 验证失败: {error_msg[:200]}...")


@router.post("/example")
async def exampleModeling(
    example_request: ExampleRequest,
    background_tasks: BackgroundTasks,
):
    task_id = create_task_id()
    work_dir = create_work_dir(task_id)
    example_dir = os.path.join("app", "example", "example", example_request.source)
    ic(example_dir)
    with open(os.path.join(example_dir, "questions.txt"), "r", encoding="utf-8") as f:
        ques_all = f.read()

    current_files = get_current_files(example_dir, "data")
    for file in current_files:
        src_file = os.path.join(example_dir, file)
        dst_file = os.path.join(work_dir, file)
        with open(src_file, "rb") as src, open(dst_file, "wb") as dst:
            dst.write(src.read())
    # 存储任务ID
    await redis_manager.set(f"task_id:{task_id}", task_id)

    logger.info(f"Adding background task for task_id: {task_id}")
    # 将任务添加到后台执行
    background_tasks.add_task(
        run_modeling_task_async,
        task_id,
        ques_all,
        CompTemplate.CHINA,
        FormatOutPut.Markdown,
    )
    return {"task_id": task_id, "status": "processing"}


@router.post("/modeling")
async def modeling(
    background_tasks: BackgroundTasks,
    ques_all: str = Form(...),  # 从表单获取
    comp_template: CompTemplate = Form(...),  # 从表单获取
    format_output: FormatOutPut = Form(...),  # 从表单获取
    files: list[UploadFile] = File(default=None),
):
    task_id = create_task_id()
    work_dir = create_work_dir(task_id)

    # 如果有上传文件，保存文件
    if files:
        logger.info(f"开始处理上传的文件，工作目录: {work_dir}")
        for file in files:
            try:
                data_file_path = os.path.join(work_dir, file.filename)
                logger.info(f"保存文件: {file.filename} -> {data_file_path}")

                # 确保文件名不为空
                if not file.filename:
                    logger.warning("跳过空文件名")
                    continue

                content = await file.read()
                if not content:
                    logger.warning(f"文件 {file.filename} 内容为空")
                    continue

                with open(data_file_path, "wb") as f:
                    f.write(content)
                logger.info(f"成功保存文件: {data_file_path}")

            except Exception as e:
                logger.error(f"保存文件 {file.filename} 失败: {str(e)}")
                raise HTTPException(status_code=500, detail=f"保存文件 {file.filename} 失败: {str(e)}")
    else:
        logger.warning("没有上传文件")

    # 存储任务ID
    await redis_manager.set(f"task_id:{task_id}", task_id)

    logger.info(f"Adding background task for task_id: {task_id}")
    # 将任务添加到后台执行
    background_tasks.add_task(run_modeling_task_async, task_id, ques_all, comp_template, format_output)
    return {"task_id": task_id, "status": "processing"}


async def run_modeling_task_async(
    task_id: str,
    ques_all: str,
    comp_template: CompTemplate,
    format_output: FormatOutPut,
):
    logger.info(f"run modeling task for task_id: {task_id}")

    problem = Problem(
        task_id=task_id,
        ques_all=ques_all,
        comp_template=comp_template,
        format_output=format_output,
    )

    # 发送任务开始状态
    await redis_manager.publish_message(
        task_id,
        SystemMessage(content="任务开始处理"),
    )

    # 给一个短暂的延迟，确保 WebSocket 有机会连接
    await asyncio.sleep(1)

    # 创建任务并保护其不被上层取消；通过回调统一发送“完成/失败”
    task = asyncio.create_task(MathModelWorkFlow().execute(problem))

    def _on_done(t: asyncio.Task):
        async def _notify():
            try:
                t.result()  # 触发异常若有
                await redis_manager.publish_message(
                    task_id,
                    SystemMessage(content="任务处理完成", type="success"),
                )
                md_2_docx(task_id)
            except Exception as e:
                await redis_manager.publish_message(
                    task_id,
                    SystemMessage(content=f"任务失败: {e}", type="error"),
                )

        asyncio.create_task(_notify())

    task.add_done_callback(_on_done)

    # 等待最多 600 分钟，但即使超时也不取消底层任务（继续后台执行）
    try:
        await asyncio.wait_for(asyncio.shield(task), timeout=36000)
    except asyncio.TimeoutError:
        await redis_manager.publish_message(
            task_id,
            SystemMessage(content="任务超过600分钟，已转为后台继续运行", type="info"),
        )
        return


================================================================================
E:\repo1\MathModelAgent-python\backend\app\routers\ws_router.py 的内容:
================================================================================
# app/router/ws_router.py

from fastapi import WebSocket, WebSocketDisconnect, APIRouter
from app.services.redis_manager import redis_manager
from app.schemas.response import SystemMessage
import asyncio
from app.services.ws_manager import ws_manager
import json

router = APIRouter()


@router.websocket("/task/{task_id}")
async def websocket_endpoint(websocket: WebSocket, task_id: str):
    print(f"WebSocket 尝试连接 task_id: {task_id}")

    redis_async_client = await redis_manager.get_client()
    if not await redis_async_client.exists(f"task_id:{task_id}"):
        print(f"Task not found: {task_id}")
        await websocket.close(code=1008, reason="Task not found")
        return
    print(f"WebSocket connected for task: {task_id}")

    # 建立 WebSocket 连接
    await ws_manager.connect(websocket)
    websocket.timeout = 6000
    print(f"WebSocket connection status: {websocket.client}")

    # 订阅 Redis 频道
    pubsub = await redis_manager.subscribe_to_task(task_id)
    print(f"Subscribed to Redis channel: task:{task_id}:messages")

    await redis_manager.publish_message(
        task_id,
        SystemMessage(content="任务开始处理"),
    )

    try:
        while True:
            try:
                msg = await pubsub.get_message(ignore_subscribe_messages=True)
                if msg:
                    print(f"Received message: {msg}")
                    try:
                        msg_dict = json.loads(msg["data"])
                        await ws_manager.send_personal_message_json(msg_dict, websocket)
                        print(f"Sent message to WebSocket: {msg_dict}")
                    except Exception as e:
                        print(f"Error parsing message: {e}")
                        await ws_manager.send_personal_message_json({"error": str(e)}, websocket)
                await asyncio.sleep(0.1)

            except WebSocketDisconnect:
                print("WebSocket disconnected")
                break
            except Exception as e:
                print(f"Error in websocket loop: {e}")
                await asyncio.sleep(1)
                continue

    except Exception as e:
        print(f"WebSocket error: {e}")
    finally:
        await pubsub.unsubscribe(f"task:{task_id}:messages")
        ws_manager.disconnect(websocket)
        print(f"WebSocket connection closed for task: {task_id}")


================================================================================
E:\repo1\MathModelAgent-python\backend\app\schemas\A2A.py 的内容:
================================================================================
# app/schemas/A2A.py

from pydantic import BaseModel
from typing import Any


class CoordinatorToModeler(BaseModel):
    questions: dict
    ques_count: int


class ModelerToCoder(BaseModel):
    questions_solution: dict[str, str]


class CoderToWriter(BaseModel):
    code_response: str | None = None
    code_output: str | None = None
    created_images: list[str] | None = None


class WriterResponse(BaseModel):
    response_content: Any
    footnotes: list[tuple[str, str]] | None = None


================================================================================
E:\repo1\MathModelAgent-python\backend\app\schemas\base.py 的内容:
================================================================================
# app/schemas/base.py


================================================================================
E:\repo1\MathModelAgent-python\backend\app\schemas\enums.py 的内容:
================================================================================
# app/schemas/enums.py

from enum import Enum


class CompTemplate(str, Enum):
    CHINA: str = "CHINA"
    AMERICAN: str = "AMERICAN"


class FormatOutPut(str, Enum):
    Markdown: str = "Markdown"
    LaTeX: str = "LaTeX"


class AgentType(str, Enum):
    COORDINATOR = "CoordinatorAgent"
    MODELER = "ModelerAgent"
    CODER = "CoderAgent"
    WRITER = "WriterAgent"
    SYSTEM = "SystemAgent"


class AgentStatus(str, Enum):
    START = "start"
    WORKING = "working"
    DONE = "done"
    ERROR = "error"
    SUCCESS = "success"


================================================================================
E:\repo1\MathModelAgent-python\backend\app\schemas\request.py 的内容:
================================================================================
# app/schemas/request.py

from pydantic import BaseModel
from app.schemas.enums import CompTemplate, FormatOutPut


class ExampleRequest(BaseModel):
    example_id: str
    source: str


class Problem(BaseModel):
    task_id: str
    ques_all: str = ""
    comp_template: CompTemplate = CompTemplate.CHINA
    format_output: FormatOutPut = FormatOutPut.Markdown

    def model_dump(self, **kwargs):
        data = super().model_dump(**kwargs)
        data["comp_template"] = self.comp_template.value
        data["format_output"] = self.format_output.value
        return data


================================================================================
E:\repo1\MathModelAgent-python\backend\app\schemas\response.py 的内容:
================================================================================
# app/schemas/response.py

from typing import Literal, Union, Any
from app.schemas.enums import AgentType
from pydantic import BaseModel, Field
from uuid import uuid4


class Message(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid4()))
    msg_type: Literal["system", "agent", "user", "tool"]  # system msg | agent message | user message | tool message
    # 允许结构化内容：dict/list/str 等
    content: Any = None


class ToolMessage(Message):
    msg_type: str = "tool"
    tool_name: Literal["execute_code", "search_scholar"]
    input: dict
    output: list


class SystemMessage(Message):
    msg_type: str = "system"
    type: Literal["info", "warning", "success", "error"] = "info"


class UserMessage(Message):
    msg_type: str = "user"


class AgentMessage(Message):
    msg_type: str = "agent"
    agent_type: AgentType  # CoordinatorAgent | ModelerAgent | CoderAgent | WriterAgent


class ModelerMessage(AgentMessage):
    agent_type: AgentType = AgentType.MODELER


class CoordinatorMessage(AgentMessage):
    agent_type: AgentType = AgentType.COORDINATOR


class CodeExecution(BaseModel):
    res_type: Literal["stdout", "stderr", "result", "error"]
    msg: str | None = None


class StdOutModel(CodeExecution):
    res_type: str = "stdout"


class StdErrModel(CodeExecution):
    res_type: str = "stderr"


class ResultModel(CodeExecution):
    res_type: str = "result"
    format: Literal[
        "text",
        "html",
        "markdown",
        "png",
        "jpeg",
        "svg",
        "pdf",
        "latex",
        "json",
        "javascript",
    ]


class ErrorModel(CodeExecution):
    res_type: str = "error"
    name: str
    value: str
    traceback: str


# 代码执行结果类型
OutputItem = Union[StdOutModel, StdErrModel, ResultModel, ErrorModel]


class ScholarMessage(ToolMessage):
    tool_name: str = "search_scholar"
    input: dict | None = None  # query
    output: list[str] | None = None  # cites


class InterpreterMessage(ToolMessage):
    tool_name: str = "execute_code"
    input: dict | None = None  # code
    output: list[OutputItem] | None = None  # code_results


# 1. 只带 code
# 2. 只带 code result
class CoderMessage(AgentMessage):
    agent_type: AgentType = AgentType.CODER


class WriterMessage(AgentMessage):
    agent_type: AgentType = AgentType.WRITER
    sub_title: str | None = None


# 所有可能的消息类型
MessageType = Union[
    SystemMessage,
    UserMessage,
    ModelerMessage,
    CoderMessage,
    WriterMessage,
    CoordinatorMessage,
]


================================================================================
E:\repo1\MathModelAgent-python\backend\app\schemas\tool_result.py 的内容:
================================================================================
# app/schemas/tool_result.py

from pydantic import BaseModel
from typing import Any, Optional


class ToolResult(BaseModel):
    success: bool
    message: Optional[str] = None
    data: Optional[Any] = None


================================================================================
E:\repo1\MathModelAgent-python\backend\app\services\redis_manager.py 的内容:
================================================================================
# app/services/redis_manager.py

import redis.asyncio as aioredis
from typing import Optional, Any, Dict, Union
import json
from pathlib import Path
from app.config.setting import settings
from app.schemas.response import Message  # v1/v2 pydantic model
from app.utils.log_util import logger
from uuid import uuid4


def _json_safe(obj: Any) -> Any:
    """
    递归将对象转换为 JSON 可序列化的结构：
    - Pydantic v1/v2 -> dict()
    - dict/list/tuple/set 递归处理（set -> list；tuple -> list）
    - bytes -> utf-8 解码失败则转十六进制字符串
    - 其余不可序列化对象 -> str(obj)
    """
    # 原生可序列化类型
    if obj is None or isinstance(obj, (bool, int, float, str)):
        return obj

    # Pydantic v2/v1
    if hasattr(obj, "model_dump") and callable(obj.model_dump):
        try:
            return _json_safe(obj.model_dump())
        except Exception:
            pass
    if hasattr(obj, "dict") and callable(obj.dict):
        try:
            return _json_safe(obj.dict())
        except Exception:
            pass

    # 容器类型
    if isinstance(obj, dict):
        return {k: _json_safe(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple)):
        return [_json_safe(v) for v in obj]
    if isinstance(obj, set):
        return [_json_safe(v) for v in obj]

    # bytes
    if isinstance(obj, (bytes, bytearray, memoryview)):
        try:
            return bytes(obj).decode("utf-8")
        except Exception:
            return bytes(obj).hex()

    # 其他：转字符串兜底
    try:
        return str(obj)
    except Exception:
        return f"<unserializable:{type(obj).__name__}>"


def _normalize_message_payload(message: Union[Message, Dict[str, Any]]) -> Dict[str, Any]:
    """
    统一清洗消息对象为 JSON-safe dict（不强制把 content 变成字符串）：
    1) 支持 Pydantic v1/v2（优先用 model_dump / dict）
    2) 兜底生成 id / msg_type
    3) 对整个 payload 做 _json_safe，确保可序列化
    """
    # 1) 提取为字典
    if hasattr(message, "model_dump"):  # pydantic v2
        raw = message.model_dump()
    elif hasattr(message, "dict"):  # pydantic v1
        raw = message.dict()
    elif isinstance(message, dict):
        raw = dict(message)
    else:
        # 极端兜底：未知类型
        raw = {
            "id": str(uuid4()),
            "msg_type": "system",
            "content": f"{message}",
            "type": "warning",
        }

    # 2) id / msg_type 兜底
    if not isinstance(raw.get("id"), str) or not raw.get("id"):
        raw["id"] = str(uuid4())
    if not isinstance(raw.get("msg_type"), str) or not raw.get("msg_type"):
        raw["msg_type"] = "system"

    # 3) JSON 安全化（保持 content 的原始结构：str/dict/list…）
    payload = _json_safe(raw)

    # 最后校验：如仍不可序列化，逐字段兜底
    try:
        json.dumps(payload, ensure_ascii=False)
    except TypeError:
        safe_payload: Dict[str, Any] = {}
        for k, v in payload.items():
            try:
                json.dumps({k: v}, ensure_ascii=False)
                safe_payload[k] = v
            except TypeError:
                safe_payload[k] = _json_safe(str(v))
        payload = safe_payload

    return payload


class RedisManager:
    def __init__(self):
        self.redis_url = settings.REDIS_URL
        self._client: Optional[aioredis.Redis] = None
        # 创建消息存储目录
        self.messages_dir = Path("logs/messages")
        self.messages_dir.mkdir(parents=True, exist_ok=True)

    async def get_client(self) -> aioredis.Redis:
        if self._client is None:
            self._client = aioredis.Redis.from_url(
                self.redis_url,
                decode_responses=True,
                max_connections=getattr(settings, "REDIS_MAX_CONNECTIONS", None),
            )
        logger.info(f"Redis 连接建立成功: {self.redis_url}")
        return self._client

    async def set(self, key: str, value: str):
        """设置Redis键值对"""
        client = await self.get_client()
        await client.set(key, value)
        # 10 小时过期（保持你原来逻辑）
        await client.expire(key, 36000)

    async def _save_message_to_file(self, task_id: str, message: Union[Message, Dict[str, Any]]):
        """将消息保存到文件中，同一任务的消息保存在同一个文件中"""
        try:
            payload = _normalize_message_payload(message)

            # 确保目录存在
            self.messages_dir.mkdir(exist_ok=True)

            # 使用任务ID作为文件名
            file_path = self.messages_dir / f"{task_id}.json"

            # 读取现有消息（如果文件存在）
            messages = []
            if file_path.exists():
                with open(file_path, "r", encoding="utf-8") as f:
                    try:
                        messages = json.load(f)
                    except Exception:
                        messages = []

            # 添加新消息
            messages.append(payload)

            # 保存所有消息到文件
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(messages, f, ensure_ascii=False, indent=2)

            logger.debug(f"消息已追加到文件: {file_path}")
        except Exception as e:
            logger.error(f"保存消息到文件失败: {str(e)}")
            # 不抛异常，保证主流程不受影响

    async def publish_message(self, task_id: str, message: Union[Message, Dict[str, Any]]):
        """
        发布消息到特定任务的频道并保存到文件
        - 仅对“最外层 payload”序列化一次
        - 不再把 payload['content'] 强制转为字符串
        """
        client = await self.get_client()
        channel = f"task:{task_id}:messages"
        payload = _normalize_message_payload(message)
        try:
            # 构造预览字符串（不改变 content 原类型）
            try:
                content_preview = (
                    payload.get("content", "")
                    if isinstance(payload.get("content", ""), str)
                    else json.dumps(payload.get("content", ""), ensure_ascii=False)
                )
            except Exception:
                content_preview = "<preview 生成失败>"

            # 仅序列化一层
            message_json = json.dumps(payload, ensure_ascii=False)
            publish_result = await client.publish(channel, message_json)
            logger.info(
                f"发布到频道 {channel} 成功，订阅者数量: {publish_result}. "
                f"msg_type:{payload.get('msg_type')} "
                f"content_preview:{str(content_preview)[:200]}"
            )

            # 落盘
            await self._save_message_to_file(task_id, payload)

            return publish_result

        except Exception as e:
            logger.exception(f"发布消息失败: task_id={task_id} channel={channel} error={e}")
            raise

    async def subscribe_to_task(self, task_id: str):
        """订阅特定任务的消息"""
        client = await self.get_client()
        pubsub = client.pubsub()
        await pubsub.subscribe(f"task:{task_id}:messages")
        return pubsub

    async def close(self):
        """关闭Redis连接"""
        if self._client:
            await self._client.close()
            self._client = None


# singleton
redis_manager = RedisManager()


================================================================================
E:\repo1\MathModelAgent-python\backend\app\services\ws_manager.py 的内容:
================================================================================
# app/services/ws_manager.py

from fastapi import WebSocket


class WebSocketManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def send_personal_message_json(self, message: dict, websocket: WebSocket):
        await websocket.send_json(message)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)


ws_manager = WebSocketManager()


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tests\get_config_template.py 的内容:
================================================================================
# app/tests/get_config_template.py

import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from app.schemas.enums import CompTemplate


def test_get_config_template():
    from app.utils.common_utils import get_config_template

    comp_template = CompTemplate.CHINA
    config_template = get_config_template(comp_template)
    print(config_template)


if __name__ == "__main__":
    test_get_config_template()


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tests\test_common_utils.py 的内容:
================================================================================
# app/tests/test_common_utils.py

import unittest

from app.utils.common_utils import split_footnotes


class TestCommonUtils(unittest.TestCase):
    def test_split_footnotes(self):
        text = "Example[^1]\n\n[^1]: Footnote content"
        main, notes = split_footnotes(text)
        self.assertEqual(main, "Example")
        self.assertEqual(notes, [("1", "Footnote content")])


if __name__ == "__main__":
    unittest.main()


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tests\test_e2b.py 的内容:
================================================================================
# app/tests/test_e2b.py

import os
import asyncio
import unittest


from dotenv import load_dotenv

from app.tools.e2b_interpreter import E2BCodeInterpreter
from app.utils.common_utils import create_work_dir

try:
    from dotenv import load_dotenv
except ModuleNotFoundError:  # Fallback if python-dotenv is not installed

    def load_dotenv(*args, **kwargs):
        return None


try:
    from app.tools.e2b_interpreter import E2BCodeInterpreter
except ModuleNotFoundError:
    E2BCodeInterpreter = None
from app.utils.common_utils import create_task_id, create_work_dir


class TestE2BCodeInterpreter(unittest.TestCase):
    def setUp(self):
        load_dotenv()

        if E2BCodeInterpreter is None:
            self.skipTest("e2b_code_interpreter not available")
        _, dirs = create_work_dir("20250312-104132-d3625cab")
        notebook = NotebookSerializer(dirs["jupyter"])

        self.code_interpreter = E2BCodeInterpreter(self.task_id, self.work_dir, notebook)

    def test_execute_code(self):
        if not os.getenv("E2B_API_KEY"):
            self.skipTest("E2B_API_KEY not set")

        code = """
import matplotlib.pyplot as plt
import numpy as np

# 生成数据
x = np.linspace(0, 2 * np.pi, 100)  # x从0到2π，生成100个点
y = np.sin(x)                       # 计算对应的sin(x)值

# 绘图
plt.figure(figsize=(8, 4))          # 设置画布大小
plt.plot(x, y, label='y = sin(x)')  # 绘制曲线，并添加图例

# 添加标签和标题
plt.title("Simple Sine Function")
plt.xlabel("x")
plt.ylabel("y")

# 添加网格和图例
plt.grid(True)
plt.legend()

# 显示图像
plt.show()
"""
        asyncio.run(self.code_interpreter.initialize())
        asyncio.run(self.code_interpreter.execute_code(code))


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tools\base.py 的内容:
================================================================================
# app/tools/base.py

from typing import Dict, Any, List, Callable
import inspect
from app.schemas.tool_result import ToolResult


def tool(
    name: str,
    description: str,
    parameters: Dict[str, Dict[str, Any]],
    required: List[str],
) -> Callable:
    """Tool registration decorator

    Args:
        name: Tool name
        description: Tool description
        parameters: Tool parameter definitions
        required: List of required parameters

    Returns:
        Decorator function
    """

    def decorator(func):
        # Create tool schema directly using provided parameters, without automatic extraction
        schema = {
            "type": "function",
            "function": {
                "name": name,
                "description": description,
                "parameters": {
                    "type": "object",
                    "properties": parameters,
                    "required": required,
                },
            },
        }

        # Store tool information
        func._function_name = name
        func._tool_description = description
        func._tool_schema = schema

        return func

    return decorator


class BaseTool:
    """Base tool class, providing common tool calling methods"""

    name: str = ""

    def __init__(self):
        """Initialize base tool class"""
        self._tools_cache = None

    def get_tools(self) -> List[Dict[str, Any]]:
        """Get all registered tools

        Returns:
            List of tools
        """
        if self._tools_cache is not None:
            return self._tools_cache

        tools = []
        for _, method in inspect.getmembers(self, inspect.ismethod):
            if hasattr(method, "_tool_schema"):
                tools.append(method._tool_schema)

        self._tools_cache = tools
        return tools

    def has_function(self, function_name: str) -> bool:
        """Check if specified function exists

        Args:
            function_name: Function name

        Returns:
            Whether the tool exists
        """
        for _, method in inspect.getmembers(self, inspect.ismethod):
            if hasattr(method, "_function_name") and method._function_name == function_name:
                return True
        return False

    async def invoke_function(self, function_name: str, **kwargs) -> ToolResult:
        """Invoke specified tool

        Args:
            function_name: Function name
            **kwargs: Parameters

        Returns:
            Invocation result

        Raises:
            ValueError: Raised when tool doesn't exist
        """
        for _, method in inspect.getmembers(self, inspect.ismethod):
            if hasattr(method, "_function_name") and method._function_name == function_name:
                return await method(**kwargs)

        raise ValueError(f"Tool '{function_name}' not found")


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tools\base_interpreter.py 的内容:
================================================================================
# app/tools/base_interpreter.py

import abc
import re
import json
from app.tools.notebook_serializer import NotebookSerializer
from app.services.redis_manager import redis_manager
from app.utils.log_util import logger
from app.schemas.response import (
    OutputItem,
    InterpreterMessage,
)


class BaseCodeInterpreter(abc.ABC):
    def __init__(
        self,
        task_id: str,
        work_dir: str,
        notebook_serializer: NotebookSerializer,
    ):
        self.task_id = task_id
        self.work_dir = work_dir
        self.notebook_serializer = notebook_serializer
        self.section_output: dict[str, dict[str, list[str]]] = {}
        self.last_created_images = set()

    @abc.abstractmethod
    async def initialize(self):
        """初始化解释器，必要时上传文件、启动内核等"""
        ...

    @abc.abstractmethod
    async def _pre_execute_code(self):
        """执行初始化代码"""
        ...

    @abc.abstractmethod
    async def execute_code(self, code: str) -> tuple[str, bool, str]:
        """执行一段代码，返回 (输出文本, 是否出错, 错误信息)"""
        ...

    @abc.abstractmethod
    async def cleanup(self):
        """清理资源，比如关闭沙箱或内核"""
        ...

    @abc.abstractmethod
    async def get_created_images(self, section: str) -> list[str]:
        """获取当前 section 创建的图片列表"""
        ...

    async def _push_to_websocket(self, content_to_display: list[OutputItem] | None):
        logger.info("执行结果已推送到WebSocket")

        agent_msg = InterpreterMessage(
            output=content_to_display,
        )
        await redis_manager.publish_message(
            self.task_id,
            agent_msg,
        )

    def add_section(self, section_name: str) -> None:
        """确保添加的section结构正确"""

        if section_name not in self.section_output:
            self.section_output[section_name] = {"content": [], "images": []}

    def add_content(self, section: str, text: str) -> None:
        """向指定section添加文本内容"""
        self.add_section(section)
        self.section_output[section]["content"].append(text)

    def get_code_output(self, section: str) -> str:
        """获取指定section的代码输出"""
        return "\n".join(self.section_output[section]["content"])

    def delete_color_control_char(self, string):
        ansi_escape = re.compile(r"(\x9B|\x1B\[)[0-?]*[ -\/]*[@-~]")
        return ansi_escape.sub("", string)

    def _truncate_text(self, text: str, max_length: int = 1000) -> str:
        """截断文本，保留开头和结尾的重要信息"""
        if len(text) <= max_length:
            return text

        half_length = max_length // 2
        return text[:half_length] + "\n... (内容已截断) ...\n" + text[-half_length:]


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tools\e2b_interpreter.py 的内容:
================================================================================
# app/tools/e2b_interpreter.py

import os
from e2b_code_interpreter import AsyncSandbox
from app.schemas.response import (
    ErrorModel,
    OutputItem,
    ResultModel,
    StdErrModel,
    StdOutModel,
    SystemMessage,
)
from app.services.redis_manager import redis_manager
from app.tools.notebook_serializer import NotebookSerializer
from app.utils.log_util import logger
from app.config.setting import settings
import json
from app.tools.base_interpreter import BaseCodeInterpreter


class E2BCodeInterpreter(BaseCodeInterpreter):
    def __init__(
        self,
        task_id: str,
        work_dir: str,
        notebook_serializer: NotebookSerializer,
    ):
        super().__init__(task_id, work_dir, notebook_serializer)
        self.sbx = None

    @classmethod
    async def create(
        cls,
        task_id: str,
        work_dir: str,
        notebook_serializer: NotebookSerializer,
    ) -> "E2BCodeInterpreter":
        """创建并初始化 E2BCodeInterpreter 实例"""
        instance = cls(task_id, work_dir, notebook_serializer)
        return instance

    async def initialize(self, timeout: int = 3000):
        """异步初始化沙箱环境"""
        try:
            self.sbx = await AsyncSandbox.create(api_key=settings.E2B_API_KEY, timeout=timeout)
            logger.info("沙箱环境初始化成功")
            await self._pre_execute_code()
            await self._upload_all_files()
        except Exception as e:
            logger.error(f"初始化沙箱环境失败: {str(e)}")
            raise

    async def _upload_all_files(self):
        """上传工作目录中的所有文件到沙箱"""
        try:
            logger.info(f"开始上传文件，工作目录: {self.work_dir}")
            if not os.path.exists(self.work_dir):
                logger.error(f"工作目录不存在: {self.work_dir}")
                raise FileNotFoundError(f"工作目录不存在: {self.work_dir}")

            files = [f for f in os.listdir(self.work_dir) if f.endswith((".csv", ".xlsx"))]
            logger.info(f"工作目录中的文件列表: {files}")

            for file in files:
                file_path = os.path.join(self.work_dir, file)
                if os.path.isfile(file_path):
                    try:
                        with open(file_path, "rb") as f:
                            content = f.read()
                            # 使用官方推荐的 files.write 方法
                            await self.sbx.files.write(f"/home/user/{file}", content)
                            logger.info(f"成功上传文件到沙箱: {file}")
                    except Exception as e:
                        logger.error(f"上传文件 {file} 失败: {str(e)}")
                        raise

        except Exception as e:
            logger.error(f"文件上传过程失败: {str(e)}")
            raise

    async def _pre_execute_code(self):
        init_code = (
            "import matplotlib.pyplot as plt\n"
            # "plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS']\n"
            # "plt.rcParams['axes.unicode_minus'] = False\n"
            # "plt.rcParams['font.family'] = 'sans-serif'\n"
        )
        await self.execute_code(init_code)

    async def execute_code(self, code: str) -> tuple[str, bool, str]:
        """执行代码并返回结果"""

        if not self.sbx:
            raise RuntimeError("沙箱环境未初始化")

        logger.info(f"执行代码: {code}")
        self.notebook_serializer.add_code_cell_to_notebook(code)

        text_to_gpt: list[str] = []
        content_to_display: list[OutputItem] | None = []
        error_occurred: bool = False
        error_message: str = ""

        await redis_manager.publish_message(
            self.task_id,
            SystemMessage(content="开始执行代码"),
        )
        # 执行 Python 代码
        logger.info("开始在沙箱中执行代码...")
        execution = await self.sbx.run_code(code)  # 返回 Execution 对象
        logger.info("代码执行完成，开始处理结果...")

        await redis_manager.publish_message(
            self.task_id,
            SystemMessage(content="代码执行完成"),
        )

        # 处理执行错误
        if execution.error:
            error_occurred = True
            error_message = f"Error: {execution.error.name}: {execution.error.value}\n{execution.error.traceback}"
            error_message = self._truncate_text(error_message)
            logger.error(f"执行错误: {error_message}")
            text_to_gpt.append(self.delete_color_control_char(error_message))
            content_to_display.append(
                ErrorModel(
                    name=execution.error.name,
                    value=execution.error.value,
                    traceback=execution.error.traceback,
                )
            )
        # 处理标准输出和标准错误

        if execution.logs:
            if execution.logs.stdout:
                stdout_str = "\n".join(execution.logs.stdout)
                stdout_str = self._truncate_text(stdout_str)
                logger.info(f"标准输出: {stdout_str}")
                text_to_gpt.append(stdout_str)
                content_to_display.append(StdOutModel(msg="\n".join(execution.logs.stdout)))
                self.notebook_serializer.add_code_cell_output_to_notebook(stdout_str)

            if execution.logs.stderr:
                stderr_str = "\n".join(execution.logs.stderr)
                stderr_str = self._truncate_text(stderr_str)
                logger.warning(f"标准错误: {stderr_str}")
                text_to_gpt.append(stderr_str)
                content_to_display.append(StdErrModel(msg="\n".join(execution.logs.stderr)))

            # 处理执行结果
        if execution.results:
            for result in execution.results:
                # 1. 文本格式
                if str(result):
                    content_to_display.append(ResultModel(type="result", format="text", msg=str(result)))
                # 2. HTML格式
                if result._repr_html_():
                    content_to_display.append(ResultModel(type="result", format="html", msg=result._repr_html_()))
                # 3. Markdown格式
                if result._repr_markdown_():
                    content_to_display.append(
                        ResultModel(
                            type="result",
                            format="markdown",
                            msg=result._repr_markdown_(),
                        )
                    )
                # 4. PNG图片（base64字符串，前端可直接渲染）
                if result._repr_png_():
                    content_to_display.append(ResultModel(type="result", format="png", msg=result._repr_png_()))
                # 5. JPEG图片
                if result._repr_jpeg_():
                    content_to_display.append(ResultModel(type="result", format="jpeg", msg=result._repr_jpeg_()))
                # 6. SVG
                if result._repr_svg_():
                    content_to_display.append(ResultModel(type="result", format="svg", msg=result._repr_svg_()))
                # 7. PDF
                if result._repr_pdf_():
                    content_to_display.append(ResultModel(type="result", format="pdf", msg=result._repr_pdf_()))
                # 8. LaTeX
                if result._repr_latex_():
                    content_to_display.append(ResultModel(type="result", format="latex", msg=result._repr_latex_()))
                # 9. JSON
                if result._repr_json_():
                    content_to_display.append(
                        ResultModel(
                            type="result",
                            format="json",
                            msg=json.dumps(result._repr_json_(), ensure_ascii=False),
                        )
                    )
                # 10. JavaScript
                if result._repr_javascript_():
                    content_to_display.append(
                        ResultModel(
                            type="result",
                            format="javascript",
                            msg=result._repr_javascript_(),
                        )
                    )

                    # 处理主要结果
                # if result.is_main_result and result.text:
                #     result_text = self._truncate_text(result.text)
                #     logger.info(f"主要结果: {result_text}")
                #     text_to_gpt.append(result_text)
                #     self.notebook_serializer.add_code_cell_output_to_notebook(
                #         result_text
                #     )

        # 限制返回的文本总长度

        for item in content_to_display:
            if isinstance(item, dict):
                if item.get("type") in ["stdout", "stderr", "error"]:
                    text_to_gpt.append(self._truncate_text(item.get("content") or item.get("value") or ""))
            elif isinstance(item, ResultModel):
                if item.format in ["text", "html", "markdown", "json"]:
                    text_to_gpt.append(self._truncate_text(f"[{item.format}]\n{item.msg}"))
                elif item.format in ["png", "jpeg", "svg", "pdf"]:
                    text_to_gpt.append(f"[{item.format} 图片已生成，内容为 base64，未展示]")

        logger.info(f"text_to_gpt: {text_to_gpt}")

        combined_text = "\n".join(text_to_gpt)

        # 在代码执行完成后，立即同步文件
        try:
            await self.download_all_files_from_sandbox()
            logger.info("文件同步完成")
        except Exception as e:
            logger.error(f"文件同步失败: {str(e)}")

        # 保存到分段内容
        ## TODO: Base64 等图像需要优化
        await self._push_to_websocket(content_to_display)

        return (
            combined_text,
            error_occurred,
            error_message,
        )

    async def get_created_images(self, section: str) -> list[str]:
        """获取当前 section 创建的图片列表"""
        if not self.sbx:
            logger.warning("沙箱环境未初始化")
            return []

        try:
            files = await self.sbx.files.list("./")
            for file in files:
                if file.path.endswith(".png") or file.path.endswith(".jpg"):
                    self.add_section(section)
                    self.section_output[section]["images"].append(file.name)

            self.created_images = list(set(self.section_output[section]["images"]) - set(self.created_images))
            logger.info(f"{section}-获取创建的图片列表: {self.created_images}")
            return self.created_images
        except Exception as e:
            logger.error(f"获取创建的图片列表失败: {str(e)}")
            return []

    async def cleanup(self):
        """清理资源并关闭沙箱"""
        try:
            if self.sbx:
                if await self.sbx.is_running():
                    try:
                        await self.download_all_files_from_sandbox()
                    except Exception as e:
                        logger.error(f"下载文件失败: {str(e)}")
                    finally:
                        await self.sbx.kill()
                        logger.info("成功关闭沙箱环境")
                else:
                    logger.warning("沙箱已经关闭，跳过清理步骤")
        except Exception as e:
            logger.error(f"清理沙箱环境失败: {str(e)}")
            # 这里可以选择不抛出异常，因为这是清理步骤

    async def download_all_files_from_sandbox(self) -> None:
        """从沙箱中下载所有文件并与本地同步"""
        try:
            # 获取沙箱中的文件列表
            sandbox_files = await self.sbx.files.list("/home/user")
            sandbox_files_dict = {f.name: f for f in sandbox_files}

            # 获取本地文件列表
            local_files = set()
            if os.path.exists(self.work_dir):
                local_files = set(os.listdir(self.work_dir))

            # 下载新文件或更新已修改的文件
            for file in sandbox_files:
                try:
                    # 排除 .bash_logout、.bashrc 和 .profile 文件
                    if file.name in [".bash_logout", ".bashrc", ".profile"]:
                        continue

                    local_path = os.path.join(self.work_dir, file.name)
                    should_download = True

                    # 检查文件是否需要更新
                    if file.name in local_files:
                        # 这里可以添加文件修改时间或内容哈希的比较
                        # 暂时简单处理，有同名文件就更新
                        pass

                    if should_download:
                        # 使用 bytes 格式读取文件内容，确保正确处理二进制数据
                        content = await self.sbx.files.read(file.path, format="bytes")

                        # 确保目标目录存在
                        os.makedirs(self.work_dir, exist_ok=True)

                        # 写入文件
                        with open(local_path, "wb") as f:
                            f.write(content)
                        logger.info(f"同步文件: {file.name}")

                except Exception as e:
                    logger.error(f"同步文件 {file.name} 失败: {str(e)}")
                    continue

            logger.info("文件同步完成")

        except Exception as e:
            logger.error(f"文件同步失败: {str(e)}")


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tools\interpreter_factory.py 的内容:
================================================================================
# app/tools/interpreter_factory.py

from typing import Literal
from app.tools.e2b_interpreter import E2BCodeInterpreter
from app.tools.local_interpreter import LocalCodeInterpreter
from app.tools.notebook_serializer import NotebookSerializer
from app.config.setting import settings
from app.utils.log_util import logger


async def create_interpreter(
    kind: Literal["remote", "local"] = "local",
    *,
    task_id: str,
    work_dir: str,
    notebook_serializer: NotebookSerializer,
    timeout=36000,
):
    if not settings.E2B_API_KEY:
        logger.info("默认使用本地解释器")
        kind = "local"
    else:
        logger.info("使用远程解释器")
        kind = "remote"

    if kind == "remote":
        interp: E2BCodeInterpreter = await E2BCodeInterpreter.create(
            task_id=task_id,
            work_dir=work_dir,
            notebook_serializer=notebook_serializer,
        )
        await interp.initialize(timeout=timeout)
        return interp
    elif kind == "local":
        interp: LocalCodeInterpreter = LocalCodeInterpreter(
            task_id=task_id,
            work_dir=work_dir,
            notebook_serializer=notebook_serializer,
        )
        await interp.initialize()
        return interp
    else:
        raise ValueError(f"未知 interpreter 类型：{kind}")


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tools\json_fixer.py 的内容:
================================================================================
# app/tools/json_fixer.py

from __future__ import annotations
import json
import re
from typing import Optional, Tuple, Any, TYPE_CHECKING

from app.tools.text_sanitizer import TextSanitizer as TS

# 只有在类型检查时才导入 LLM，避免运行时循环导入
if TYPE_CHECKING:
    from app.core.llm.llm import LLM  # pragma: no cover

JSON_FIXER_SYSTEM_PROMPT = (
    "你是严格的 JSON 修复器。\n"
    "要求：\n"
    "1) 仅输出一个 JSON 对象，不能包含解释或额外文本；\n"
    "2) 保证是合法 JSON（双引号、转义符正确），能被 Python json.loads 解析；\n"
    "3) 类型必须是对象（dict），不要数组或多对象。"
)


class JsonFixer:
    """提取 + 修复 + 解析。一旦失败可用 LLM 重建，再做本地兜底。"""

    @staticmethod
    def _escape_raw_newlines_in_json_strings(s: str) -> str:
        """
        仅把 JSON **字符串字面量内部**的真实换行('\n')和回车('\r')替换为 '\\n'。
        不影响字符串外部的换行（JSON 语法允许作为空白）。
        """
        out = []
        in_str = False
        esc = False
        for ch in s:
            if in_str:
                if esc:
                    # 处理「反斜杠 + 真实换行」为 '\\n'
                    if ch == "\n" or ch == "\r":
                        out.append("\\n")
                    else:
                        out.append(ch)
                    esc = False
                else:
                    if ch == "\\":
                        out.append(ch)
                        esc = True
                    elif ch == '"':
                        out.append(ch)
                        in_str = False
                    elif ch == "\n" or ch == "\r":
                        out.append("\\n")
                    else:
                        out.append(ch)
            else:
                out.append(ch)
                if ch == '"':
                    in_str = True
        return "".join(out)

    @staticmethod
    def _force_double_backslashes_in_strings(s: str) -> str:
        r"""
        兜底策略：在 JSON **字符串字面量内部**，把“单个反斜杠”强制双写成 '\\\\'，
        但**保留**以下合法 JSON 转义不再重复转义：
            \"  \\  \/  \b  \f  \n  \r  \t  \uXXXX
        其余如 \left \right \text \quad \( \) \- 等等，统统变成 \\left \\right ...
        仅在前置修复与 LLM 修复都失败时才采用。
        """
        out = []
        in_str = False
        i = 0
        L = len(s)
        while i < L:
            ch = s[i]
            if not in_str:
                out.append(ch)
                if ch == '"':
                    in_str = True
                i += 1
                continue

            # in_str == True
            if ch == '"':
                out.append(ch)
                in_str = False
                i += 1
                continue

            if ch != "\\":
                out.append(ch)
                i += 1
                continue

            # ch == "\\"
            if i + 1 >= L:
                # 字符串末尾的孤立反斜杠 -> 双写避免非法
                out.append("\\\\")
                i += 1
                continue

            nxt = s[i + 1]

            # 情况 A：双反斜杠开头（表示字面一个反斜杠）
            if nxt == "\\":
                # 保留现状（它已经代表字面一个反斜杠）
                out.append("\\\\")
                i += 2
                continue

            # 情况 B：合法 JSON 转义：\" \/ \b \f \n \r \t
            if nxt in ['"', "/", "b", "f", "n", "r", "t"]:
                out.append("\\" + nxt)
                i += 2
                continue

            # 情况 C：\uXXXX（共 6 个字符）
            if nxt == "u" and i + 5 < L and re.match(r"u[0-9a-fA-F]{4}", s[i + 1 : i + 6]):
                out.append(s[i : i + 6])
                i += 6
                continue

            # 其它情况：一律强制双写，避免 Invalid \escape
            out.append("\\\\")
            out.append(nxt)
            i += 2

        return "".join(out)

    @staticmethod
    def _try_parse(json_str: str) -> Optional[Any]:
        try:
            return json.loads(json_str)
        except Exception:
            return None

    @staticmethod
    def _fallback_regex(json_str: str) -> Optional[Any]:
        """
        宽松兜底（顺序重要）：
        1) 去尾逗号（,} / ,]）
        2) 单引号 -> 双引号
        3) **字符串内部**把所有单反斜杠强制双写（保留合法转义不重复）
        """
        safe = re.sub(r",\s*}", "}", json_str)
        safe = re.sub(r",\s*]", "]", safe)
        safe = safe.replace("'", '"')
        safe = JsonFixer._force_double_backslashes_in_strings(safe)
        try:
            return json.loads(safe)
        except Exception:
            return None

    @classmethod
    def _local_first_pass(cls, raw: str) -> Tuple[Optional[str], str]:
        """
        本地第一阶段：清洗围栏/控制字符 → 提取首个 JSON → 修复非法转义
                   → 处理“行尾反斜杠+换行” → 处理字符串内裸换行
        返回 (json_str 或 None, 阶段标签)
        """
        if not raw:
            return None, "empty"

        # 1) 清理围栏与控制字符（保留换行/制表）
        content = TS.strip_fences_outer_or_all(TS.clean_control_chars(raw, keep_whitespace=True))

        # 2) 提取首个配平 JSON（栈法）
        json_str = TS.extract_first_json_block(content, strip_fences_first=False)
        if not json_str:
            return None, "not_found"

        # 3) 修复 JSON 中的非法反斜杠转义（如 LaTeX 的 \text 之类）
        if hasattr(TS, "fix_invalid_json_escapes"):
            json_str = TS.fix_invalid_json_escapes(json_str)
        else:
            json_str = re.sub(r'\\(?!["\\/bfnrtu])', r"\\\\", json_str)

        # 3.5) 额外兜底：把“反斜杠+行末换行”直接规范为 \\n，避免行尾反斜杠破坏字符串边界
        json_str = re.sub(r"\\\r?\n", r"\\n", json_str)

        # 4) 把“字符串内部”的真实换行/回车转为 \\n，避免 json.loads 因为裸换行失败
        json_str = cls._escape_raw_newlines_in_json_strings(json_str)

        return json_str, "prepared"

    @classmethod
    async def fix_and_parse(
        cls,
        raw: str,
        llm: Optional["LLM"] = None,
        agent_name: str = "JsonFixer",
    ) -> Tuple[Optional[dict], str]:
        json_str, stage = cls._local_first_pass(raw)
        if not json_str:
            return None, f"fail:{stage}"

        # ① 本地直接解析
        obj = cls._try_parse(json_str)
        if isinstance(obj, dict):
            return obj, "parsed"

        # ② 有 LLM → 让模型按严格约束重建（静默，不发布）
        if llm is not None:
            fix_history = [
                {"role": "system", "content": JSON_FIXER_SYSTEM_PROMPT},
                {"role": "user", "content": json_str},
            ]
            fix_resp = await llm.chat(
                history=fix_history,
                agent_name="JsonFixerInternal",
                sub_title="JsonFixer",
                publish=False,  # 关键：不发布，仅拿返回内容
            )
            fixed_raw = getattr(fix_resp.choices[0].message, "content", "") or ""
            fixed = TS.strip_fences_outer_or_all(fixed_raw)
            fixed_json = TS.extract_first_json_block(fixed, strip_fences_first=False)
            if fixed_json:
                if hasattr(TS, "fix_invalid_json_escapes"):
                    fixed_json = TS.fix_invalid_json_escapes(fixed_json)
                else:
                    fixed_json = re.sub(r'\\(?!["\\/bfnrtu])', r"\\\\", fixed_json)
                fixed_json = re.sub(r"\\\r?\n", r"\\n", fixed_json)
                fixed_json = cls._escape_raw_newlines_in_json_strings(fixed_json)

                obj = cls._try_parse(fixed_json)
                if isinstance(obj, dict):
                    return obj, "llm_fixed"

                obj = cls._fallback_regex(fixed_json)
                if isinstance(obj, dict):
                    return obj, "llm_fallback_parsed"

        # ③ 无 LLM 或仍失败 → 本地宽松兜底
        obj = cls._fallback_regex(json_str)
        if isinstance(obj, dict):
            return obj, "fallback_parsed"

        return None, "error:unparseable"


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tools\local_interpreter.py 的内容:
================================================================================
# app/tools/local_interpreter.py

from app.tools.base_interpreter import BaseCodeInterpreter
from app.tools.notebook_serializer import NotebookSerializer
import jupyter_client
from app.utils.log_util import logger
import os
from app.services.redis_manager import redis_manager
from app.schemas.response import (
    OutputItem,
    ResultModel,
    StdErrModel,
    SystemMessage,
)


class LocalCodeInterpreter(BaseCodeInterpreter):
    def __init__(
        self,
        task_id: str,
        work_dir: str,
        notebook_serializer: NotebookSerializer,
    ):
        super().__init__(task_id, work_dir, notebook_serializer)
        self.km, self.kc = None, None
        self.interrupt_signal = False

    async def initialize(self):
        # 本地内核一般不需异步上传文件，直接切换目录即可
        # 初始化 Jupyter 内核管理器和客户端
        logger.info("初始化本地内核")
        self.km, self.kc = jupyter_client.manager.start_new_kernel(kernel_name="python3")
        self._pre_execute_code()

    def _pre_execute_code(self):
        init_code = (
            f"import os\n"
            f"work_dir = r'{self.work_dir}'\n"
            f"os.makedirs(work_dir, exist_ok=True)\n"
            f"os.chdir(work_dir)\n"
            f"print('当前工作目录:', os.getcwd())\n"
            f"import matplotlib.pyplot as plt\n"
            f"import matplotlib as mpl\n"
            # 更完整的中文字体配置
            f"plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'Microsoft YaHei', 'WenQuanYi Micro Hei', 'PingFang SC', 'Hiragino Sans GB', 'Heiti SC', 'DejaVu Sans', 'sans-serif']\n"
            f"plt.rcParams['axes.unicode_minus'] = False\n"
            f"plt.rcParams['font.family'] = 'sans-serif'\n"
            f"mpl.rcParams['font.size'] = 12\n"
            f"mpl.rcParams['axes.labelsize'] = 12\n"
            f"mpl.rcParams['xtick.labelsize'] = 10\n"
            f"mpl.rcParams['ytick.labelsize'] = 10\n"
            # 设置DPI以获得更清晰的显示
        )
        self.execute_code_(init_code)

    async def execute_code(self, code: str) -> tuple[str, bool, str]:
        logger.info(f"执行代码: {code}")
        #  添加代码到notebook
        self.notebook_serializer.add_code_cell_to_notebook(code)

        text_to_gpt: list[str] = []
        content_to_display: list[OutputItem] | None = []
        error_occurred: bool = False
        error_message: str = ""

        await redis_manager.publish_message(
            self.task_id,
            SystemMessage(content="开始执行代码"),
        )
        # 执行 Python 代码
        logger.info("开始在本地执行代码...")
        execution = self.execute_code_(code)
        logger.info("代码执行完成，开始处理结果...")

        await redis_manager.publish_message(
            self.task_id,
            SystemMessage(content="代码执行完成"),
        )

        for mark, out_str in execution:
            if mark in ("stdout", "execute_result_text", "display_text"):
                text_to_gpt.append(self._truncate_text(f"[{mark}]\n{out_str}"))
                #  添加text到notebook
                content_to_display.append(ResultModel(type="result", format="text", msg=out_str))
                self.notebook_serializer.add_code_cell_output_to_notebook(out_str)

            elif mark in (
                "execute_result_png",
                "execute_result_jpeg",
                "display_png",
                "display_jpeg",
            ):
                # TODO: 视觉模型解释图像
                text_to_gpt.append(f"[{mark} 图片已生成，内容为 base64，未展示]")

                #  添加image到notebook
                if "png" in mark:
                    self.notebook_serializer.add_image_to_notebook(out_str, "image/png")
                    content_to_display.append(ResultModel(type="result", format="png", msg=out_str))
                else:
                    self.notebook_serializer.add_image_to_notebook(out_str, "image/jpeg")
                    content_to_display.append(ResultModel(type="result", format="jpeg", msg=out_str))

            elif mark == "error":
                error_occurred = True
                error_message = self.delete_color_control_char(out_str)
                error_message = self._truncate_text(error_message)
                logger.error(f"执行错误: {error_message}")
                text_to_gpt.append(error_message)
                #  添加error到notebook
                self.notebook_serializer.add_code_cell_error_to_notebook(out_str)
                content_to_display.append(StdErrModel(msg=out_str))

        logger.info(f"text_to_gpt: {text_to_gpt}")
        combined_text = "\n".join(text_to_gpt)

        await self._push_to_websocket(content_to_display)

        return (
            combined_text,
            error_occurred,
            error_message,
        )

    def execute_code_(self, code) -> list[tuple[str, str]]:
        msg_id = self.kc.execute(code)
        logger.info(f"执行代码: {code}")
        # Get the output of the code
        msg_list = []
        while True:
            try:
                iopub_msg = self.kc.get_iopub_msg(timeout=1)
                msg_list.append(iopub_msg)
                if iopub_msg["msg_type"] == "status" and iopub_msg["content"].get("execution_state") == "idle":
                    break
            except:
                if self.interrupt_signal:
                    self.km.interrupt_kernel()
                    self.interrupt_signal = False
                continue

        all_output: list[tuple[str, str]] = []
        for iopub_msg in msg_list:
            if iopub_msg["msg_type"] == "stream":
                if iopub_msg["content"].get("name") == "stdout":
                    output = iopub_msg["content"]["text"]
                    all_output.append(("stdout", output))
            elif iopub_msg["msg_type"] == "execute_result":
                if "data" in iopub_msg["content"]:
                    if "text/plain" in iopub_msg["content"]["data"]:
                        output = iopub_msg["content"]["data"]["text/plain"]
                        all_output.append(("execute_result_text", output))
                    if "text/html" in iopub_msg["content"]["data"]:
                        output = iopub_msg["content"]["data"]["text/html"]
                        all_output.append(("execute_result_html", output))
                    if "image/png" in iopub_msg["content"]["data"]:
                        output = iopub_msg["content"]["data"]["image/png"]
                        all_output.append(("execute_result_png", output))
                    if "image/jpeg" in iopub_msg["content"]["data"]:
                        output = iopub_msg["content"]["data"]["image/jpeg"]
                        all_output.append(("execute_result_jpeg", output))
            elif iopub_msg["msg_type"] == "display_data":
                if "data" in iopub_msg["content"]:
                    if "text/plain" in iopub_msg["content"]["data"]:
                        output = iopub_msg["content"]["data"]["text/plain"]
                        all_output.append(("display_text", output))
                    if "text/html" in iopub_msg["content"]["data"]:
                        output = iopub_msg["content"]["data"]["text/html"]
                        all_output.append(("display_html", output))
                    if "image/png" in iopub_msg["content"]["data"]:
                        output = iopub_msg["content"]["data"]["image/png"]
                        all_output.append(("display_png", output))
                    if "image/jpeg" in iopub_msg["content"]["data"]:
                        output = iopub_msg["content"]["data"]["image/jpeg"]
                        all_output.append(("display_jpeg", output))
            elif iopub_msg["msg_type"] == "error":
                # TODO: 正确返回格式
                if "traceback" in iopub_msg["content"]:
                    output = "\n".join(iopub_msg["content"]["traceback"])
                    cleaned_output = self.delete_color_control_char(output)
                    all_output.append(("error", cleaned_output))
        return all_output

    async def get_created_images(self, section: str) -> list[str]:
        """获取新创建的图片列表"""
        current_images = set()
        files = os.listdir(self.work_dir)
        for file in files:
            if file.endswith((".png", ".jpg", ".jpeg")):
                current_images.add(file)

        # 计算新增的图片
        new_images = current_images - self.last_created_images

        # 更新last_created_images为当前的图片集合
        self.last_created_images = current_images

        logger.info(f"新创建的图片列表: {new_images}")
        return list(new_images)  # 最后转换为list返回

    async def cleanup(self):
        # 关闭内核
        self.kc.shutdown()
        logger.info("关闭内核")
        self.km.shutdown_kernel()

    def send_interrupt_signal(self):
        self.interrupt_signal = True

    def restart_jupyter_kernel(self):
        """Restart the Jupyter kernel and recreate the work directory."""
        self.kc.shutdown()
        self.km, self.kc = jupyter_client.manager.start_new_kernel(kernel_name="python3")
        self.interrupt_signal = False
        self._create_work_dir()

    def _create_work_dir(self):
        """Ensure the working directory exists after a restart."""
        os.makedirs(self.work_dir, exist_ok=True)


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tools\notebook_serializer.py 的内容:
================================================================================
# app/tools/notebook_serializer.py

import nbformat
from nbformat import v4 as nbf
import ansi2html
import os


class NotebookSerializer:
    def __init__(self, work_dir=None, notebook_name="notebook.ipynb"):
        self.nb = nbf.new_notebook()
        self.notebook_path = None
        self.initialized = True
        self.segmentation_output_content = {}  # 保存coder_agent 在 jupyter 中执行的 output 结果内容
        # {
        #     "eda": {
        #     }
        # }
        self.current_segmentation: str = ""

        self.init_notebook(work_dir, notebook_name)

    def init_notebook(self, work_dir=None, notebook_name="notebook.ipynb"):
        """初始化notebook路径

        Args:
            work_dir (str): jupyter工作目录路径
            notebook_name (str): notebook文件名,默认为notebook.ipynb
        """
        if work_dir:
            # 确保使用jupyter工作目录
            base, ext = os.path.splitext(notebook_name)
            if ext.lower() != ".ipynb":
                notebook_name += ".ipynb"

            # 在jupyter工作目录下创建notebook文件
            self.notebook_path = os.path.join(work_dir, notebook_name)

            # if os.path.exists(self.notebook_path):
            #     raise FileExistsError(
            #         f"文件 {self.notebook_path} 已存在。请选择其他文件名。"
            #     )

    def ansi_to_html(self, ansi_text):
        converter = ansi2html.Ansi2HTMLConverter()
        html_text = converter.convert(ansi_text)
        return html_text

    def write_to_notebook(self):
        if self.notebook_path:
            with open(self.notebook_path, "w", encoding="utf-8") as f:
                f.write(nbformat.writes(self.nb))

    def add_code_cell_to_notebook(self, code):
        code_cell = nbf.new_code_cell(source=code)
        self.nb["cells"].append(code_cell)
        self.write_to_notebook()

    def add_code_cell_output_to_notebook(self, output):
        """添加代码单元格输出

        Args:
            output: 代码输出内容
        """
        html_content = self.ansi_to_html(output)
        if self.current_segmentation:
            # 确保键存在
            if self.current_segmentation not in self.segmentation_output_content:
                self.segmentation_output_content[self.current_segmentation] = ""
            self.segmentation_output_content[self.current_segmentation] += html_content

        cell_output = nbf.new_output(output_type="display_data", data={"text/html": html_content})
        self.nb["cells"][-1]["outputs"].append(cell_output)
        self.write_to_notebook()

    def add_code_cell_error_to_notebook(self, error):
        nbf_error_output = nbf.new_output(
            output_type="error",
            ename="Error",
            evalue="Error message",
            traceback=[error],
        )
        self.nb["cells"][-1]["outputs"].append(nbf_error_output)
        self.write_to_notebook()

    def add_image_to_notebook(self, image, mime_type):
        image_output = nbf.new_output(output_type="display_data", data={mime_type: image})
        self.nb["cells"][-1]["outputs"].append(image_output)
        self.write_to_notebook()

    def add_markdown_to_notebook(self, content, title=None):
        if title:
            content = "##### " + title + ":\n" + content
        markdown_cell = nbf.new_markdown_cell(content)
        self.nb["cells"].append(markdown_cell)
        self.write_to_notebook()

    def add_markdown_segmentation_to_notebook(self, content, segmentation):
        """添加markdown分段并初始化对应的output内容存储

        Args:
            content: markdown内容
            segmentation: 分段名称
        """
        self.current_segmentation = segmentation
        # 初始化该分段的output内容
        self.segmentation_output_content[segmentation] = ""
        self.add_markdown_to_notebook(content, segmentation)

    def get_notebook_output_content(self, segmentation):
        return self.segmentation_output_content[segmentation]


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tools\openalex_scholar.py 的内容:
================================================================================
# app/tools/openalex_scholar.py

import requests
from typing import List, Dict, Any, Tuple
from app.services.redis_manager import redis_manager
from app.schemas.response import ScholarMessage


class OpenAlexScholar:
    def __init__(self, task_id: str, email: str = None):
        """Initialize OpenAlex client.

        Args:
            email: Optional email for better API service
        """
        self.base_url = "https://api.openalex.org"
        self.email = email
        self.task_id = task_id

    def _get_request_url(self, endpoint: str) -> str:
        """Construct request URL with email parameter if provided."""
        if endpoint.startswith("/"):
            endpoint = endpoint[1:]
        return f"{self.base_url}/{endpoint}"

    def _get_abstract_from_index(self, abstract_inverted_index: Dict) -> str:
        """从abstract_inverted_index中重建摘要文本"""
        if not abstract_inverted_index:
            return ""

        max_position = 0
        for positions in abstract_inverted_index.values():
            if positions and max(positions) > max_position:
                max_position = max(positions)

        words = [""] * (max_position + 1)

        for word, positions in abstract_inverted_index.items():
            for position in positions:
                words[position] = word

        return " ".join(words).strip()

    async def search_papers(self, query: str, limit: int = 8) -> List[Dict[str, Any]]:
        """Search for papers using OpenAlex API."""
        base_url = self._get_request_url("works")
        params = {
            "search": query,
            "per_page": limit,
            "select": "id,title,display_name,authorships,cited_by_count,doi,publication_year,biblio,abstract_inverted_index,host_venue,primary_location",
        }

        if self.email:
            params["mailto"] = self.email
        else:
            raise ValueError("配置OpenAlex邮箱获取访问文献权利")

        headers = {"User-Agent": f"OpenAlexScholar/1.0 (mailto:{self.email})" if self.email else "OpenAlexScholar/1.0"}

        try:
            print(f"请求 URL: {base_url} 参数: {params}")
            response = requests.get(base_url, params=params, headers=headers)
            print(f"响应状态: {response.status_code}")
            response.raise_for_status()
            results = response.json()
        except requests.exceptions.HTTPError as e:
            print(f"HTTP 错误: {e}")
            if response.status_code == 403:
                print("提示: 403错误通常意味着您需要提供有效的邮箱地址或者遵循礼貌池（polite pool）规则")
            if hasattr(response, "text"):
                print(f"响应内容: {response.text}")
            raise
        except Exception as e:
            print(f"请求出错: {e}")
            raise

        papers = []
        paper_titles = []
        for work in results.get("results", []):
            abstract = self._get_abstract_from_index(work.get("abstract_inverted_index", {}))

            authors = []
            for authorship in work.get("authorships", []):
                author = authorship.get("author", {})
                if author:
                    author_info = {
                        "name": author.get("display_name"),
                        "position": authorship.get("author_position"),
                        "institution": (
                            authorship.get("institutions", [{}])[0].get("display_name")
                            if authorship.get("institutions")
                            else None
                        ),
                    }
                    authors.append(author_info)

            biblio = work.get("biblio", {})
            citation = {
                "volume": biblio.get("volume"),
                "issue": biblio.get("issue"),
                "first_page": biblio.get("first_page"),
                "last_page": biblio.get("last_page"),
            }

            paper = {
                "title": work.get("display_name") or work.get("title", ""),
                "abstract": abstract,
                "authors": authors,
                "citations_count": work.get("cited_by_count"),
                "doi": work.get("doi"),
                "publication_year": work.get("publication_year"),
                "citation_info": citation,
                "host_venue": work.get("host_venue"),
                "primary_location": work.get("primary_location"),
                "citation_format": self._format_citation(work),
            }
            papers.append(paper)
            paper_titles.append(paper["title"])

        await redis_manager.publish_message(
            self.task_id,
            ScholarMessage(input={"query": query}, output=paper_titles),
        )
        return papers

    def papers_to_str(self, papers: List[Dict[str, Any]]) -> str:
        """将文献列表转换为字符串"""
        result = ""
        for paper in papers:
            result += "\n" + "=" * 100
            result += f"\n标题: {paper['title']}"
            result += f"\n摘要: {paper['abstract']}"
            result += "\n作者:"
            for author in paper["authors"]:
                result += f"- {author['name']}"
            result += f"\n引用次数: {paper['citations_count']}"
            result += f"\n发表年份: {paper['publication_year']}"
            result += f"\n引用格式:\n{paper['citation_format']}"
            result += "=" * 100
        return result

    def _format_citation(self, work: Dict[str, Any]) -> str:
        """Format citation in a readable format."""
        authors = [
            authorship.get("author", {}).get("display_name")
            for authorship in work.get("authorships", [])
            if authorship.get("author")
        ]

        if len(authors) > 3:
            authors_str = f"{authors[0]} et al."
        else:
            authors_str = ", ".join(authors)

        title = work.get("display_name") or work.get("title", "")
        year = work.get("publication_year", "")
        doi = work.get("doi", "")

        citation = f"{authors_str} ({year}). {title}."
        if doi:
            citation += f" DOI: {doi}"
        return citation


# ========= 源头就生成 footnote tuple =========
def paper_to_footnote_tuple(paper: Dict[str, Any]) -> Tuple[str, str]:
    """将论文转成 (citation_text, url)，保证 WriterResponse 类型安全"""
    title = str(paper.get("title") or "")
    year = str(paper.get("publication_year") or "")

    # 简化作者展示
    authors = paper.get("authors") or []
    author_names = [a.get("name") for a in authors if isinstance(a, dict) and a.get("name")]
    authors_str = ""
    if author_names:
        authors_str = "; ".join(author_names[:3])
        if len(author_names) > 3:
            authors_str += " et al."

    venue = ""
    host_venue = paper.get("host_venue")
    if isinstance(host_venue, dict):
        venue = host_venue.get("display_name") or ""

    citation_text = f"{title}"
    if authors_str:
        citation_text += f" — {authors_str}"
    if year:
        citation_text += f" ({year})"
    if venue:
        citation_text += f", {venue}"

    url = ""
    doi = paper.get("doi")
    if doi:
        url = f"https://doi.org/{doi.split('doi.org/')[-1]}"
    else:
        loc = paper.get("primary_location") or {}
        if isinstance(loc, dict):
            url = loc.get("landing_page_url") or loc.get("pdf_url") or ""
    return citation_text.strip(), url.strip()


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tools\png_paths.py 的内容:
================================================================================
# app/tools/png_paths.py

import os
from pathlib import Path
from typing import List
from app.utils.common_utils import get_work_dir  # 用它拿到 work_dir

KEEP_FOLDERS = ["eda", "sensitivity_analysis"]


def collect_png_relative_paths(startpath: str, only_figures: bool = True) -> List[str]:
    """
    收集 .png 的相对路径（仅保留 eda、sensitivity_analysis、quesN）。
    默认仅限 figures 子目录（only_figures=True）。
    """
    png_paths: List[str] = []
    root_path = Path(startpath)

    for root, dirs, files in os.walk(root_path):
        rel_root = Path(root).relative_to(root_path)
        rel_root_str = rel_root.as_posix()

        ok = (
            rel_root_str.startswith("eda")
            or rel_root_str.startswith("sensitivity_analysis")
            or (rel_root_str.startswith("ques") and len(rel_root_str) >= 5 and rel_root_str[4].isdigit())
        )
        if not ok:
            continue

        if only_figures and "figures" not in rel_root.parts:
            # 只要 figures 子目录里的图（与你 Writer 约定一致）
            continue

        for f in files:
            if f.lower().endswith(".png"):
                rel_path = (rel_root / f).as_posix()  # 始终用 /
                png_paths.append(rel_path)

    # 排序去重
    return sorted(set(png_paths))


def collect_png_paths_by_task(task_id: str, only_figures: bool = True) -> List[str]:
    """给定 task_id，扫描该任务 work_dir 下的 png 相对路径"""
    work_dir = get_work_dir(task_id)  # e.g. project/work_dir/<task_id>
    return collect_png_relative_paths(work_dir, only_figures=only_figures)


================================================================================
E:\repo1\MathModelAgent-python\backend\app\tools\text_sanitizer.py 的内容:
================================================================================
# app/tools/text_sanitizer.py

"""
TextSanitizer: 统一的文本/代码清洗与正则工具
- 控制字符/ANSI 清理
- Markdown 代码栅栏剥离与 JSON 提取
- 代码执行前规范化
- tool.arguments 中兜底抽取 code
- Markdown 图片路径解析与校验

用法示例:
    from app.tools.text_sanitizer import TextSanitizer as TS
    code = TS.normalize_for_execution(raw_text, language="python")
"""

from __future__ import annotations
import json
import re
import textwrap
from typing import List, Tuple


class TextSanitizer:
    # -----------------------
    # 编译好的正则常量（与项目中原先使用的保持语义等价）
    # -----------------------
    # 控制字符清理（严格：去掉 0x00–0x1F 和 DEL；保留/不保留换行/制表可选）
    CLEAN_CTRL_STRICT_RE = re.compile(r"[\x00-\x1F\x7F]")
    # 宽松：保留 \t(\x09), \n(\x0A), \r(\x0D)
    CLEAN_CTRL_RELAXED_RE = re.compile(r"[\x00-\x08\x0B-\x0C\x0E-\x1F\x7F]")

    # ANSI 颜色控制序列（与原 delete_color_control_char 的正则等价）
    ANSI_ESCAPE_RE = re.compile(r"(?:\x9B|\x1B\[)[0-?]*[ -\/]*[@-~]")

    # Markdown 代码栅栏
    # 匹配整段被单个 fence 包裹的情况（优先提取内部）
    CODE_FENCE_OUTER_RE = re.compile(r"^\s*```(?:\s*[^\n`]*)?\s*\n(.*)\n```\s*$", re.S)
    # 匹配文本中所有 fenced blocks（提取内部）
    CODE_FENCE_ALL_RE = re.compile(r"```(?:\s*[^\n`]*)?\n(.*?)```", re.S)

    # REPL/Notebook 提示符
    PY_REPL_PROMPT_RE = re.compile(r"^\s*>>>\s?", re.M)
    NB_IN_PROMPT_RE = re.compile(r"^\s*In\[\d+\]:\s?", re.M)

    # tool.arguments 解析辅助
    # 支持转义字符的 "code": "...." 捕获
    QUOTED_CODE_RE = re.compile(r'"code"\s*:\s*"((?:\\.|[^"\\])*)"', re.S)
    # 单行键值对 style: code: something（忽略大小写，行首）
    CODE_KV_LINE_RE = re.compile(r"^\s*code\s*:\s*([^\n\r]+)", re.I | re.M)

    # 图片路径前缀规则（quesN/figures/）
    QUES_FIG_PREFIX_RE = re.compile(r"^ques\d+/figures/")

    # -----------------------
    # 基础清理
    # -----------------------
    @classmethod
    def clean_control_chars(cls, s: str, keep_whitespace: bool = True) -> str:
        """
        去除会导致解析/展示问题的控制字符。
        keep_whitespace=True 时保留 \t \n \r，False 时与严格模式一致。
        返回空字符串而非 None。
        """
        if s is None:
            return ""
        # 选择松/严格正则
        re_obj = cls.CLEAN_CTRL_RELAXED_RE if keep_whitespace else cls.CLEAN_CTRL_STRICT_RE
        return re_obj.sub("", s)

    @classmethod
    def strip_ansi(cls, s: str) -> str:
        """去除 ANSI 颜色控制序列（escape sequences）"""
        if s is None:
            return ""
        return cls.ANSI_ESCAPE_RE.sub("", s)

    # -----------------------
    # 代码栅栏 / JSON 提取
    # -----------------------
    @classmethod
    def strip_fences_outer_or_all(cls, s: str) -> str:
        """
        更稳健地剥离 Markdown 代码栅栏：
        1) 若整段被单个 fence 包裹，优先去掉外层并返回内部（保留内部原样）；
        2) 否则把文中所有 fence 去掉围栏、保留内部内容（非贪婪匹配）。
        返回去围栏后的字符串（strip 后）。
        """
        if not s:
            return ""
        s = s.strip()
        m = cls.CODE_FENCE_OUTER_RE.match(s)
        if m:
            return m.group(1).strip()
        # 若不是完全包裹情况，尽量把所有 fence 的围栏剥离，保留内部文本
        return cls.CODE_FENCE_ALL_RE.sub(r"\1", s).strip()

    @classmethod
    def extract_first_json_block(cls, s: str, strip_fences_first: bool = True) -> str:
        """
        用“栈法”提取首个配平的 JSON 对象字符串（比简单正则更稳健）。
        """
        if not s:
            return ""
        text = cls.strip_fences_outer_or_all(s) if strip_fences_first else s
        start = text.find("{")
        if start == -1:
            return ""
        stack: List[str] = []
        in_str = False
        esc = False
        for i, ch in enumerate(text[start:], start):
            if in_str:
                if esc:
                    esc = False
                elif ch == "\\":
                    esc = True
                elif ch == '"':
                    in_str = False
            else:
                if ch == '"':
                    in_str = True
                elif ch == "{":
                    stack.append("{")
                elif ch == "}":
                    if stack:
                        stack.pop()
                    if not stack:
                        return text[start : i + 1]
        # 未闭合，返回空（调用方可能决定如何 fallback）
        return ""

    @classmethod
    def fix_invalid_json_escapes(cls, s: str) -> str:
        """
        把 JSON 字符串里所有“非法转义”的单反斜杠补成双反斜杠。
        合法转义仅包括: \", \\, \\/, \b, \f, \n, \r, \t, \\uXXXX
        其它一律加一杠，避免 json.loads 报 Invalid \\escape。
        """
        if not isinstance(s, str) or not s:
            return ""
        return re.sub(r"\\(?![\"\\/bfnrtu])", r"\\\\", s)

    @classmethod
    def normalize_common_glitches(cls, s: str) -> str:
        """
        对常见的小毛病做修复：
        - '"qu es2"' -> '"ques2"'
        - '" ques  3 "' -> '"ques3"'
        - 同时剥离围栏
        """
        if not s:
            return ""
        s = cls.strip_fences_outer_or_all(s)
        # "qu es2" -> "ques2"
        s = re.sub(r'"qu\s+es(\d+)"', r'"ques\1"', s)
        # '" ques  3 "' 或者 '"ques 3"' 等 -> "ques3"
        s = re.sub(r'"\s*ques\s*(\d+)\s*"', r'"ques\1"', s)
        return s.strip()

    # -----------------------
    # 代码执行前规范化（与原项目行为等价）
    # -----------------------
    @classmethod
    def normalize_for_execution(cls, raw: str, language: str = "python") -> str:
        """
        将 raw 文本规范化为可直接执行的多行字符串（以 '\n' 结尾）。
        策略（保守）：
        - 优先抽取 fenced code（如果存在）
        - 规范换行 CRLF/CR -> LF
        - 仅在没有真实换行但存在字面 '\\n' 时保守转换为真实换行
        - 去除常见 REPL/Notebook 提示符（>>> / In[n]:）
        - textwrap.dedent + 去首尾空行，保证以单个换行结尾
        """
        if raw is None:
            return "\n"
        if not isinstance(raw, str):
            raw = str(raw)

        txt = raw

        # 1) 优先提取 fenced code 中的内容
        txt = cls.strip_fences_outer_or_all(txt)

        # 2) 去掉 UTF-8 BOM
        txt = txt.lstrip("\ufeff")

        # 3) 规范行尾：CRLF/CR -> LF
        txt = txt.replace("\r\n", "\n").replace("\r", "\n")

        # 4) 保守处理字面转义的换行/制表
        if "\\n" in txt and "\n" not in txt:
            txt = txt.replace("\\r\\n", "\n").replace("\\n", "\n").replace("\\t", "\t")
        else:
            # 如果文本中既有真实换行也有字面 \r\n，做有限的替换以清理
            if "\\r\\n" in txt:
                txt = txt.replace("\\r\\n", "\n")

        # 5) 去交互式提示符（多行模式）
        txt = cls.PY_REPL_PROMPT_RE.sub("", txt)
        txt = cls.NB_IN_PROMPT_RE.sub("", txt)

        # 6) dedent + 去首尾额外换行，确保以单个 '\n' 结尾
        txt = textwrap.dedent(txt).strip("\n") + "\n"
        return txt

    # --- 在 class TextSanitizer 内新增一个安全解码的小工具 ---
    @classmethod
    def _decode_string_with_json_if_needed(cls, s: str) -> str:
        """
        使用 JSON 解码处理字符串中的转义（\\\" \\\\ \\/ \\b \\f \\n \\r \\t \\uXXXX \\xHH），
        在不破坏中文（非 ASCII）的前提下还原。
        方案说明：
        - 先用 fix_invalid_json_escapes 处理非法单反斜杠，避免 json.loads 报错；
        - 再把处理后的内容包在双引号内交给 json.loads，能正确解析常见转义序列且保留 Unicode。
        - 若解析失败，返回原字符串（保守策略）。
        """
        if not isinstance(s, str) or not s:
            return ""
        s2 = cls.fix_invalid_json_escapes(s)
        try:
            return json.loads(f'"{s2}"')
        except Exception:
            # 解析失败时保守返回原样，避免破坏中文或其他 Unicode 内容
            return s

    # --- 替换原有 extract_code_from_arguments 方法 ---
    @classmethod
    def extract_code_from_arguments(cls, args_raw: str) -> str:
        """
        从 tools.arguments（通常是 LLM 返回的字符串）中尽可能安全地抽取 code 字段。
        逻辑顺序：
        1) 尝试严格的 json.loads（首选，不会破坏 Unicode）；
        2) 宽松匹配 "code": "..." ，根据内容类型采取不同处理策略：
           - 纯 ASCII 且仅含字面转义（\\n/\\t 等）时做轻量替换；
           - 含非 ASCII（如中文）且含转义时使用 JSON 解码恢复转义；
           - 仅含标准转义时同样用 JSON 解码；
        3) 匹配 code: xxx 的单行键值对作为最后兜底；
        4) 若均未命中，返回剥围栏后的原文（保守）。
        """
        stripped = cls.strip_fences_outer_or_all(args_raw or "")

        # 1) 尝试严格 JSON（首选路径，零损伤）
        try:
            obj = json.loads(stripped)
            if isinstance(obj, dict) and "code" in obj:
                val = obj.get("code", "")
                return val if isinstance(val, str) else str(val)
        except Exception:
            pass

        # 2) 宽松 JSON: 匹配 "code": "...."
        m2 = cls.QUOTED_CODE_RE.search(stripped)
        if m2:
            s = m2.group(1)

            # 2.1 纯 ASCII 且明显只是字面转义（无真实换行/制表、含 \n/\r\n/\t）
            #     这种情况只做轻量替换，不做 unicode_escape，避免误伤多字节字符
            if cls.looks_like_literal_escapes(s):
                return s.replace("\\r\\n", "\n").replace("\\n", "\n").replace("\\t", "\t")

            # 2.2 含非 ASCII（可能有中文）且带转义：用 JSON 解码最稳妥
            has_non_ascii = any(ord(ch) > 127 for ch in s)
            has_escapes = bool(re.search(r"\\u[0-9a-fA-F]{4}|\\x[0-9a-fA-F]{2}|\\[\"\\/bfnrt]", s))
            if has_non_ascii and has_escapes:
                return cls._decode_string_with_json_if_needed(s)

            # 2.3 仅有标准转义（即便是 ASCII），也用 JSON 解码统一处理
            if has_escapes:
                return cls._decode_string_with_json_if_needed(s)

            # 2.4 没有任何需要处理的转义，原样返回
            return s

        # 3) 其它兜底：code: xxx 单行键值
        m3 = cls.CODE_KV_LINE_RE.search(stripped)
        if m3:
            return m3.group(1).strip().strip('"').strip("'")

        # 4) 最后兜底：去栅栏后的原文
        return stripped

    # -----------------------
    # Markdown 图片路径解析与校验（支持嵌套括号与 <...> 包裹）
    # -----------------------
    @classmethod
    def extract_markdown_image_paths(cls, text: str) -> List[str]:
        """
        更稳健地解析 Markdown 图片：
        - 解析 '![alt](...)'，支持嵌套括号
        - 处理 <...> 包裹、可选 "title"
        - 返回路径列表，按出现顺序
        """
        if not text:
            return []
        paths: List[str] = []
        i, L = 0, len(text)
        while True:
            start = text.find("![", i)
            if start == -1:
                break
            close_br = text.find("]", start + 2)
            if close_br == -1:
                break
            # 必须紧跟 '(' 才是图片语法
            if close_br + 1 >= L or text[close_br + 1] != "(":
                i = close_br + 1
                continue

            p = close_br + 2
            depth = 0
            end = -1
            # 支持嵌套括号寻找匹配的 ')'
            while p < L:
                ch = text[p]
                if ch == "(":
                    depth += 1
                elif ch == ")":
                    if depth == 0:
                        end = p
                        break
                    else:
                        depth -= 1
                p += 1
            if end == -1:
                break

            raw_inside = text[close_br + 2 : end].strip()
            path = raw_inside
            # 处理 <...> 包裹
            if path.startswith("<") and path.endswith(">"):
                path = path[1:-1].strip()
            else:
                # 去掉可选 title (例如: path "title")
                qpos = path.find('"')
                if qpos == -1:
                    qpos = path.find("'")
                if qpos != -1:
                    candidate = path[:qpos].strip()
                    if candidate:
                        path = candidate
            # 去两端引号和空白
            path = path.strip().strip('"').strip("'").strip()

            if path:
                paths.append(path)

            i = end + 1

        return paths

    @classmethod
    def normalize_relpath(cls, p: str) -> str:
        """规范化相对路径（去掉开头 ./ 或 /，去首尾空白）"""
        if not p:
            return ""
        p = p.strip()
        if p.startswith("./"):
            p = p[2:]
        if p.startswith("/"):
            p = p[1:]
        return p

    @classmethod
    def is_allowed_image_prefix(
        cls,
        p: str,
        allowed_prefixes: Tuple[str, ...] = (
            "eda/figures/",
            "sensitivity_analysis/figures/",
        ),
        allow_ques_prefix: bool = True,
    ) -> bool:
        """
        路径前缀校验：允许固定白名单前缀；可选允许 quesN/figures/
        """
        if not p:
            return False
        p = cls.normalize_relpath(p)
        if any(p.startswith(pref) for pref in allowed_prefixes):
            return True
        return bool(cls.QUES_FIG_PREFIX_RE.match(p)) if allow_ques_prefix else False

    # -----------------------
    # 其它小工具
    # -----------------------
    @staticmethod
    def looks_like_literal_escapes(s: str) -> bool:
        """
        仅当字符串是 ASCII 且包含典型字面转义（\\n/\\r\\n/\\t），且没有真实换行/制表时返回 True。
        保证不对含中文等多字节字符的字符串返回 True（避免误解码）。
        """
        if not isinstance(s, str) or not s:
            return False
        try:
            s.encode("ascii")
        except UnicodeEncodeError:
            return False
        has_literal = ("\\n" in s) or ("\\r\\n" in s) or ("\\t" in s)
        no_real = ("\n" not in s) and ("\r\n" not in s) and ("\t" not in s)
        # 代码栅栏中不应该进行反解
        return has_literal and no_real and ("```" not in s)


================================================================================
E:\repo1\MathModelAgent-python\backend\app\utils\cli.py 的内容:
================================================================================
# app/utils/cli.py

from textwrap import dedent


def center_cli_str(text: str, width: int | None = None):
    import shutil

    width = width or shutil.get_terminal_size().columns
    lines = text.split("\n")
    max_line_len = max(len(line) for line in lines)
    return "\n".join((line + " " * (max_line_len - len(line))).center(width) for line in lines)


def get_ascii_banner(center: bool = True) -> str:
    text = dedent(
        r"""
        ===============================================================================
         __  __       _   _     __  __           _      _                          _   
        |  \/  |     | | | |   |  \/  |         | |    | |   /\                   | |  
        | \  / | __ _| |_| |__ | \  / | ___   __| | ___| |  /  \   __ _  ___ _ __ | |_ 
        | |\/| |/ _` | __| '_ \| |\/| |/ _ \ / _` |/ _ \ | / /\ \ / _` |/ _ \ '_ \| __|
        | |  | | (_| | |_| | | | |  | | (_) | (_| |  __/ |/ ____ \ (_| |  __/ | | | |_ 
        |_|  |_|\__,_|\__|_| |_|_|  |_|\___/ \__,_|\___|_/_/    \_\__, |\___|_| |_|\__|
                                                                    __/ |               
                                                                |___/                
        ===============================================================================
        """,
    ).strip()
    if center:
        return center_cli_str(text)
    else:
        return text


================================================================================
E:\repo1\MathModelAgent-python\backend\app\utils\common_utils.py 的内容:
================================================================================
# app/utils/common_utils.py

import os
import datetime
import hashlib
import tomllib
from app.schemas.enums import CompTemplate
from app.utils.log_util import logger
import re
import pypandoc
from app.config.setting import settings
from icecream import ic


def create_task_id() -> str:
    """生成任务ID"""
    # 生成时间戳和随机hash
    timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    random_hash = hashlib.md5(str(datetime.datetime.now()).encode()).hexdigest()[:8]
    return f"{timestamp}-{random_hash}"


def create_work_dir(task_id: str) -> str:
    # 设置主工作目录和子目录
    work_dir = os.path.join("project", "work_dir", task_id)

    try:
        # 创建目录，如果目录已存在也不会报错
        os.makedirs(work_dir, exist_ok=True)
        return work_dir
    except Exception as e:
        # 捕获并记录创建目录时的异常
        logger.error(f"创建工作目录失败: {str(e)}")
        raise


def get_work_dir(task_id: str) -> str:
    work_dir = os.path.join("project", "work_dir", task_id)
    if os.path.exists(work_dir):
        return work_dir
    else:
        logger.error(f"工作目录不存在: {work_dir}")
        raise FileNotFoundError(f"工作目录不存在: {work_dir}")


#  TODO: 是不是应该将 Prompt 写成一个 class
def get_config_template(comp_template: CompTemplate = CompTemplate.CHINA) -> dict:
    if comp_template == CompTemplate.CHINA:
        return load_toml(os.path.join("app", "config", "md_template.toml"))


def load_toml(path: str) -> dict:
    with open(path, "rb") as f:
        return tomllib.load(f)


def load_markdown(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()


def get_current_files(folder_path: str, type: str = "all") -> list[str]:
    files = os.listdir(folder_path)
    if type == "all":
        return files
    elif type == "md":
        return [file for file in files if file.endswith(".md")]
    elif type == "ipynb":
        return [file for file in files if file.endswith(".ipynb")]
    elif type == "data":
        return [file for file in files if file.endswith(".xlsx") or file.endswith(".csv")]
    elif type == "image":
        return [file for file in files if file.endswith(".png") or file.endswith(".jpg")]


# 判断content是否包含图片 xx.png,对其处理为    ![filename](http://localhost:8000/static/20250428-200915-ebc154d4/filename.jpg)
def transform_link(task_id: str, content: str):
    content = re.sub(
        r"!\[(.*?)\]\((.*?\.(?:png|jpg|jpeg|gif|bmp|webp))\)",
        lambda match: f"![{match.group(1)}]({settings.SERVER_HOST}/static/{task_id}/{match.group(2)})",
        content,
    )
    return content


# TODO: fix 公式显示
def md_2_docx(task_id: str):
    work_dir = get_work_dir(task_id)
    md_path = os.path.join(work_dir, "res.md")
    docx_path = os.path.join(work_dir, "res.docx")

    extra_args = [
        "--resource-path",
        str(work_dir),
        "--mathml",  # MathML 格式公式
        "--standalone",
    ]

    pypandoc.convert_file(
        source_file=md_path,
        to="docx",
        outputfile=docx_path,
        format="markdown+tex_math_dollars",
        extra_args=extra_args,
    )
    print(f"转换完成: {docx_path}")
    logger.info(f"转换完成: {docx_path}")


def split_footnotes(text: str) -> tuple[str, list[tuple[str, str]]]:
    main_text = re.sub(r"\n\[\^\d+\]:.*?(?=\n\[\^|\n\n|\Z)", "", text, flags=re.DOTALL).strip()

    # 匹配脚注定义
    footnotes = re.findall(r"\[\^(\d+)\]:\s*(.+?)(?=\n\[\^|\n\n|\Z)", text, re.DOTALL)
    logger.info(f"main_text:{main_text} \n footnotes:{footnotes}")
    return main_text, footnotes


================================================================================
E:\repo1\MathModelAgent-python\backend\app\utils\data_recorder.py 的内容:
================================================================================
# app/utils/data_recorder.py

import json
import os
from app.utils.log_util import logger
from typing import Any, Dict


# TODO: 记录数据
# data analysis : save all data and result
# agent-histroy, token usgae, , cost , workflow cost , res
class DataRecorder:
    def __init__(self, log_work_dir: str = ""):
        self.total_cost = 0.0
        self.agents_chat_history = {}
        # {"agent_name": [{}, {}, ...]
        #
        # }
        self.chat_completion = {}
        # {"agent_name": [ChatCompletion, ChatCompletion, ...]
        #
        # }
        self.log_work_dir = log_work_dir
        self.token_usage = {}

        self.initialized = True

    def print_summary(self):
        """打印统计摘要"""
        logger.info("\n=== Token Usage and Cost Summary ===")

        # 创建表格数据
        headers = ["Agent", "Chats", "Prompt", "Completion", "Total", "Cost ($)"]
        rows = []

        for agent_name, usage in self.token_usage.items():
            rows.append(
                [
                    agent_name,
                    usage["chat_count"],
                    usage["prompt_tokens"],
                    usage["completion_tokens"],
                    usage["total_tokens"],
                    f"{usage['cost']:.4f}",
                ]
            )

        # 添加总计行
        total_chats = sum(usage["chat_count"] for usage in self.token_usage.values())
        total_prompt = sum(usage["prompt_tokens"] for usage in self.token_usage.values())
        total_completion = sum(usage["completion_tokens"] for usage in self.token_usage.values())
        total_tokens = sum(usage["total_tokens"] for usage in self.token_usage.values())

        rows.append(
            [
                "TOTAL",
                total_chats,
                total_prompt,
                total_completion,
                total_tokens,
                f"{self.total_cost:.4f}",
            ]
        )

        # 使用 RichPrinter 打印表格
        from utils.RichPrinter import RichPrinter

        RichPrinter.table(
            headers=headers,
            rows=rows,
            title="Token Usage and Cost Summary",
            column_styles=["cyan", "magenta", "blue", "blue", "blue", "green"],
        )

    def write_to_json(self, to_save: dict, file_name: str):
        if self.log_work_dir:
            json_path = os.path.join(self.log_work_dir, file_name)
            try:
                with open(json_path, "w", encoding="utf-8") as f:
                    json.dump(to_save, f, ensure_ascii=False, indent=4)
            except Exception as e:
                logger.error(f"写入json文件失败: {e}")

    def append_chat_history(self, msg: dict, agent_name: str) -> None:
        """添加聊天历史记录"""
        if agent_name not in self.agents_chat_history:
            self.agents_chat_history[agent_name] = []
        self.agents_chat_history[agent_name].append(msg)
        self.write_to_json(self.agents_chat_history, "chat_history.json")

    def chat_completion_to_dict(self, completion: Any) -> Dict:
        """将 ChatCompletion 对象转换为可序列化的字典"""
        return {
            "id": completion.id,
            "choices": [
                {
                    "index": choice.index,
                    "message": {
                        "role": choice.message.role,
                        "content": choice.message.content,
                        "tool_calls": (
                            [
                                {
                                    "id": tool_call.id,
                                    "type": tool_call.type,
                                    "function": {
                                        "name": tool_call.function.name,
                                        "arguments": tool_call.function.arguments,
                                    },
                                }
                                for tool_call in (choice.message.tool_calls or [])
                            ]
                            if hasattr(choice.message, "tool_calls")
                            else None
                        ),
                    },
                    "finish_reason": choice.finish_reason,
                }
                for choice in completion.choices
            ],
            "created": completion.created,
            "model": completion.model,
            "usage": (
                {
                    "completion_tokens": completion.usage.completion_tokens,
                    "prompt_tokens": completion.usage.prompt_tokens,
                    "total_tokens": completion.usage.total_tokens,
                }
                if hasattr(completion, "usage")
                else None
            ),
            "system_fingerprint": completion.system_fingerprint if hasattr(completion, "system_fingerprint") else None,
        }

    def append_chat_completion(self, completion: Any, agent_name: str) -> None:
        """添加聊天完成记录"""
        if agent_name not in self.chat_completion:
            self.chat_completion[agent_name] = []

        # 将 ChatCompletion 对象转换为可序列化的字典
        completion_dict = self.chat_completion_to_dict(completion)
        self.chat_completion[agent_name].append(completion_dict)

        # 更新 token 使用统计
        self.update_token_usage(completion, agent_name)

        # 写入 JSON 文件
        self.write_to_json(self.chat_completion, "chat_completion.json")

    def update_token_usage(self, completion: Any, agent_name: str) -> None:
        """更新 token 使用统计和费用
        Args:
            completion: ChatCompletion 对象
            agent_name: 代理名称
        """
        if not hasattr(completion, "usage"):
            return

        if agent_name not in self.token_usage:
            self.token_usage[agent_name] = {
                "completion_tokens": 0,
                "prompt_tokens": 0,
                "total_tokens": 0,
                "chat_count": 0,
                "cost": 0.0,  # 添加费用字段
            }

        usage = completion.usage
        model = completion.model

        # 更新 token 统计
        self.token_usage[agent_name]["completion_tokens"] += usage.completion_tokens
        self.token_usage[agent_name]["prompt_tokens"] += usage.prompt_tokens
        self.token_usage[agent_name]["total_tokens"] += usage.total_tokens
        self.token_usage[agent_name]["chat_count"] += 1

        # 计算本次请求的费用
        cost = self.calculate_cost(model, usage.prompt_tokens, usage.completion_tokens)
        self.token_usage[agent_name]["cost"] += cost
        self.total_cost += cost  # 更新总费用

        # 写入 JSON 文件
        self.write_to_json(self.token_usage, "token_usage.json")

    def calculate_cost(self, model: str, prompt_tokens: int, completion_tokens: int) -> float:
        """计算API调用费用
        Args:
            model: 模型名称
            prompt_tokens: 输入token数
            completion_tokens: 输出token数
        Returns:
            float: 费用（rmb）
        """
        # 定义模型价格（每1000个token的价格，单位：rmb）
        model_prices = {
            "gpt-4-turbo-preview": {"prompt": 0.01, "completion": 0.03},
            "gpt-4": {"prompt": 0.03, "completion": 0.06},
            "gpt-3.5-turbo": {"prompt": 0.0005, "completion": 0.0015},
            "qwen-max-latest": {"prompt": 0.0024, "completion": 0.0096},  # 示例价格
        }

        # 获取模型价格，如果模型不在列表中使用默认价格
        model_price = model_prices.get(
            model,
            {"prompt": 0.0001, "completion": 0.0001},  # 默认价格
        )

        # 计算费用（将token数转换为千分比）
        prompt_cost = (prompt_tokens / 1000.0) * model_price["prompt"]
        completion_cost = (completion_tokens / 1000.0) * model_price["completion"]

        return prompt_cost + completion_cost


================================================================================
E:\repo1\MathModelAgent-python\backend\app\utils\log_util.py 的内容:
================================================================================
# app/utils/log_util.py

import os
import sys
import time
from loguru import logger as _logger


class LoggerInitializer:
    def __init__(self):
        self.log_path = os.path.join(os.getcwd(), "logs")
        self.__ensure_log_directory_exists()
        self.log_path_error = os.path.join(self.log_path, f"{time.strftime('%Y-%m-%d')}_error.log")

    def __ensure_log_directory_exists(self):
        """
        确保日志目录存在，如果不存在则创建
        """
        if not os.path.exists(self.log_path):
            os.mkdir(self.log_path)

    @staticmethod
    def __filter(log: dict):
        """
        自定义日志过滤器，添加trace_id
        """
        return log

    def init_log(self):
        """
        初始化日志配置
        """
        # 自定义日志格式
        format_str = (
            "<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | "
            "<level>{level: <8}</level> | "
            "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - "
            "<level>{message}</level>"
        )
        _logger.remove()
        # 移除后重新添加sys.stderr, 目的: 控制台输出与文件日志内容和结构一致
        _logger.add(sys.stderr, filter=self.__filter, format=format_str, enqueue=False)
        _logger.add(
            self.log_path_error,
            filter=self.__filter,
            format=format_str,
            rotation="50MB",
            encoding="utf-8",
            enqueue=False,
            compression="zip",
        )

        return _logger


# 初始化日志处理器
log_initializer = LoggerInitializer()
logger = log_initializer.init_log()


================================================================================
E:\repo1\MathModelAgent-python\backend\app\utils\RichPrinter.py 的内容:
================================================================================
# app/utils/RichPrinter.py

from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.text import Text
from typing import Optional, List, Any, Dict
from rich import print as rprint
from app.utils.log_util import logger


class RichPrinter:
    # 类属性：全局样式配置
    _styles = {
        "success": {"emoji": "✅", "color": "green", "prefix": "成功"},
        "error": {"emoji": "❌", "color": "red", "prefix": "错误"},
        "warning": {"emoji": "⚠️", "color": "yellow", "prefix": "警告"},
        "info": {"emoji": "ℹ️", "color": "blue", "prefix": "信息"},
        "debug": {"emoji": "🐞", "color": "magenta", "prefix": "调试"},
    }

    # 共享的 Console 实例（线程安全）
    _console = Console()

    @classmethod
    def _format_message(
        cls,
        message: str,
        style_type: str,
        color: Optional[str] = None,
        emoji: Optional[str] = None,
        prefix: Optional[str] = None,
    ) -> Text:
        """格式化消息为统一样式"""
        style = cls._styles.get(style_type, {})
        emoji = emoji or style.get("emoji", "")
        color = color or style.get("color", "white")
        prefix = prefix or style.get("prefix", "")

        formatted = Text()
        if emoji:
            formatted.append(f"{emoji} ", style="bold")
        if prefix:
            formatted.append(f"{prefix}: ", style=f"bold {color}")
        formatted.append(message, style=color)
        return formatted

    @classmethod
    def success(cls, message: str, **kwargs):
        cls._print_panel(message, style_type="success", **kwargs)

    @classmethod
    def error(cls, message: str, **kwargs):
        cls._print_panel(message, style_type="error", **kwargs)

    @classmethod
    def warning(cls, message: str, **kwargs):
        cls._print_panel(message, style_type="warning", **kwargs)

    @staticmethod
    def print_agent_msg(message: str, agent_name: str):
        logger.info(f"{agent_name}: {message}")
        if agent_name == "CoderAgent":
            rprint(f"[bold purple on green]{agent_name}[/bold purple on green]: {message}")
        elif agent_name == "WriterAgent":
            rprint(f"[bold purple on yellow]{agent_name}[/bold purple on yellow]: {message}")
        elif agent_name == "test_agent":
            rprint(f"[bold white on blue]{agent_name}[/bold white on blue]: {message}")
        else:
            rprint(f"[bold white]{agent_name}[/bold white]: {message}")

    @classmethod
    def _print_panel(
        cls,
        message: str,
        style_type: str,
        title: Optional[str] = None,
        color: Optional[str] = None,
        emoji: Optional[str] = None,
        prefix: Optional[str] = None,
        panel_kwargs: Optional[Dict] = None,
    ):
        """通用带面板样式的打印方法"""
        text = cls._format_message(message, style_type, color, emoji, prefix)
        default_panel_args = {
            "title": title or style_type.upper(),
            "border_style": color or cls._styles[style_type]["color"],
            "padding": (1, 4),
        }
        panel_args = {**default_panel_args, **(panel_kwargs or {})}
        cls._console.print(Panel.fit(text, **panel_args))

    @classmethod
    def table(
        cls,
        headers: List[str],
        rows: List[List[Any]],
        title: str = "数据表格",
        column_styles: Optional[List[str]] = None,
    ):
        """快速打印表格"""
        table = Table(title=title, show_header=True, header_style="bold cyan")
        column_styles = column_styles or ["magenta"] * len(headers)

        for header, style in zip(headers, column_styles):
            table.add_column(header, style=style)

        for row in rows:
            table.add_row(*[str(item) for item in row])

        cls._console.print(table)

    @classmethod
    def workflow_start(cls):
        """打印工作流开始信息"""
        cls._console.print()  # 添加前置换行
        formatted = Text()
        formatted.append("🚀 ", style="bold")
        formatted.append("开始执行工作流", style="bold blue")
        cls._console.print(Panel.fit(formatted, border_style="blue", padding=(1, 4)))
        logger.info("\n=======================开始执行工作流=======================\n")

    @classmethod
    def workflow_end(cls):
        """打印工作流结束信息"""
        cls._console.print()  # 添加前置换行
        formatted = Text()
        formatted.append("✨ ", style="bold")
        formatted.append("工作流执行完成", style="bold green")
        cls._console.print(Panel.fit(formatted, border_style="green", padding=(1, 4)))
        logger.info("\n=======================工作流执行完成=======================\n")

    @classmethod
    def agent_start(cls, agent_name: str):
        """打印 Agent 开始信息"""
        cls._console.print()  # 添加前置换行
        formatted = Text()
        formatted.append("🤖 ", style="bold")
        formatted.append(f"Agent: {agent_name} ", style="bold cyan")
        formatted.append("开始执行", style="bold blue")
        cls._console.print(Panel.fit(formatted, border_style="blue", padding=(1, 4)))
        logger.info(f"\n================Agent: {agent_name}开始=================\n")

    @classmethod
    def agent_end(cls, agent_name: str):
        """打印 Agent 结束信息"""
        cls._console.print()  # 添加前置换行
        formatted = Text()
        formatted.append("✨ ", style="bold")
        formatted.append(f"Agent: {agent_name} ", style="bold cyan")
        formatted.append("执行完成", style="bold green")
        cls._console.print(Panel.fit(formatted, border_style="green", padding=(1, 4)))
        logger.info(f"\n================Agent: {agent_name}结束==================\n")


================================================================================
E:\repo1\MathModelAgent-python\backend\app\utils\track.py 的内容:
================================================================================
# app/utils/track.py

from litellm.integrations.custom_logger import CustomLogger
import litellm


class AgentMetrics(CustomLogger):
    #### ASYNC ####

    async def async_log_success_event(self, kwargs, response_obj, start_time, end_time):
        try:
            # response_cost = kwargs.get("response_cost", 0)
            # print("streaming response_cost", response_cost)
            print("agent_name", kwargs["litellm_params"]["metadata"]["agent_name"])
        except:
            pass

    async def async_log_failure_event(self, kwargs, response_obj, start_time, end_time):
        print(f"On Async Failure")


# 全局指标收集器实例
agent_metrics = AgentMetrics()


