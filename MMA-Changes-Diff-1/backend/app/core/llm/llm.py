# app/core/llm/llm.py

# 1 ä¾èµ–
import json
import codecs
import asyncio
import random
import uuid
from typing import Any, List, Dict

from app.utils.common_utils import transform_link, split_footnotes
from app.utils.log_util import logger
from app.schemas.response import (
    CoderMessage,
    WriterMessage,
    ModelerMessage,
    SystemMessage,
    CoordinatorMessage,
)
from app.services.redis_manager import redis_manager
from litellm import acompletion, token_counter
import litellm
from app.schemas.enums import AgentType
from app.utils.track import agent_metrics
from icecream import ic

# 2 æ–‡æœ¬å¤„ç†å·¥å…·
from app.tools.text_sanitizer import TextSanitizer as TS
from app.tools.json_fixer import JsonFixer

# 3 å…¨å±€é…ç½®
# 3.1 è¯·æ±‚/é‡è¯•
REQUEST_TIMEOUT = 600
HTTPX_TIMEOUTS = {"connect": 120, "read": 120, "write": 240, "pool": 120}
DEFAULT_MAX_RETRIES = 3
BACKOFF_BASE = 0.8

# 3.2 ä¸Šä¸‹æ–‡ä¿æŠ¤
CONTEXT_TOKEN_HARD_LIMIT = 120_000

# 3.3 ä¸¥æ ¼å‚æ•° + è½»æ¸…æ´—ï¼ˆé¢æ¿ JSON å‘å¸ƒï¼‰
STRICT_JSON_ONLY = True  # ä»…æ¥å—ä¸¥æ ¼ JSONï¼ˆdictï¼‰ï¼Œç¦ç”¨ LLM é‡å»º
LIGHT_CLEANING = True  # åªå»æ§åˆ¶å­—ç¬¦ä¸æœ€å¤–å±‚å›´æ ï¼Œä¸æ”¹å†™è¯­ä¹‰

litellm.callbacks = [agent_metrics]

# 4 æœ€åä¸€è·³æ¶ˆæ¯æ¸…æ´—
_ALLOWED_KEYS = {"role", "content", "name", "tool_calls", "tool_call_id"}


def _json_dumps_safe(obj: Any) -> str:
    try:
        return json.dumps(obj, ensure_ascii=False)
    except Exception:
        return str(obj)


# === æ”¾åœ¨ llm.py é¡¶éƒ¨å·¥å…·å‡½æ•°åŒºåŸŸï¼ˆ_json_dumps_safe ä¹‹åï¼‰===
def _pretty_preview_messages(msgs: List[Dict[str, Any]], max_len: int = 2000) -> str:
    """
    å°† messages æ‰“å°ä¸ºæ˜“è¯»çš„å¤šè¡Œæ–‡æœ¬ï¼Œæˆªæ–­ contentï¼Œéšè— tool arguments çš„é•¿ä¸²ã€‚
    ä»…ç”¨äºè°ƒè¯•æ—¥å¿—ã€‚
    """
    lines = []
    for i, m in enumerate(msgs or []):
        if not isinstance(m, dict):
            lines.append(f"[{i}] <non-dict> {type(m).__name__}")
            continue
        role = m.get("role")
        tc = m.get("tool_calls")
        tc_info = ""
        if isinstance(tc, list) and tc:
            brief = []
            for t in tc:
                if not isinstance(t, dict):
                    continue
                fid = t.get("id")
                fn = (t.get("function") or {}).get("name")
                fargs = (t.get("function") or {}).get("arguments")
                alen = len(fargs) if isinstance(fargs, str) else -1
                brief.append(f"(id={fid}, fn={fn}, args_len={alen})")
            tc_info = f" tool_calls={brief}"
        tcid = m.get("tool_call_id")
        content = m.get("content")
        if isinstance(content, (dict, list)):
            try:
                content = json.dumps(content, ensure_ascii=False)
            except Exception:
                content = str(content)
        cprev = content or ""
        if isinstance(cprev, str) and len(cprev) > max_len:
            cprev = cprev[:max_len] + "â€¦"
        lines.append(f"[{i}] role={role}{tc_info}{(' tool_call_id='+tcid) if tcid else ''} | {repr(cprev)}")
    return "\n".join(lines)


def _extract_tool_text(msg: Dict[str, Any]) -> str:
    """4.1 ä» tool æ¶ˆæ¯å°½é‡æç‚¼å¯è¯»æ–‡æœ¬"""
    extracted = []

    out = msg.get("output") or msg.get("outputs") or msg.get("result") or msg.get("results")
    if out is not None:
        if isinstance(out, (list, tuple)):
            for it in out:
                if isinstance(it, dict):
                    for k in ("msg", "message", "text", "result", "content"):
                        v = it.get(k)
                        if v:
                            extracted.append(str(v))
                            break
                    else:
                        extracted.append(_json_dumps_safe(it))
                else:
                    extracted.append(str(it))
        elif isinstance(out, dict):
            for k in ("msg", "message", "text", "result", "content"):
                v = out.get(k)
                if v:
                    extracted.append(str(v))
                    break
            else:
                extracted.append(_json_dumps_safe(out))
        else:
            extracted.append(str(out))

    for k in ("text", "stdout", "stderr", "data", "value"):
        v = msg.get(k)
        if v:
            extracted.append(_json_dumps_safe(v) if isinstance(v, (list, dict)) else str(v))

    tc = msg.get("tool_result") or msg.get("tool_response") or msg.get("tool_outputs")
    if tc is not None:
        extracted.append(_json_dumps_safe(tc))

    parts, seen = [], set()
    for s in (x.strip() for x in extracted if isinstance(x, str)):
        if s and s not in seen:
            seen.add(s)
            parts.append(s)
    return "\n".join(parts)


def _looks_like_literal_escapes(s: str) -> bool:
    return TS.looks_like_literal_escapes(s)


def _stringify_tool_calls(tc_list: Any) -> Any:
    # ä¿ç•™ä»¥é˜²æ—§è°ƒç”¨å¼•ç”¨ï¼›ä¸å†å¯¹ tool_calls åšä»»ä½•â€œè§„èŒƒåŒ–/é‡ç¼–ç â€
    return tc_list


def _preflight_validate_messages(msgs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    å‘é€å‰çš„æœ€ä¿å®ˆå…œåº•ï¼š
    1) åˆ å»ä»»ä½•éå­—å…¸é¡¹
    2) ä¸¢å¼ƒç©º contentï¼ˆä½† assistant+tool_calls å…è®¸æ—  contentï¼‰
    3) ç¡®ä¿é¦–æ¡é system æ˜¯ userï¼›è‹¥ç¼ºå¤±åˆ™æ’å…¥æœ€å° user
    4) ä¸¢å¼ƒæœ€åçš„ tool
    5) å…³é”®ï¼šä¿ç•™ tool.tool_call_id ä»¥ä¾›å®¡è®¡åŒ¹é…
    """
    msgs = [m for m in (msgs or []) if isinstance(m, dict)]
    if not msgs:
        return [{"role": "user", "content": "[ç©ºå¯¹è¯å¯åŠ¨] ç»§ç»­ã€‚"}]

    # é¦–æ¡é system å¿…é¡»æ˜¯ user
    i = 0
    while i < len(msgs) and msgs[i].get("role") == "system":
        i += 1
    if i >= len(msgs) or msgs[i].get("role") != "user":
        msgs = msgs[:i] + [{"role": "user", "content": "[æ‰¿æ¥ä¸Šæ–‡ä¸Šä¸‹æ–‡] ç»§ç»­ã€‚"}] + msgs[i:]

    # å»æ‰æœ«å°¾çš„ toolï¼ˆå…ˆåšä¸€è½®ï¼‰
    while msgs and msgs[-1].get("role") == "tool":
        msgs.pop()

    cleaned = []
    for m in msgs:
        role = m.get("role")
        m2: Dict[str, Any] = {"role": role}

        # åªç»™ assistant å¤åˆ¶ tool_calls
        if role == "assistant" and isinstance(m.get("tool_calls"), list) and m["tool_calls"]:
            m2["tool_calls"] = m["tool_calls"]

        # å…³é”®ï¼šä¿ç•™ tool çš„ tool_call_id
        if role == "tool":
            tcid = m.get("tool_call_id")
            if isinstance(tcid, str) and tcid.strip():
                m2["tool_call_id"] = tcid

        # content ç»Ÿä¸€ä¸ºéç©ºå­—ç¬¦ä¸²ï¼›assistant è‹¥å¸¦ tool_calls å¯æ—  content
        c = m.get("content")
        if isinstance(c, str):
            if c.strip():
                m2["content"] = c
        elif isinstance(c, (list, dict)):
            try:
                s = json.dumps(c, ensure_ascii=False)
                if s.strip():
                    m2["content"] = s
            except Exception:
                pass

        # æ²¡å†…å®¹è€Œä¸”ä¹Ÿæ²¡æœ‰ tool_callsï¼ˆé assistantï¼‰å°±è·³è¿‡
        if role != "assistant" and "tool_calls" not in m2 and "content" not in m2:
            continue

        cleaned.append(m2)

    # å†æ¬¡å»æ‰æœ«å°¾çš„ toolï¼ˆåŒä¿é™©ï¼‰
    while cleaned and cleaned[-1].get("role") == "tool":
        cleaned.pop()

    if not cleaned:
        return [{"role": "user", "content": "[ç©ºå¯¹è¯å¯åŠ¨] ç»§ç»­ã€‚"}]

    return cleaned


def sanitize_messages_for_openai(messages: List[Dict[str, Any]]):
    """
    ç»Ÿä¸€è§„æ•´ messagesï¼Œç¡®ä¿å°½å¯èƒ½ç¬¦åˆå„åç«¯æœ€ä¿å®ˆçš„ OpenAI å…¼å®¹æ ¼å¼ï¼š
    1) ä»…å…è®¸ role in {system,user,assistant,tool}
    2) content å¿…é¡»ä¸ºéç©ºå­—ç¬¦ä¸²ï¼›assistant+tool_calls æ—¶å¯ç§»é™¤ content å­—æ®µ
    3) tool æ¶ˆæ¯å¿…é¡»èƒ½åŒ¹é…åˆ°ä¸Šä¸€æ¡ assistant.tool_calls[*].idï¼›ä¸”ä¸æºå¸¦ name å­—æ®µ
    4) ä¸¢å¼ƒç©º/æ— æ„ä¹‰æ¶ˆæ¯ï¼›åˆå¹¶ç›¸é‚»åŒè§’è‰²ï¼ˆuser/assistantï¼Œçº¯æ–‡æœ¬ä¸”å‡ä¸å« tool_callsï¼‰
    5) ç¡®ä¿æœ€åä¸€æ¡ä¸æ˜¯ toolï¼›è‹¥å…¨æ˜¯ systemï¼Œè¡¥ä¸€æ¡æœ€å° user
    """
    allowed_roles = {"system", "user", "assistant", "tool"}
    result: List[Dict[str, Any]] = []
    assistant_call_ids: set[str] = set()

    def _nonempty_str(x) -> bool:
        return isinstance(x, str) and x.strip() != ""

    for _, msg in enumerate(messages or []):
        if not isinstance(msg, dict):
            continue
        role = msg.get("role")
        if role not in allowed_roles:
            continue

        clean: Dict[str, Any] = {"role": role}

        if "content" in msg and msg.get("content") is not None:
            c = msg.get("content")
            if isinstance(c, str):
                if _nonempty_str(c):
                    clean["content"] = c
            else:
                try:
                    c2 = json.dumps(c, ensure_ascii=False)
                    if _nonempty_str(c2):
                        clean["content"] = c2
                except Exception:
                    pass

        if role == "assistant":
            tcs = msg.get("tool_calls")
            if isinstance(tcs, list) and len(tcs) > 0:
                valid_calls = []
                for tc in tcs:
                    if not isinstance(tc, dict):
                        continue
                    f = tc.get("function") or {}
                    name = f.get("name")
                    args = f.get("arguments")
                    if not (isinstance(name, str) and name.strip()):
                        continue
                    if args is None:
                        args_str = "{}"
                    elif isinstance(args, (dict, list)):
                        try:
                            args_str = json.dumps(args, ensure_ascii=False)
                        except Exception:
                            args_str = "{}"
                    elif isinstance(args, str):
                        args_str = args
                    else:
                        args_str = str(args)

                    tc_id = tc.get("id")
                    if not isinstance(tc_id, str) or not tc_id:
                        tc_id = f"call_{uuid.uuid4().hex[:12]}"

                    assistant_call_ids.add(tc_id)
                    valid_calls.append(
                        {"id": tc_id, "type": "function", "function": {"name": name, "arguments": args_str}}
                    )
                if valid_calls:
                    clean["tool_calls"] = valid_calls
                    if not _nonempty_str(clean.get("content", "")):
                        clean.pop("content", None)

        if role == "tool":
            tcid = msg.get("tool_call_id")
            if not (isinstance(tcid, str) and tcid in assistant_call_ids):
                continue
            clean["tool_call_id"] = tcid
            content = msg.get("content")
            if isinstance(content, str) and content.strip():
                clean["content"] = content
            elif isinstance(content, (dict, list)):
                try:
                    s = json.dumps(content, ensure_ascii=False)
                    if s.strip():
                        clean["content"] = s
                except Exception:
                    pass
            if "content" not in clean:
                continue

        if not _nonempty_str(clean.get("content", "")) and "tool_calls" not in clean:
            continue
        result.append(clean)

    merged: List[Dict[str, Any]] = []
    for m in result:
        if merged:
            last = merged[-1]
            if (
                last["role"] == m["role"]
                and last["role"] in ("user", "assistant")
                and not last.get("tool_calls")
                and not m.get("tool_calls")
            ):
                a = (last.get("content") or "").strip()
                b = (m.get("content") or "").strip()
                s = (a + ("\n\n" if a and b else "") + b).strip()
                if s:
                    last["content"] = s
                    continue
        merged.append(m)

    while merged and merged[-1]["role"] == "tool":
        merged.pop()
    if not merged:
        return [{"role": "user", "content": "[ç©ºå¯¹è¯å¯åŠ¨] ç»§ç»­ã€‚"}]
    if all(m.get("role") == "system" for m in merged):
        merged.append({"role": "user", "content": "[æ‰¿æ¥ä¸Šæ–‡ä¸Šä¸‹æ–‡] ç»§ç»­ã€‚"})

    logger.info("ğŸ§¹ sanitize_messages_for_openai =>\n" + _pretty_preview_messages(merged))
    return merged


# === æ”¾åœ¨ llm.py ä¸­éƒ¨ï¼ˆsanitize_messages_for_openai ä¹‹åï¼ŒLLM ç±»ä¹‹å‰ï¼‰===
def _audit_openai_messages(messages: List[Dict[str, Any]]) -> tuple[bool, List[str]]:
    """
    å¯¹æ¸…æ´—åçš„ messages åšæœ€ä¿å®ˆçš„ OpenAI å…¼å®¹æ€§å®¡è®¡ã€‚
    è¿”å› (ok, problems)
    """
    problems: List[str] = []
    allowed_roles = {"system", "user", "assistant", "tool"}

    if not isinstance(messages, list):
        problems.append("messages ä¸æ˜¯ list")
        return False, problems

    assistant_call_ids: set[str] = set()  # å…¨å±€æ”¶é›†æ‰€æœ‰ assistant çš„ tool_call_id
    first_non_system_idx = None

    for idx, m in enumerate(messages):
        if not isinstance(m, dict):
            problems.append(f"[{idx}] é dict é¡¹ï¼š{type(m).__name__}")
            continue

        role = m.get("role")
        if role not in allowed_roles:
            problems.append(f"[{idx}] éæ³• role={role}")
            continue

        if role != "system" and first_non_system_idx is None:
            first_non_system_idx = idx

        content = m.get("content")

        if role == "assistant":
            tcs = m.get("tool_calls")
            if tcs is not None:
                if not isinstance(tcs, list) or not tcs:
                    problems.append(f"[{idx}] assistant.tool_calls ä¸æ˜¯éç©º list")
                else:
                    for j, tc in enumerate(tcs):
                        if not isinstance(tc, dict):
                            problems.append(f"[{idx}] tool_calls[{j}] ä¸æ˜¯ dict")
                            continue
                        if tc.get("type") != "function":
                            problems.append(f"[{idx}] tool_calls[{j}].type å¿…é¡»ä¸º 'function'")
                        func = tc.get("function") or {}
                        name = func.get("name")
                        args = func.get("arguments")
                        if not isinstance(name, str) or not name.strip():
                            problems.append(f"[{idx}] tool_calls[{j}].function.name ç¼ºå¤±/éæ³•")
                        if not isinstance(args, str):
                            problems.append(f"[{idx}] tool_calls[{j}].function.arguments å¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼ˆJSON æ–‡æœ¬ï¼‰")
                        tcid = tc.get("id")
                        if not isinstance(tcid, str) or not tcid.strip():
                            problems.append(f"[{idx}] tool_calls[{j}].id ç¼ºå¤±/éæ³•ï¼Œå°†å¯¼è‡´ tool æ— æ³•é…å¯¹")
                        else:
                            assistant_call_ids.add(tcid)
                if not tcs:
                    if not (isinstance(content, str) and content.strip()):
                        problems.append(f"[{idx}] assistant æ²¡æœ‰ tool_calls æ—¶ content å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")
            else:
                if not (isinstance(content, str) and content.strip()):
                    problems.append(f"[{idx}] assistant.content å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")

        elif role == "tool":
            tcid = m.get("tool_call_id")
            if not isinstance(tcid, str) or tcid not in assistant_call_ids:
                problems.append(f"[{idx}] tool.tool_call_id ç¼ºå¤±æˆ–æœªæ‰¾åˆ°åœ¨ä»»ä½•å†å² assistant.tool_calls ä¸­")
            if not (isinstance(content, str) and content.strip()):
                problems.append(f"[{idx}] tool.content å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")
            if "name" in m:
                problems.append(f"[{idx}] tool ä¸åº”æºå¸¦ name å­—æ®µ")

        else:
            if not (isinstance(content, str) and content.strip()):
                problems.append(f"[{idx}] {role}.content å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")

    if first_non_system_idx is None:
        problems.append("å…¨æ˜¯ systemï¼›ç¼ºå°‘ user å¯åŠ¨æ¶ˆæ¯")
    else:
        if messages[first_non_system_idx].get("role") != "user":
            problems.append(
                f"ç¬¬ä¸€æ¡é system æ¶ˆæ¯å¿…é¡»æ˜¯ userï¼ˆå½“å‰ idx={first_non_system_idx}, role={messages[first_non_system_idx].get('role')})"
            )

    if messages and messages[-1].get("role") == "tool":
        problems.append("æœ€åä¸€æ¡æ¶ˆæ¯ä¸èƒ½æ˜¯ tool")

    ok = len(problems) == 0
    return ok, problems


# 5 LLM å°è£…
class LLM:
    def __init__(self, api_key: str, model: str, base_url: str, task_id: str):
        self.api_key = api_key
        self.model = model
        self.base_url = base_url
        self.chat_count = 0
        self.max_tokens: int | None = None
        self.task_id = task_id

    async def chat(
        self,
        history: list = None,
        tools: list = None,
        tool_choice: str = None,
        max_retries: int = DEFAULT_MAX_RETRIES,
        retry_delay: float = BACKOFF_BASE,
        top_p: float | None = None,
        agent_name: AgentType | str = AgentType.SYSTEM,
        sub_title: str | None = None,
        publish: bool = True,
    ) -> object:
        logger.info(f"subtitleæ˜¯:{sub_title}")

        if history:
            history = self._validate_and_fix_tool_calls(history)
            history = self._truncate_history_by_tokens(history, CONTEXT_TOKEN_HARD_LIMIT)
            history = self._ensure_first_after_system_user(history)

        # â€”â€” åˆ†åˆ«è®°å½• sanitize å‰/åçš„é¢„è§ˆ â€”â€” #
        safe_messages_before_preflight = sanitize_messages_for_openai(history or [])
        logger.info("ğŸ§¾ sanitize é¢„è§ˆï¼š\n" + _pretty_preview_messages(safe_messages_before_preflight))

        safe_messages_after_preflight = _preflight_validate_messages(safe_messages_before_preflight)
        logger.info("ğŸ§¾ preflight é¢„è§ˆï¼š\n" + _pretty_preview_messages(safe_messages_after_preflight))

        # ä¹‹åç»Ÿä¸€ç”¨ preflight åçš„äº§ç‰©
        safe_messages = safe_messages_after_preflight

        # ä¸¥æ ¼å®¡è®¡ + é¢„è§ˆ
        ok, probs = _audit_openai_messages(safe_messages)
        if not ok:
            logger.error("ğŸš« OpenAI æ¶ˆæ¯å®¡è®¡æœªé€šè¿‡ï¼Œå…·ä½“é—®é¢˜å¦‚ä¸‹ï¼š")
            for p in probs:
                logger.error(" - " + p)
            logger.error("ğŸ§¾ æ¸…æ´—å messages é¢„è§ˆï¼š\n" + _pretty_preview_messages(safe_messages))
            raise ValueError('"messages" failed strict audit before acompletion')
        else:
            logger.info("âœ… OpenAI æ¶ˆæ¯å®¡è®¡é€šè¿‡ã€‚")
            logger.info("ğŸ§¾ æ¸…æ´—å messages é¢„è§ˆï¼š\n" + _pretty_preview_messages(safe_messages))

        kwargs = {
            "api_key": self.api_key,
            "model": self.model,
            "messages": safe_messages,
            "stream": False,
            "metadata": {"agent_name": getattr(agent_name, "name", str(agent_name))},
            "request_timeout": REQUEST_TIMEOUT,
            "client_args": {"timeout": HTTPX_TIMEOUTS},
        }
        if top_p is not None:
            kwargs["top_p"] = top_p
        if tools:
            kwargs["tools"] = tools
            if tool_choice is not None:
                kwargs["tool_choice"] = tool_choice
        if self.max_tokens:
            kwargs["max_tokens"] = self.max_tokens
        if self.base_url:
            kwargs["base_url"] = self.base_url

        def _redact(d: dict) -> dict:
            safe = dict(d)
            if "api_key" in safe:
                safe["api_key"] = "***"
            if "client_args" in safe:
                safe["client_args"] = {"timeout": "(configured)"}
            if "messages" in safe:
                safe["messages"] = f"[{len(safe['messages'])} messages]"
            return safe

        for attempt in range(max_retries):
            try:
                response = await acompletion(**kwargs)
                if not response or not hasattr(response, "choices"):
                    raise ValueError("æ— æ•ˆçš„APIå“åº”")
                if publish:
                    self.chat_count += 1
                    await self.send_message(response, agent_name, sub_title)
                return response
            except asyncio.CancelledError:
                logger.warning("è¯·æ±‚è¢«ä¸Šå±‚å–æ¶ˆï¼ˆCancelledErrorï¼‰ï¼Œä¸é‡è¯•ã€‚")
                raise
            except (litellm.BadRequestError, litellm.AuthenticationError, litellm.NotFoundError) as e:
                msg = str(e)
                if "context" in msg.lower():
                    logger.error("ä¸Šä¸‹æ–‡è¶…é™ï¼Œè¯·åœ¨è¿›å…¥ acompletion å‰å·²å……åˆ†æˆªæ–­ã€‚")
                else:
                    logger.error(f"éé‡è¯•é”™è¯¯ï¼š{e}")
                raise
            except (
                litellm.RateLimitError,
                litellm.Timeout,
                litellm.APIConnectionError,
                litellm.InternalServerError,
                json.JSONDecodeError,
            ) as e:
                logger.error(f"ç¬¬ {attempt + 1}/{max_retries} æ¬¡é‡è¯•: {e}")
                if attempt >= max_retries - 1:
                    logger.info(f"è¯·æ±‚å‚æ•°: {_redact(kwargs)}")
                    raise
                delay = retry_delay * (2**attempt) + random.random() * 0.3
                await asyncio.sleep(delay)
            except Exception as e:
                logger.error(f"ç¬¬ {attempt + 1}/{max_retries} æ¬¡é‡è¯•ï¼ˆæœªçŸ¥å¼‚å¸¸ï¼‰: {e}")
                if attempt >= max_retries - 1:
                    logger.info(f"è¯·æ±‚å‚æ•°: {_redact(kwargs)}")
                    raise
                delay = retry_delay * (2**attempt) + random.random() * 0.3
                await asyncio.sleep(delay)

    def _validate_and_fix_tool_calls(self, history: list) -> list:
        """
        5.5 ä¿®å¤å·¥å…·è°ƒç”¨å®Œæ•´æ€§ï¼š
        1) è§’è‰²åˆæ³•åŒ–ï¼›2) assistant.tool_calls ä¸åç»­ tool é…å¯¹ï¼›
        3) é—ç•™ function â†’ toolï¼›4) å­¤å„¿ tool ä¸¢å¼ƒã€‚
        """
        if not history:
            return history

        ic(f"ğŸ” å¼€å§‹éªŒè¯å·¥å…·è°ƒç”¨ï¼Œå†å²æ¶ˆæ¯æ•°é‡: {len(history)}")
        fixed_history = []
        i = 0

        def _is_tool_resp(m: dict) -> bool:
            return isinstance(m, dict) and m.get("role") in ("tool", "function")

        while i < len(history):
            msg = history[i]

            if isinstance(msg, dict) and msg.get("tool_calls"):
                ic(f"ğŸ“ å‘ç°tool_callsæ¶ˆæ¯åœ¨ä½ç½® {i}")
                valid_tool_calls, invalid_tool_calls = [], []

                for tc in msg["tool_calls"]:
                    tool_call_id = (tc or {}).get("id")
                    ic(f"  æ£€æŸ¥tool_call_id: {tool_call_id}")
                    if not tool_call_id:
                        invalid_tool_calls.append(tc)
                        continue

                    found_response = False
                    for j in range(i + 1, len(history)):
                        m2 = history[j]
                        if _is_tool_resp(m2):
                            if m2.get("tool_call_id") == tool_call_id:
                                ic(f"  âœ… æ‰¾åˆ°åŒ¹é…å“åº”åœ¨ä½ç½® {j}")
                                found_response = True
                                break

                    (valid_tool_calls if found_response else invalid_tool_calls).append(tc)

                if valid_tool_calls:
                    fixed_msg = msg.copy()
                    fixed_msg["tool_calls"] = valid_tool_calls
                    fixed_history.append(fixed_msg)
                    ic(f"  ğŸ”§ ä¿ç•™ {len(valid_tool_calls)} ä¸ªæœ‰æ•ˆtool_callsï¼Œç§»é™¤ {len(invalid_tool_calls)} ä¸ªæ— æ•ˆçš„")
                else:
                    cleaned_msg = {k: v for k, v in msg.items() if k != "tool_calls"}
                    content = (cleaned_msg.get("content") or "").strip()
                    if content:
                        fixed_history.append(cleaned_msg)
                        ic("  ğŸ”§ ç§»é™¤æ‰€æœ‰tool_callsï¼Œä¿ç•™æ¶ˆæ¯å†…å®¹")
                    else:
                        ic("  ğŸ—‘ï¸ å®Œå…¨ç§»é™¤ç©ºçš„tool_callsæ¶ˆæ¯")

            elif _is_tool_resp(msg):
                role = msg.get("role")
                tool_call_id = msg.get("tool_call_id")
                ic(f"ğŸ”§ æ£€æŸ¥å·¥å…·å“åº”æ¶ˆæ¯: role={role}, tool_call_id={tool_call_id}")

                found_call = False
                for k in range(len(fixed_history) - 1, -1, -1):
                    prev = fixed_history[k]
                    if isinstance(prev, dict) and prev.get("tool_calls"):
                        if any((tc or {}).get("id") == tool_call_id for tc in prev["tool_calls"]):
                            found_call = True
                            break

                if found_call:
                    if role == "function":
                        msg = dict(msg)
                        msg["role"] = "tool"
                    fixed_history.append(msg)
                    ic("  âœ… ä¿ç•™æœ‰æ•ˆçš„å·¥å…·å“åº”ï¼ˆrole=toolï¼‰")
                else:
                    ic(f"  ğŸ—‘ï¸ ç§»é™¤å­¤ç«‹çš„å·¥å…·å“åº”: {tool_call_id}")

            else:
                fixed_history.append(msg)

            i += 1

        if len(fixed_history) != len(history):
            ic(f"ğŸ”§ ä¿®å¤å®Œæˆ: {len(history)} -> {len(fixed_history)} æ¡æ¶ˆæ¯")
        else:
            ic("âœ… éªŒè¯é€šè¿‡ï¼Œæ— éœ€ä¿®å¤")

        return fixed_history

    def _truncate_history_by_tokens(self, history: list, token_limit: int) -> list:
        """
        5.6 åŸºäº token çš„è£å‰ªï¼šä¿ç•™é¦–æ¡ system + å°¾éƒ¨è¿ç»­ç‰‡æ®µï¼ˆå†æ¬¡åšå·¥å…·é…å¯¹ä¿®å¤ï¼‰ã€‚
        """
        if not history:
            return history

        def msg_tokens(msg: dict) -> int:
            content = msg.get("content") or ""
            try:
                return token_counter(self.model, content)
            except Exception:
                return max(1, len(content) // 3)

        system_msg = None
        start_idx = 0
        if history[0].get("role") == "system":
            system_msg = history[0]
            start_idx = 1

        total = (msg_tokens(system_msg) if system_msg else 0) + sum(msg_tokens(m) for m in history[start_idx:])
        if total <= token_limit:
            return history

        kept = []
        running = msg_tokens(system_msg) if system_msg else 0
        for i in range(len(history) - 1, start_idx - 1, -1):
            t = msg_tokens(history[i])
            if running + t > token_limit:
                break
            kept.append(history[i])
            running += t
        kept.reverse()
        new_history = [system_msg] + kept if system_msg else kept
        new_history = self._validate_and_fix_tool_calls(new_history)
        return new_history

    async def send_message(self, response, agent_name, sub_title=None):
        logger.info(f"subtitleæ˜¯:{sub_title}")
        raw_content = getattr(response.choices[0].message, "content", "") or ""
        content_to_send = raw_content

        # 5.7 å½’ä¸€ AgentType
        if isinstance(agent_name, str):
            key = agent_name.lower().replace(" ", "")
            mapping = {
                "coordinatoragent": AgentType.COORDINATOR,
                "modeleragent": AgentType.MODELER,
                "writeragent": AgentType.WRITER,
                "coderagent": AgentType.CODER,
                "jsonfixer": AgentType.MODELER,
                "jsonfixerheavy": AgentType.MODELER,
            }
            agent_name = mapping.get(key) or (
                AgentType.COORDINATOR
                if "coord" in key
                else (
                    AgentType.MODELER
                    if ("model" in key or "jsonfixer" in key)
                    else (
                        AgentType.WRITER if "writer" in key else AgentType.CODER if "coder" in key else AgentType.SYSTEM
                    )
                )
            )

        # 5.8 Coordinator / Modelerï¼šé¢æ¿å‘å¸ƒä¸¥æ ¼ JSONï¼ˆåº”ç”¨ STRICT_JSON_ONLY + LIGHT_CLEANINGï¼‰
        if agent_name in (AgentType.COORDINATOR, AgentType.MODELER):
            prepared = raw_content
            if LIGHT_CLEANING:
                prepared = TS.clean_control_chars(prepared, keep_whitespace=True)
                prepared = TS.strip_fences_outer_or_all(prepared)

            try:
                obj, stage = await JsonFixer.fix_and_parse(
                    raw=prepared,
                    llm=None if STRICT_JSON_ONLY else self,
                    agent_name=f"{getattr(agent_name, 'name', str(agent_name))}.JsonFixer",
                )
                logger.info(f"[send_message] JsonFixer stage: {stage}")
            except Exception as e:
                logger.exception(f"JsonFixer è°ƒç”¨å¤±è´¥: {e}")
                err_obj = {"error": "jsonfixer_exception", "exc": str(e)}
                content_to_send = json.dumps(err_obj, ensure_ascii=False)
            else:
                if isinstance(obj, dict):
                    content_to_send = json.dumps(obj, ensure_ascii=False)
                else:
                    preview = (prepared[:2000] + "â€¦") if len(prepared) > 2000 else prepared
                    err_obj = {"error": "json_unparseable", "stage": stage, "raw_preview": preview}
                    content_to_send = json.dumps(err_obj, ensure_ascii=False)
                    logger.warning(f"send_message: JSON è§£æå¤±è´¥ stage={stage}; å·²å‘å¸ƒé”™è¯¯å¯¹è±¡ä¾›ä¸Šæ¸¸å¤„ç†.")

        # 5.9 å‘å¸ƒåˆ°å‰ç«¯
        match agent_name:
            case AgentType.CODER:
                agent_msg: CoderMessage = CoderMessage(content=content_to_send)
            case AgentType.WRITER:
                c, _ = split_footnotes(content_to_send)
                c = transform_link(self.task_id, c)
                agent_msg: WriterMessage = WriterMessage(content=c, sub_title=sub_title)
            case AgentType.MODELER:
                agent_msg: ModelerMessage = ModelerMessage(content=content_to_send)
            case AgentType.COORDINATOR:
                agent_msg: CoordinatorMessage = CoordinatorMessage(content=content_to_send)
            case AgentType.SYSTEM:
                agent_msg: SystemMessage = SystemMessage(content=content_to_send)
            case _:
                agent_msg: SystemMessage = SystemMessage(content=content_to_send)

        await redis_manager.publish_message(self.task_id, agent_msg)

    def _ensure_first_after_system_user(self, history: list) -> list:
        """
        5.10 ä¿è¯ï¼šä»»æ„æ•°é‡çš„ system ä¹‹åï¼Œç¬¬ä¸€æ¡é system å¿…é¡»æ˜¯ userã€‚
        A) è‹¥é¦–æ¡é system æ˜¯ assistant ä¸”å†…å®¹åƒâ€œå†å²å¯¹è¯æ€»ç»“â€¦â€ï¼Œå°±åœ°æ”¹ä¸º userï¼›
        B) å¦åˆ™åœ¨å…¶å‰æ’å…¥æœ€å° user æ‰¿æ¥è¯­ï¼›
        C) è‹¥å…¨æ˜¯ system æˆ–ç©ºï¼Œä¹Ÿæ’å…¥ä¸€æ¡æœ€å° userã€‚
        """
        if not history:
            return [{"role": "user", "content": "[ç©ºå¯¹è¯å¯åŠ¨] ç»§ç»­ã€‚"}]

        i = 0
        while i < len(history) and isinstance(history[i], dict) and history[i].get("role") == "system":
            i += 1

        if i >= len(history):
            return history + [{"role": "user", "content": "[æ‰¿æ¥ä¸Šæ–‡ä¸Šä¸‹æ–‡] ç»§ç»­ã€‚"}]

        first = history[i] if isinstance(history[i], dict) else {}
        role = first.get("role")
        if role != "user":
            content = (first.get("content") or "").strip()
            if role == "assistant" and content.startswith("[å†å²å¯¹è¯æ€»ç»“"):
                first["role"] = "user"
                history[i] = first
            else:
                history = history[:i] + [{"role": "user", "content": "[æ‰¿æ¥ä¸Šæ–‡ä¸Šä¸‹æ–‡] ç»§ç»­ã€‚"}] + history[i:]

        return history


# 6 ç®€å•èŠå¤©ï¼ˆå«ä¸Šä¸‹æ–‡å‹ç¼©ï¼‰
async def simple_chat(model: LLM, history: list) -> str:
    """
    6.1 å…ˆåšå·¥å…·é…å¯¹ä¿®å¤ï¼›
    6.2 è‹¥è¶…é™ï¼šä¿ç•™ system + å°¾éƒ¨ç‰‡æ®µï¼Œå‰æ®µåšæ‘˜è¦ï¼ˆå¤šè½®é€’å‡ï¼‰ï¼›
    6.3 å§‹ç»ˆä¿è¯ system åç¬¬ä¸€æ¡æ˜¯ userï¼Œå†å‘èµ·è¡¥å…¨ã€‚
    """

    def quick_count(msg):
        content = (msg or {}).get("content") or ""
        try:
            return token_counter(model=model.model, text=content)  # æ–°ç‰ˆç­¾åï¼›å¤±è´¥èµ° except
        except Exception:
            try:
                return token_counter(model.model, content)  # æ—§ç­¾åå…œåº•
            except Exception:
                return max(1, len(content) // 3)

    def tokens_of(messages):
        if not messages:
            return 0
        return sum(quick_count(m) for m in messages if isinstance(m, dict))

    def pair_safe_tail(messages):
        MAX_TAIL_MSGS = 300
        start = max(0, len(messages) - MAX_TAIL_MSGS)
        tail = messages[start:]
        return model._validate_and_fix_tool_calls(tail)

    async def summarize_chunk(chunk_msgs, retries: int = 2):  # â† åŠ è½»é‡é‡è¯•
        sys_prompt = {
            "role": "system",
            "content": (
                "ä½ æ˜¯ä¸€ä¸ªå¯¹è¯æ‘˜è¦å™¨ã€‚è¯·å°†ä»¥ä¸‹å¯¹è¯å‹ç¼©ä¸ºä¸€æ®µç®€æ´çš„ä¸­æ–‡æ€»ç»“ï¼Œ"
                "ä¿ç•™ä»»åŠ¡ç›®æ ‡ã€å…³é”®çº¦æŸã€é‡è¦ç»“è®ºå’Œå·²å®Œæˆæ­¥éª¤ï¼Œå»é™¤æ— å…³ç»†èŠ‚ã€‚è¾“å‡ºä¸è¶…è¿‡ 600 å­—ã€‚"
            ),
        }
        user_prompt = {
            "role": "user",
            "content": "\n".join(
                f"{m.get('role')}: {(m.get('content') or '')[:2000]}" for m in chunk_msgs if isinstance(m, dict)
            ),
        }
        msgs = sanitize_messages_for_openai([sys_prompt, user_prompt])
        for attempt in range(retries + 1):
            try:
                kwargs2 = {
                    "api_key": model.api_key,
                    "model": model.model,
                    "messages": msgs,
                    "stream": False,
                    "request_timeout": REQUEST_TIMEOUT,
                    "client_args": {"timeout": HTTPX_TIMEOUTS},
                }
                if model.base_url:
                    kwargs2["base_url"] = model.base_url
                resp = await acompletion(**kwargs2)
                return resp.choices[0].message.content.strip()
            except Exception as e:
                if attempt >= retries:
                    raise
                await asyncio.sleep(0.6 * (2**attempt))  # 0.6s, 1.2s

    history = history or []
    history = model._validate_and_fix_tool_calls(history)

    sys_msg = history[0] if (history and history[0].get("role") == "system") else None
    start_idx = 1 if sys_msg else 0
    body = history[start_idx:]

    total_tokens = (quick_count(sys_msg) if sys_msg else 0) + tokens_of(body)
    if total_tokens <= CONTEXT_TOKEN_HARD_LIMIT:
        ready = [sys_msg] + body if sys_msg else body
        ready = model._ensure_first_after_system_user(ready)
        msgs = sanitize_messages_for_openai(ready)

        kwargs = {
            "api_key": model.api_key,
            "model": model.model,
            "messages": msgs,
            "stream": False,
            "request_timeout": REQUEST_TIMEOUT,
            "client_args": {"timeout": HTTPX_TIMEOUTS},
        }
        if model.base_url:
            kwargs["base_url"] = model.base_url
        resp = await acompletion(**kwargs)
        return resp.choices[0].message.content

    MAX_SUMMARY_ROUNDS = 3
    for _ in range(MAX_SUMMARY_ROUNDS):
        tail = pair_safe_tail(body)
        SUMMARY_BUDGET_HINT = 1500

        def tail_tokens(t):
            return tokens_of(t)

        keep = len(tail)
        while keep > 0:
            candidate_tail = tail[-keep:]
            rough_total = (quick_count(sys_msg) if sys_msg else 0) + SUMMARY_BUDGET_HINT + tail_tokens(candidate_tail)
            if rough_total <= CONTEXT_TOKEN_HARD_LIMIT:
                tail = model._validate_and_fix_tool_calls(candidate_tail)
                break
            keep //= 2
        else:
            tail = []

        cut_at = len(body) - len(tail)
        head = body[: max(cut_at, 0)]

        try:
            summary_text = await summarize_chunk(head) if head else ""
        except Exception as e:
            logger.error(f"æ‘˜è¦å¤±è´¥ï¼Œå›é€€ä½¿ç”¨å ä½ï¼š{e}")
            summary_text = "ï¼ˆå¯¹è¯ä¸­æ®µæ‘˜è¦ï¼šåŒ…å«è‹¥å¹²æ­¥éª¤ä¸ä¸­é—´ç»“è®ºï¼Œå·²çœç•¥ç»†èŠ‚ã€‚ï¼‰"

        summary_msg = {"role": "user", "content": f"[å†å²å¯¹è¯æ€»ç»“-ä»…ä¾›ä¸Šä¸‹æ–‡ï¼Œæ— éœ€å›å¤]\n{summary_text}"}
        new_history = ([sys_msg] if sys_msg else []) + [summary_msg] + tail
        new_history = model._validate_and_fix_tool_calls(new_history)
        new_history = model._ensure_first_after_system_user(new_history)
        exact_total = tokens_of(new_history)

        if exact_total <= CONTEXT_TOKEN_HARD_LIMIT:
            msgs = sanitize_messages_for_openai(new_history)
            kwargs = {
                "api_key": model.api_key,
                "model": model.model,
                "messages": msgs,
                "stream": False,
                "request_timeout": REQUEST_TIMEOUT,
                "client_args": {"timeout": HTTPX_TIMEOUTS},
            }
            if model.base_url:
                kwargs["base_url"] = model.base_url
            resp = await acompletion(**kwargs)
            return resp.choices[0].message.content

        body = head + tail  # ä¸‹ä¸€è½®ç»§ç»­å‹ç¼©

    try:
        minimal_summary = await summarize_chunk(body[:2000])
    except Exception:
        minimal_summary = "ï¼ˆè¶…é•¿ä¸Šä¸‹æ–‡ï¼Œå·²å‹ç¼©ä¸ºæçŸ­æ‘˜è¦ã€‚ï¼‰"

    final_history = ([sys_msg] if sys_msg else []) + [
        {"role": "user", "content": f"[å†å²å¯¹è¯æç®€æ€»ç»“-ä»…ä¾›ä¸Šä¸‹æ–‡ï¼Œæ— éœ€å›å¤]\n{minimal_summary}"}
    ]
    final_history = model._ensure_first_after_system_user(final_history)
    msgs = sanitize_messages_for_openai(final_history)

    kwargs = {
        "api_key": model.api_key,
        "model": model.model,
        "messages": msgs,
        "stream": False,
        "request_timeout": REQUEST_TIMEOUT,
        "client_args": {"timeout": HTTPX_TIMEOUTS},
    }
    if model.base_url:
        kwargs["base_url"] = model.base_url
    resp = await acompletion(**kwargs)
    return resp.choices[0].message.content
